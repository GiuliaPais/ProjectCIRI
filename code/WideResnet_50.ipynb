{"cells":[{"cell_type":"markdown","metadata":{"id":"V_ELLXjBYFpB"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24521,"status":"ok","timestamp":1713122936114,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"},"user_tz":-120},"id":"hFTjGbWPX7j6","outputId":"320d1c9b-1805-427e-ecf2-d4bb121ced6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713122936114,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"},"user_tz":-120},"id":"poQ3pFEvYOei"},"outputs":[],"source":["import os\n","project_folder = '/gdrive/MyDrive/ProjectCIRI'\n","my_module_path = os.path.join(project_folder, 'code', 'ciri_utils')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148046,"status":"ok","timestamp":1713123084157,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"},"user_tz":-120},"id":"f71rsuysYQk1","outputId":"4fa8b8a2-d21d-4a21-b797-aa0c377fbfca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /gdrive/MyDrive/ProjectCIRI/code/ciri_utils\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ciri-utils==0.1) (2.0.3)\n","Collecting torch>=2.2.2 (from ciri-utils==0.1)\n","  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision>=0.17.2 (from ciri-utils==0.1)\n","  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ray[tune] (from ciri-utils==0.1)\n","  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ciri-utils==0.1) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ciri-utils==0.1) (1.2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ciri-utils==0.1) (4.66.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.2->ciri-utils==0.1) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.2->ciri-utils==0.1) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.2->ciri-utils==0.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.2->ciri-utils==0.1) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.2->ciri-utils==0.1) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.2->ciri-utils==0.1) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.2->ciri-utils==0.1) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.2->ciri-utils==0.1)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.17.2->ciri-utils==0.1) (9.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ciri-utils==0.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ciri-utils==0.1) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ciri-utils==0.1) (2024.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]->ciri-utils==0.1) (8.1.7)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]->ciri-utils==0.1) (4.19.2)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]->ciri-utils==0.1) (1.0.8)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]->ciri-utils==0.1) (24.0)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]->ciri-utils==0.1) (3.20.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[tune]->ciri-utils==0.1) (6.0.1)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]->ciri-utils==0.1) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]->ciri-utils==0.1) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]->ciri-utils==0.1) (2.31.0)\n","Collecting tensorboardX>=1.9 (from ray[tune]->ciri-utils==0.1)\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]->ciri-utils==0.1) (14.0.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ciri-utils==0.1) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ciri-utils==0.1) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ciri-utils==0.1) (3.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ciri-utils==0.1) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.2->ciri-utils==0.1) (2.1.5)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]->ciri-utils==0.1) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]->ciri-utils==0.1) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]->ciri-utils==0.1) (0.34.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]->ciri-utils==0.1) (0.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]->ciri-utils==0.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]->ciri-utils==0.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]->ciri-utils==0.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]->ciri-utils==0.1) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.2->ciri-utils==0.1) (1.3.0)\n","Building wheels for collected packages: ciri-utils\n","  Building wheel for ciri-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ciri-utils: filename=ciri_utils-0.1-py3-none-any.whl size=26970 sha256=f2b55da56bd9057c695647f0a90c97389dccb713f525d909fb49bf7541281f39\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_nkvbydx/wheels/af/b2/73/860a75cbbf27b28ca0320a77f4feeba042b17de09092a60e68\n","Successfully built ciri-utils\n","Installing collected packages: tensorboardX, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, ray, torchvision, ciri-utils\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.2.1+cu121\n","    Uninstalling torch-2.2.1+cu121:\n","      Successfully uninstalled torch-2.2.1+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.17.1+cu121\n","    Uninstalling torchvision-0.17.1+cu121:\n","      Successfully uninstalled torchvision-0.17.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\n","torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed ciri-utils-0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 ray-2.10.0 tensorboardX-2.6.2.2 torch-2.2.2 torchvision-0.17.2\n"]}],"source":["!pip install $my_module_path"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":18819,"status":"ok","timestamp":1713123102970,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"},"user_tz":-120},"id":"lGBakHaeYXYx"},"outputs":[],"source":["import ray\n","\n","from ray import tune\n","from ciri_utils.engine_v2 import CIRI_trainer"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1713123102971,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"},"user_tz":-120},"id":"O2x3kF5tYjoR"},"outputs":[],"source":["# Paths for the dataset\n","root_base = os.path.join(project_folder, 'Incidents-subset')\n","root_augmented = os.path.join(project_folder, 'augmented_images')\n","\n","data_folders=[root_base, root_augmented]\n","persistence_path = os.path.join(project_folder, 'checkpoints', 'HPT_wide_resnet_50')"]},{"cell_type":"markdown","metadata":{"id":"iPcXt51cZJfC"},"source":["# Preparation"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1713123102971,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"},"user_tz":-120},"id":"O72Fze0pYt3L"},"outputs":[],"source":["selected_model=\"wide_resnet50_2\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gva43STPY5JP"},"outputs":[],"source":["ciri_trainer = CIRI_trainer(model=selected_model,\n","                            data_folders=data_folders,\n","                            data_prop=0.8,\n","                            sample_indices=0.2)"]},{"cell_type":"markdown","metadata":{"id":"pFrqYn1qYiwY"},"source":["# Hyperparameter tuning"]},{"cell_type":"markdown","metadata":{"id":"oCTYkOvUZYrF"},"source":["Perform hyper parameter tuning with nested cross-validation on a 20% sample of the dataset."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1713123102971,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"},"user_tz":-120},"id":"UGtcSMdMZGuN"},"outputs":[],"source":["search_space={\n","\t'epochs': tune.choice([5, 10, 20]),\n","\t'batch_size': tune.choice([32, 64]),\n","\t'lr': tune.loguniform(1e-4, 1e-2)\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSdRAJCYZUDK","outputId":"1ede1c38-7a15-4a38-856e-54e2d89d4737","executionInfo":{"status":"ok","timestamp":1713085309928,"user_tz":-120,"elapsed":4180123,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Outer fold 4, inner fold 0 - number of samples: 1281\n","Tuning hyperparameters for wide_resnet50_hpt_outer_4_inner_0...\n","Defaulting to ASHA scheduler (no scheduler provided or not an instance of TrialScheduler)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = _posixsubprocess.fork_exec(\n","2024-04-14 07:52:13,556\tINFO worker.py:1752 -- Started a local Ray instance.\n","2024-04-14 07:52:14,946\tINFO tune.py:263 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n","2024-04-14 07:52:14,963\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------------------+\n","| Configuration for experiment     wide_resnet50_hpt_outer_4_inner_0   |\n","+----------------------------------------------------------------------+\n","| Search algorithm                 BasicVariantGenerator               |\n","| Scheduler                        AsyncHyperBandScheduler             |\n","| Number of trials                 5                                   |\n","+----------------------------------------------------------------------+\n","\n","View detailed results here: /root/ray_results/wide_resnet50_hpt_outer_4_inner_0\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-04-14_07-52-09_892030_20145/artifacts/2024-04-14_07-52-14/wide_resnet50_hpt_outer_4_inner_0/driver_artifacts`\n","\n","Trial status: 5 PENDING\n","Current time: 2024-04-14 07:52:15. Total running time: 0s\n","Logical resource usage: 0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr |\n","+----------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   PENDING                        10                       64              0.000304055 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874   |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071  |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889  |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077  |\n","+----------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(TrainTrainable pid=20570)\u001b[0m 2024-04-14 07:52:21.506807: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(TrainTrainable pid=20570)\u001b[0m 2024-04-14 07:52:21.506873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(TrainTrainable pid=20570)\u001b[0m 2024-04-14 07:52:21.508720: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(TrainTrainable pid=20570)\u001b[0m 2024-04-14 07:52:23.440172: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial TorchTrainer_e8bbe_00000 started with configuration:\n","+------------------------------------------------------------------+\n","| Trial TorchTrainer_e8bbe_00000 config                            |\n","+------------------------------------------------------------------+\n","| train_loop_config/batch_size                                  64 |\n","| train_loop_config/epochs                                      10 |\n","| train_loop_config/lr                      0.00030405490309504623 |\n","| train_loop_config/train_test_idx            ...20, 11731, 1157]) |\n","+------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(TorchTrainer pid=20570)\u001b[0m Started distributed worker processes: \n","\u001b[36m(TorchTrainer pid=20570)\u001b[0m - (ip=172.28.0.12, pid=20650) world_rank=0, local_rank=0, node_rank=0\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m 2024-04-14 07:52:29.920907: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m 2024-04-14 07:52:29.920993: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m 2024-04-14 07:52:29.922641: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m 2024-04-14 07:52:31.293619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Moving model to device: cuda:0\n","Epoch (training) 1:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 1:   5%|▍         | 1/21 [00:07<02:38,  7.92s/it]\n","Epoch (training) 1:  10%|▉         | 2/21 [00:10<01:29,  4.71s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:52:45. Total running time: 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr |\n","+----------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874   |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071  |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889  |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077  |\n","+----------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  14%|█▍        | 3/21 [00:13<01:08,  3.79s/it]\n","Epoch (training) 1:  19%|█▉        | 4/21 [00:15<00:53,  3.14s/it]\n","Epoch (training) 1:  24%|██▍       | 5/21 [00:18<00:50,  3.18s/it]\n","Epoch (training) 1:  29%|██▊       | 6/21 [00:20<00:42,  2.82s/it]\n","Epoch (training) 1:  33%|███▎      | 7/21 [00:22<00:36,  2.57s/it]\n","Epoch (training) 1:  38%|███▊      | 8/21 [00:24<00:30,  2.37s/it]\n","Epoch (training) 1:  43%|████▎     | 9/21 [00:27<00:30,  2.51s/it]\n","Epoch (training) 1:  48%|████▊     | 10/21 [00:30<00:28,  2.56s/it]\n","Epoch (training) 1:  52%|█████▏    | 11/21 [00:33<00:26,  2.68s/it]\n","Epoch (training) 1:  57%|█████▋    | 12/21 [00:36<00:25,  2.80s/it]\n","Epoch (training) 1:  62%|██████▏   | 13/21 [00:38<00:21,  2.70s/it]\n","Epoch (training) 1:  67%|██████▋   | 14/21 [00:40<00:17,  2.55s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:53:15. Total running time: 1min 0s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr |\n","+----------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874   |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071  |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889  |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077  |\n","+----------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  71%|███████▏  | 15/21 [00:42<00:13,  2.29s/it]\n","Epoch (training) 1:  76%|███████▌  | 16/21 [00:44<00:11,  2.28s/it]\n","Epoch (training) 1:  81%|████████  | 17/21 [00:47<00:10,  2.56s/it]\n","Epoch (training) 1:  86%|████████▌ | 18/21 [00:51<00:08,  2.85s/it]\n","Epoch (training) 1:  90%|█████████ | 19/21 [00:53<00:04,  2.50s/it]\n","Epoch (training) 1:  95%|█████████▌| 20/21 [00:53<00:01,  1.84s/it]\n","Epoch (training) 1: 100%|██████████| 21/21 [00:53<00:00,  2.56s/it]\n","Epoch (test) 1:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 1:   9%|▉         | 1/11 [00:04<00:45,  4.56s/it]\n","Epoch (test) 1:  18%|█▊        | 2/11 [00:07<00:29,  3.33s/it]\n","Epoch (test) 1:  27%|██▋       | 3/11 [00:10<00:27,  3.39s/it]\n","Epoch (test) 1:  36%|███▋      | 4/11 [00:13<00:22,  3.26s/it]\n","Epoch (test) 1:  45%|████▌     | 5/11 [00:15<00:17,  2.87s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:53:45. Total running time: 1min 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr |\n","+----------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874   |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071  |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889  |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077  |\n","+----------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 1:  55%|█████▍    | 6/11 [00:18<00:14,  2.87s/it]\n","Epoch (test) 1:  64%|██████▎   | 7/11 [00:20<00:09,  2.43s/it]\n","Epoch (test) 1:  73%|███████▎  | 8/11 [00:21<00:06,  2.22s/it]\n","Epoch (test) 1:  82%|████████▏ | 9/11 [00:24<00:04,  2.43s/it]\n","Epoch (test) 1: 100%|██████████| 11/11 [00:24<00:00,  2.27s/it]\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00000_0_batch_size=64,epochs=10,lr=0.0003_2024-04-14_07-52-15/checkpoint_000000)\n","Epoch (training) 2:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 2:   5%|▍         | 1/21 [00:03<01:15,  3.79s/it]\n","Epoch (training) 2:  10%|▉         | 2/21 [00:05<00:49,  2.60s/it]\n","Epoch (training) 2:  14%|█▍        | 3/21 [00:09<00:56,  3.16s/it]\n","Epoch (training) 2:  19%|█▉        | 4/21 [00:11<00:46,  2.72s/it]\n","Epoch (training) 2:  24%|██▍       | 5/21 [00:13<00:42,  2.64s/it]\n","Epoch (training) 2:  29%|██▊       | 6/21 [00:16<00:37,  2.47s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:54:15. Total running time: 2min 0s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        1            93.5278   4.39592     0.110764 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 2:  33%|███▎      | 7/21 [00:18<00:34,  2.45s/it]\n","Epoch (training) 2:  38%|███▊      | 8/21 [00:20<00:29,  2.31s/it]\n","Epoch (training) 2:  43%|████▎     | 9/21 [00:24<00:33,  2.78s/it]\n","Epoch (training) 2:  48%|████▊     | 10/21 [00:26<00:28,  2.59s/it]\n","Epoch (training) 2:  52%|█████▏    | 11/21 [00:28<00:24,  2.41s/it]\n","Epoch (training) 2:  57%|█████▋    | 12/21 [00:30<00:21,  2.39s/it]\n","Epoch (training) 2:  62%|██████▏   | 13/21 [00:33<00:20,  2.52s/it]\n","Epoch (training) 2:  67%|██████▋   | 14/21 [00:36<00:17,  2.49s/it]\n","Epoch (training) 2:  71%|███████▏  | 15/21 [00:39<00:17,  2.88s/it]\n","Epoch (training) 2:  76%|███████▌  | 16/21 [00:42<00:13,  2.74s/it]\n","Epoch (training) 2:  81%|████████  | 17/21 [00:44<00:10,  2.74s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:54:45. Total running time: 2min 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        1            93.5278   4.39592     0.110764 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 2:  86%|████████▌ | 18/21 [00:48<00:08,  2.84s/it]\n","Epoch (training) 2:  90%|█████████ | 19/21 [00:50<00:05,  2.71s/it]\n","Epoch (training) 2:  95%|█████████▌| 20/21 [00:50<00:02,  2.00s/it]\n","Epoch (training) 2: 100%|██████████| 21/21 [00:51<00:00,  2.43s/it]\n","Epoch (test) 2:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 2:   9%|▉         | 1/11 [00:05<00:56,  5.62s/it]\n","Epoch (test) 2:  18%|█▊        | 2/11 [00:08<00:34,  3.78s/it]\n","Epoch (test) 2:  27%|██▋       | 3/11 [00:10<00:25,  3.15s/it]\n","Epoch (test) 2:  36%|███▋      | 4/11 [00:12<00:20,  2.86s/it]\n","Epoch (test) 2:  45%|████▌     | 5/11 [00:15<00:16,  2.69s/it]\n","Epoch (test) 2:  55%|█████▍    | 6/11 [00:19<00:15,  3.14s/it]\n","Epoch (test) 2:  64%|██████▎   | 7/11 [00:20<00:10,  2.60s/it]\n","Epoch (test) 2:  73%|███████▎  | 8/11 [00:22<00:07,  2.34s/it]\n","Epoch (test) 2:  82%|████████▏ | 9/11 [00:24<00:04,  2.26s/it]\n","Epoch (test) 2: 100%|██████████| 11/11 [00:24<00:00,  2.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:55:15. Total running time: 3min 0s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        1            93.5278   4.39592     0.110764 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00000_0_batch_size=64,epochs=10,lr=0.0003_2024-04-14_07-52-15/checkpoint_000001)\n","Epoch (training) 3:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 3:   5%|▍         | 1/21 [00:03<01:17,  3.86s/it]\n","Epoch (training) 3:  10%|▉         | 2/21 [00:05<00:50,  2.68s/it]\n","Epoch (training) 3:  14%|█▍        | 3/21 [00:09<00:55,  3.07s/it]\n","Epoch (training) 3:  19%|█▉        | 4/21 [00:11<00:47,  2.80s/it]\n","Epoch (training) 3:  24%|██▍       | 5/21 [00:14<00:44,  2.76s/it]\n","Epoch (training) 3:  29%|██▊       | 6/21 [00:16<00:36,  2.41s/it]\n","Epoch (training) 3:  33%|███▎      | 7/21 [00:18<00:35,  2.56s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:55:45. Total running time: 3min 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        2            180.349   2.42988     0.185647 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 3:  38%|███▊      | 8/21 [00:22<00:37,  2.88s/it]\n","Epoch (training) 3:  43%|████▎     | 9/21 [00:24<00:30,  2.53s/it]\n","Epoch (training) 3:  48%|████▊     | 10/21 [00:28<00:32,  2.95s/it]\n","Epoch (training) 3:  52%|█████▏    | 11/21 [00:29<00:25,  2.58s/it]\n","Epoch (training) 3:  57%|█████▋    | 12/21 [00:31<00:21,  2.38s/it]\n","Epoch (training) 3:  62%|██████▏   | 13/21 [00:33<00:17,  2.14s/it]\n","Epoch (training) 3:  67%|██████▋   | 14/21 [00:36<00:16,  2.33s/it]\n","Epoch (training) 3:  71%|███████▏  | 15/21 [00:38<00:14,  2.40s/it]\n","Epoch (training) 3:  76%|███████▌  | 16/21 [00:42<00:14,  2.87s/it]\n","Epoch (training) 3:  81%|████████  | 17/21 [00:44<00:10,  2.70s/it]\n","Epoch (training) 3:  86%|████████▌ | 18/21 [00:47<00:07,  2.60s/it]\n","Epoch (training) 3:  90%|█████████ | 19/21 [00:49<00:04,  2.42s/it]\n","Epoch (training) 3:  95%|█████████▌| 20/21 [00:49<00:01,  1.79s/it]\n","Epoch (training) 3: 100%|██████████| 21/21 [00:49<00:00,  2.38s/it]\n","Epoch (test) 3:   0%|          | 0/11 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:56:15. Total running time: 4min 0s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        2            180.349   2.42988     0.185647 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 3:   9%|▉         | 1/11 [00:05<00:58,  5.89s/it]\n","Epoch (test) 3:  18%|█▊        | 2/11 [00:08<00:35,  3.90s/it]\n","Epoch (test) 3:  27%|██▋       | 3/11 [00:10<00:25,  3.22s/it]\n","Epoch (test) 3:  36%|███▋      | 4/11 [00:13<00:20,  2.92s/it]\n","Epoch (test) 3:  45%|████▌     | 5/11 [00:15<00:15,  2.63s/it]\n","Epoch (test) 3:  55%|█████▍    | 6/11 [00:19<00:15,  3.13s/it]\n","Epoch (test) 3:  64%|██████▎   | 7/11 [00:21<00:10,  2.66s/it]\n","Epoch (test) 3:  73%|███████▎  | 8/11 [00:22<00:07,  2.37s/it]\n","Epoch (test) 3:  82%|████████▏ | 9/11 [00:24<00:04,  2.27s/it]\n","Epoch (test) 3: 100%|██████████| 11/11 [00:25<00:00,  2.28s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:56:45. Total running time: 4min 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        2            180.349   2.42988     0.185647 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00000_0_batch_size=64,epochs=10,lr=0.0003_2024-04-14_07-52-15/checkpoint_000002)\n","Epoch (training) 4:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 4:   5%|▍         | 1/21 [00:04<01:35,  4.79s/it]\n","Epoch (training) 4:  10%|▉         | 2/21 [00:08<01:14,  3.90s/it]\n","Epoch (training) 4:  14%|█▍        | 3/21 [00:11<01:05,  3.65s/it]\n","Epoch (training) 4:  19%|█▉        | 4/21 [00:14<01:00,  3.55s/it]\n","Epoch (training) 4:  24%|██▍       | 5/21 [00:17<00:52,  3.26s/it]\n","Epoch (training) 4:  29%|██▊       | 6/21 [00:19<00:41,  2.75s/it]\n","Epoch (training) 4:  33%|███▎      | 7/21 [00:20<00:32,  2.33s/it]\n","Epoch (training) 4:  38%|███▊      | 8/21 [00:22<00:29,  2.29s/it]\n","Epoch (training) 4:  43%|████▎     | 9/21 [00:26<00:32,  2.71s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:57:16. Total running time: 5min 0s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        3            263.098   2.96712     0.265211 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 4:  48%|████▊     | 10/21 [00:29<00:30,  2.73s/it]\n","Epoch (training) 4:  52%|█████▏    | 11/21 [00:31<00:26,  2.61s/it]\n","Epoch (training) 4:  57%|█████▋    | 12/21 [00:33<00:21,  2.39s/it]\n","Epoch (training) 4:  62%|██████▏   | 13/21 [00:36<00:19,  2.41s/it]\n","Epoch (training) 4:  67%|██████▋   | 14/21 [00:38<00:16,  2.29s/it]\n","Epoch (training) 4:  71%|███████▏  | 15/21 [00:39<00:12,  2.09s/it]\n","Epoch (training) 4:  76%|███████▌  | 16/21 [00:41<00:10,  2.08s/it]\n","Epoch (training) 4:  81%|████████  | 17/21 [00:46<00:10,  2.75s/it]\n","Epoch (training) 4:  86%|████████▌ | 18/21 [00:48<00:07,  2.64s/it]\n","Epoch (training) 4:  90%|█████████ | 19/21 [00:50<00:04,  2.36s/it]\n","Epoch (training) 4:  95%|█████████▌| 20/21 [00:50<00:01,  1.75s/it]\n","Epoch (training) 4: 100%|██████████| 21/21 [00:50<00:00,  2.41s/it]\n","Epoch (test) 4:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 4:   9%|▉         | 1/11 [00:04<00:43,  4.38s/it]\n","Epoch (test) 4:  18%|█▊        | 2/11 [00:07<00:33,  3.71s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:57:46. Total running time: 5min 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        3            263.098   2.96712     0.265211 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 4:  27%|██▋       | 3/11 [00:10<00:27,  3.44s/it]\n","Epoch (test) 4:  36%|███▋      | 4/11 [00:13<00:21,  3.04s/it]\n","Epoch (test) 4:  45%|████▌     | 5/11 [00:15<00:16,  2.71s/it]\n","Epoch (test) 4:  55%|█████▍    | 6/11 [00:18<00:13,  2.75s/it]\n","Epoch (test) 4:  64%|██████▎   | 7/11 [00:19<00:09,  2.33s/it]\n","Epoch (test) 4:  73%|███████▎  | 8/11 [00:21<00:07,  2.36s/it]\n","Epoch (test) 4:  82%|████████▏ | 9/11 [00:24<00:04,  2.50s/it]\n","Epoch (test) 4: 100%|██████████| 11/11 [00:24<00:00,  2.27s/it]\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00000_0_batch_size=64,epochs=10,lr=0.0003_2024-04-14_07-52-15/checkpoint_000003)\n","Epoch (training) 5:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 5:   5%|▍         | 1/21 [00:05<01:51,  5.58s/it]\n","Epoch (training) 5:  10%|▉         | 2/21 [00:08<01:18,  4.12s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:58:16. Total running time: 6min 0s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        4            342.755   2.24182     0.276131 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 5:  14%|█▍        | 3/21 [00:12<01:09,  3.89s/it]\n","Epoch (training) 5:  19%|█▉        | 4/21 [00:13<00:51,  3.03s/it]\n","Epoch (training) 5:  24%|██▍       | 5/21 [00:16<00:43,  2.73s/it]\n","Epoch (training) 5:  29%|██▊       | 6/21 [00:17<00:35,  2.34s/it]\n","Epoch (training) 5:  33%|███▎      | 7/21 [00:19<00:29,  2.09s/it]\n","Epoch (training) 5:  38%|███▊      | 8/21 [00:22<00:31,  2.42s/it]\n","Epoch (training) 5:  43%|████▎     | 9/21 [00:26<00:36,  3.04s/it]\n","Epoch (training) 5:  48%|████▊     | 10/21 [00:28<00:28,  2.63s/it]\n","Epoch (training) 5:  52%|█████▏    | 11/21 [00:30<00:23,  2.35s/it]\n","Epoch (training) 5:  57%|█████▋    | 12/21 [00:33<00:22,  2.47s/it]\n","Epoch (training) 5:  62%|██████▏   | 13/21 [00:35<00:18,  2.36s/it]\n","Epoch (training) 5:  67%|██████▋   | 14/21 [00:37<00:16,  2.42s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:58:46. Total running time: 6min 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        4            342.755   2.24182     0.276131 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 5:  71%|███████▏  | 15/21 [00:40<00:14,  2.45s/it]\n","Epoch (training) 5:  76%|███████▌  | 16/21 [00:42<00:12,  2.46s/it]\n","Epoch (training) 5:  81%|████████  | 17/21 [00:44<00:09,  2.32s/it]\n","Epoch (training) 5:  86%|████████▌ | 18/21 [00:47<00:06,  2.32s/it]\n","Epoch (training) 5:  90%|█████████ | 19/21 [00:48<00:04,  2.20s/it]\n","Epoch (training) 5:  95%|█████████▌| 20/21 [00:49<00:01,  1.64s/it]\n","Epoch (training) 5: 100%|██████████| 21/21 [00:49<00:00,  2.36s/it]\n","Epoch (test) 5:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 5:   9%|▉         | 1/11 [00:05<00:57,  5.78s/it]\n","Epoch (test) 5:  18%|█▊        | 2/11 [00:08<00:34,  3.84s/it]\n","Epoch (test) 5:  27%|██▋       | 3/11 [00:10<00:25,  3.19s/it]\n","Epoch (test) 5:  36%|███▋      | 4/11 [00:13<00:20,  2.88s/it]\n","Epoch (test) 5:  45%|████▌     | 5/11 [00:15<00:15,  2.65s/it]\n","Epoch (test) 5:  55%|█████▍    | 6/11 [00:19<00:15,  3.13s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:59:16. Total running time: 7min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        4            342.755   2.24182     0.276131 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 5:  64%|██████▎   | 7/11 [00:20<00:10,  2.61s/it]\n","Epoch (test) 5:  73%|███████▎  | 8/11 [00:22<00:07,  2.35s/it]\n","Epoch (test) 5:  82%|████████▏ | 9/11 [00:24<00:04,  2.27s/it]\n","Epoch (test) 5: 100%|██████████| 11/11 [00:24<00:00,  2.27s/it]\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00000_0_batch_size=64,epochs=10,lr=0.0003_2024-04-14_07-52-15/checkpoint_000004)\n","Epoch (training) 6:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 6:   5%|▍         | 1/21 [00:03<01:11,  3.58s/it]\n","Epoch (training) 6:  10%|▉         | 2/21 [00:05<00:52,  2.77s/it]\n","Epoch (training) 6:  14%|█▍        | 3/21 [00:07<00:41,  2.33s/it]\n","Epoch (training) 6:  19%|█▉        | 4/21 [00:09<00:36,  2.18s/it]\n","Epoch (training) 6:  24%|██▍       | 5/21 [00:12<00:40,  2.52s/it]\n","Epoch (training) 6:  29%|██▊       | 6/21 [00:16<00:42,  2.83s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 07:59:46. Total running time: 7min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        5            425.317   2.1443     0.316693 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                     |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                    |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                    |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                    |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 6:  33%|███▎      | 7/21 [00:20<00:45,  3.24s/it]\n","Epoch (training) 6:  38%|███▊      | 8/21 [00:22<00:38,  2.93s/it]\n","Epoch (training) 6:  43%|████▎     | 9/21 [00:25<00:34,  2.85s/it]\n","Epoch (training) 6:  48%|████▊     | 10/21 [00:27<00:29,  2.65s/it]\n","Epoch (training) 6:  52%|█████▏    | 11/21 [00:30<00:29,  2.90s/it]\n","Epoch (training) 6:  57%|█████▋    | 12/21 [00:32<00:23,  2.64s/it]\n","Epoch (training) 6:  62%|██████▏   | 13/21 [00:35<00:20,  2.50s/it]\n","Epoch (training) 6:  67%|██████▋   | 14/21 [00:37<00:17,  2.47s/it]\n","Epoch (training) 6:  71%|███████▏  | 15/21 [00:39<00:14,  2.34s/it]\n","Epoch (training) 6:  76%|███████▌  | 16/21 [00:42<00:12,  2.47s/it]\n","Epoch (training) 6:  81%|████████  | 17/21 [00:45<00:10,  2.72s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:00:16. Total running time: 8min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        5            425.317   2.1443     0.316693 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                     |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                    |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                    |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                    |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 6:  86%|████████▌ | 18/21 [00:47<00:07,  2.52s/it]\n","Epoch (training) 6:  90%|█████████ | 19/21 [00:49<00:04,  2.36s/it]\n","Epoch (training) 6:  95%|█████████▌| 20/21 [00:49<00:01,  1.75s/it]\n","Epoch (training) 6: 100%|██████████| 21/21 [00:50<00:00,  2.39s/it]\n","Epoch (test) 6:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 6:   9%|▉         | 1/11 [00:04<00:44,  4.41s/it]\n","Epoch (test) 6:  18%|█▊        | 2/11 [00:07<00:34,  3.81s/it]\n","Epoch (test) 6:  27%|██▋       | 3/11 [00:10<00:27,  3.41s/it]\n","Epoch (test) 6:  36%|███▋      | 4/11 [00:13<00:21,  3.00s/it]\n","Epoch (test) 6:  45%|████▌     | 5/11 [00:15<00:16,  2.68s/it]\n","Epoch (test) 6:  55%|█████▍    | 6/11 [00:18<00:13,  2.73s/it]\n","Epoch (test) 6:  64%|██████▎   | 7/11 [00:19<00:09,  2.32s/it]\n","Epoch (test) 6:  73%|███████▎  | 8/11 [00:21<00:07,  2.37s/it]\n","Epoch (test) 6:  82%|████████▏ | 9/11 [00:24<00:04,  2.49s/it]\n","Epoch (test) 6: 100%|██████████| 11/11 [00:24<00:00,  2.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:00:46. Total running time: 8min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        5            425.317   2.1443     0.316693 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                     |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                    |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                    |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                    |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00000_0_batch_size=64,epochs=10,lr=0.0003_2024-04-14_07-52-15/checkpoint_000005)\n","Epoch (training) 7:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 7:   5%|▍         | 1/21 [00:04<01:23,  4.19s/it]\n","Epoch (training) 7:  10%|▉         | 2/21 [00:08<01:15,  4.00s/it]\n","Epoch (training) 7:  14%|█▍        | 3/21 [00:11<01:04,  3.59s/it]\n","Epoch (training) 7:  19%|█▉        | 4/21 [00:13<00:52,  3.10s/it]\n","Epoch (training) 7:  24%|██▍       | 5/21 [00:16<00:46,  2.90s/it]\n","Epoch (training) 7:  29%|██▊       | 6/21 [00:17<00:37,  2.51s/it]\n","Epoch (training) 7:  33%|███▎      | 7/21 [00:20<00:35,  2.50s/it]\n","Epoch (training) 7:  38%|███▊      | 8/21 [00:23<00:33,  2.58s/it]\n","Epoch (training) 7:  43%|████▎     | 9/21 [00:25<00:31,  2.64s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:01:16. Total running time: 9min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        6            504.455   2.22881     0.312012 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 7:  48%|████▊     | 10/21 [00:27<00:26,  2.40s/it]\n","Epoch (training) 7:  52%|█████▏    | 11/21 [00:29<00:22,  2.27s/it]\n","Epoch (training) 7:  57%|█████▋    | 12/21 [00:31<00:18,  2.05s/it]\n","Epoch (training) 7:  62%|██████▏   | 13/21 [00:34<00:18,  2.31s/it]\n","Epoch (training) 7:  67%|██████▋   | 14/21 [00:36<00:16,  2.37s/it]\n","Epoch (training) 7:  71%|███████▏  | 15/21 [00:39<00:15,  2.50s/it]\n","Epoch (training) 7:  76%|███████▌  | 16/21 [00:41<00:11,  2.24s/it]\n","Epoch (training) 7:  81%|████████  | 17/21 [00:44<00:10,  2.56s/it]\n","Epoch (training) 7:  86%|████████▌ | 18/21 [00:47<00:08,  2.69s/it]\n","Epoch (training) 7:  90%|█████████ | 19/21 [00:49<00:05,  2.60s/it]\n","Epoch (training) 7:  95%|█████████▌| 20/21 [00:50<00:01,  1.92s/it]\n","Epoch (training) 7: 100%|██████████| 21/21 [00:50<00:00,  2.40s/it]\n","Epoch (test) 7:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 7:   9%|▉         | 1/11 [00:05<00:54,  5.46s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:01:46. Total running time: 9min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        6            504.455   2.22881     0.312012 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 7:  18%|█▊        | 2/11 [00:07<00:33,  3.72s/it]\n","Epoch (test) 7:  27%|██▋       | 3/11 [00:10<00:24,  3.12s/it]\n","Epoch (test) 7:  36%|███▋      | 4/11 [00:12<00:19,  2.84s/it]\n","Epoch (test) 7:  45%|████▌     | 5/11 [00:15<00:16,  2.77s/it]\n","Epoch (test) 7:  55%|█████▍    | 6/11 [00:19<00:15,  3.12s/it]\n","Epoch (test) 7:  64%|██████▎   | 7/11 [00:20<00:10,  2.58s/it]\n","Epoch (test) 7:  73%|███████▎  | 8/11 [00:22<00:07,  2.33s/it]\n","Epoch (test) 7:  82%|████████▏ | 9/11 [00:24<00:04,  2.25s/it]\n","Epoch (test) 7: 100%|██████████| 11/11 [00:24<00:00,  2.25s/it]\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00000_0_batch_size=64,epochs=10,lr=0.0003_2024-04-14_07-52-15/checkpoint_000006)\n","Epoch (training) 8:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 8:   5%|▍         | 1/21 [00:05<01:46,  5.31s/it]\n","Epoch (training) 8:  10%|▉         | 2/21 [00:07<01:01,  3.24s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:02:16. Total running time: 10min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        7            583.544   2.37068     0.297972 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 8:  14%|█▍        | 3/21 [00:09<00:47,  2.64s/it]\n","Epoch (training) 8:  19%|█▉        | 4/21 [00:11<00:43,  2.53s/it]\n","Epoch (training) 8:  24%|██▍       | 5/21 [00:13<00:37,  2.36s/it]\n","Epoch (training) 8:  29%|██▊       | 6/21 [00:16<00:38,  2.60s/it]\n","Epoch (training) 8:  33%|███▎      | 7/21 [00:20<00:43,  3.07s/it]\n","Epoch (training) 8:  38%|███▊      | 8/21 [00:22<00:34,  2.67s/it]\n","Epoch (training) 8:  43%|████▎     | 9/21 [00:24<00:29,  2.49s/it]\n","Epoch (training) 8:  48%|████▊     | 10/21 [00:26<00:25,  2.29s/it]\n","Epoch (training) 8:  52%|█████▏    | 11/21 [00:29<00:25,  2.57s/it]\n","Epoch (training) 8:  57%|█████▋    | 12/21 [00:32<00:23,  2.62s/it]\n","Epoch (training) 8:  62%|██████▏   | 13/21 [00:34<00:20,  2.56s/it]\n","Epoch (training) 8:  67%|██████▋   | 14/21 [00:36<00:15,  2.27s/it]\n","Epoch (training) 8:  71%|███████▏  | 15/21 [00:38<00:12,  2.14s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:02:46. Total running time: 10min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        7            583.544   2.37068     0.297972 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 8:  76%|███████▌  | 16/21 [00:41<00:12,  2.49s/it]\n","Epoch (training) 8:  81%|████████  | 17/21 [00:43<00:09,  2.38s/it]\n","Epoch (training) 8:  86%|████████▌ | 18/21 [00:48<00:09,  3.17s/it]\n","Epoch (training) 8:  90%|█████████ | 19/21 [00:50<00:05,  2.75s/it]\n","Epoch (training) 8:  95%|█████████▌| 20/21 [00:50<00:02,  2.02s/it]\n","Epoch (training) 8: 100%|██████████| 21/21 [00:50<00:00,  2.42s/it]\n","Epoch (test) 8:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 8:   9%|▉         | 1/11 [00:04<00:43,  4.38s/it]\n","Epoch (test) 8:  18%|█▊        | 2/11 [00:06<00:29,  3.27s/it]\n","Epoch (test) 8:  27%|██▋       | 3/11 [00:10<00:25,  3.21s/it]\n","Epoch (test) 8:  36%|███▋      | 4/11 [00:13<00:22,  3.21s/it]\n","Epoch (test) 8:  45%|████▌     | 5/11 [00:15<00:16,  2.82s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:03:16. Total running time: 11min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        7            583.544   2.37068     0.297972 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 8:  55%|█████▍    | 6/11 [00:18<00:14,  2.84s/it]\n","Epoch (test) 8:  64%|██████▎   | 7/11 [00:19<00:09,  2.40s/it]\n","Epoch (test) 8:  73%|███████▎  | 8/11 [00:21<00:06,  2.20s/it]\n","Epoch (test) 8:  82%|████████▏ | 9/11 [00:24<00:04,  2.32s/it]\n","Epoch (test) 8: 100%|██████████| 11/11 [00:24<00:00,  2.20s/it]\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00000_0_batch_size=64,epochs=10,lr=0.0003_2024-04-14_07-52-15/checkpoint_000007)\n","Epoch (training) 9:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 9:   5%|▍         | 1/21 [00:04<01:25,  4.27s/it]\n","Epoch (training) 9:  10%|▉         | 2/21 [00:07<01:07,  3.54s/it]\n","Epoch (training) 9:  14%|█▍        | 3/21 [00:09<00:53,  2.96s/it]\n","Epoch (training) 9:  19%|█▉        | 4/21 [00:12<00:49,  2.93s/it]\n","Epoch (training) 9:  24%|██▍       | 5/21 [00:15<00:48,  3.04s/it]\n","Epoch (training) 9:  29%|██▊       | 6/21 [00:17<00:39,  2.66s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:03:46. Total running time: 11min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        8            662.826   2.3095     0.310452 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                     |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                    |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                    |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                    |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 9:  33%|███▎      | 7/21 [00:20<00:39,  2.85s/it]\n","Epoch (training) 9:  38%|███▊      | 8/21 [00:22<00:32,  2.51s/it]\n","Epoch (training) 9:  43%|████▎     | 9/21 [00:24<00:27,  2.25s/it]\n","Epoch (training) 9:  48%|████▊     | 10/21 [00:27<00:26,  2.39s/it]\n","Epoch (training) 9:  52%|█████▏    | 11/21 [00:29<00:23,  2.33s/it]\n","Epoch (training) 9:  57%|█████▋    | 12/21 [00:30<00:18,  2.11s/it]\n","Epoch (training) 9:  62%|██████▏   | 13/21 [00:32<00:16,  2.05s/it]\n","Epoch (training) 9:  67%|██████▋   | 14/21 [00:35<00:16,  2.38s/it]\n","Epoch (training) 9:  71%|███████▏  | 15/21 [00:38<00:14,  2.44s/it]\n","Epoch (training) 9:  76%|███████▌  | 16/21 [00:41<00:13,  2.65s/it]\n","Epoch (training) 9:  81%|████████  | 17/21 [00:44<00:10,  2.72s/it]\n","Epoch (training) 9:  86%|████████▌ | 18/21 [00:47<00:08,  2.76s/it]\n","Epoch (training) 9:  90%|█████████ | 19/21 [00:49<00:04,  2.48s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:04:16. Total running time: 12min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        8            662.826   2.3095     0.310452 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                     |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                    |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                    |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                    |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 9:  95%|█████████▌| 20/21 [00:49<00:01,  1.83s/it]\n","Epoch (training) 9: 100%|██████████| 21/21 [00:49<00:00,  2.37s/it]\n","Epoch (test) 9:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 9:   9%|▉         | 1/11 [00:04<00:44,  4.43s/it]\n","Epoch (test) 9:  18%|█▊        | 2/11 [00:07<00:35,  3.90s/it]\n","Epoch (test) 9:  27%|██▋       | 3/11 [00:10<00:26,  3.35s/it]\n","Epoch (test) 9:  36%|███▋      | 4/11 [00:13<00:20,  2.98s/it]\n","Epoch (test) 9:  45%|████▌     | 5/11 [00:15<00:16,  2.69s/it]\n","Epoch (test) 9:  55%|█████▍    | 6/11 [00:18<00:13,  2.76s/it]\n","Epoch (test) 9:  64%|██████▎   | 7/11 [00:19<00:09,  2.42s/it]\n","Epoch (test) 9:  73%|███████▎  | 8/11 [00:22<00:07,  2.43s/it]\n","Epoch (test) 9:  82%|████████▏ | 9/11 [00:24<00:04,  2.44s/it]\n","Epoch (test) 9: 100%|██████████| 11/11 [00:24<00:00,  2.26s/it]\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00000_0_batch_size=64,epochs=10,lr=0.0003_2024-04-14_07-52-15/checkpoint_000008)\n","Epoch (training) 10:   0%|          | 0/21 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:04:46. Total running time: 12min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        9            741.529   2.72982     0.294852 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 10:   5%|▍         | 1/21 [00:03<01:12,  3.64s/it]\n","Epoch (training) 10:  10%|▉         | 2/21 [00:05<00:50,  2.64s/it]\n","Epoch (training) 10:  14%|█▍        | 3/21 [00:08<00:51,  2.83s/it]\n","Epoch (training) 10:  19%|█▉        | 4/21 [00:11<00:48,  2.88s/it]\n","Epoch (training) 10:  24%|██▍       | 5/21 [00:13<00:42,  2.64s/it]\n","Epoch (training) 10:  29%|██▊       | 6/21 [00:16<00:38,  2.55s/it]\n","Epoch (training) 10:  33%|███▎      | 7/21 [00:19<00:39,  2.80s/it]\n","Epoch (training) 10:  38%|███▊      | 8/21 [00:23<00:40,  3.09s/it]\n","Epoch (training) 10:  43%|████▎     | 9/21 [00:25<00:33,  2.79s/it]\n","Epoch (training) 10:  48%|████▊     | 10/21 [00:27<00:28,  2.63s/it]\n","Epoch (training) 10:  52%|█████▏    | 11/21 [00:29<00:25,  2.53s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:05:16. Total running time: 13min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        9            741.529   2.72982     0.294852 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 10:  57%|█████▋    | 12/21 [00:32<00:22,  2.50s/it]\n","Epoch (training) 10:  62%|██████▏   | 13/21 [00:34<00:20,  2.50s/it]\n","Epoch (training) 10:  67%|██████▋   | 14/21 [00:37<00:17,  2.56s/it]\n","Epoch (training) 10:  71%|███████▏  | 15/21 [00:40<00:16,  2.83s/it]\n","Epoch (training) 10:  76%|███████▌  | 16/21 [00:42<00:12,  2.54s/it]\n","Epoch (training) 10:  81%|████████  | 17/21 [00:45<00:10,  2.61s/it]\n","Epoch (training) 10:  86%|████████▌ | 18/21 [00:47<00:06,  2.31s/it]\n","Epoch (training) 10:  90%|█████████ | 19/21 [00:49<00:04,  2.23s/it]\n","Epoch (training) 10:  95%|█████████▌| 20/21 [00:49<00:01,  1.66s/it]\n","Epoch (training) 10: 100%|██████████| 21/21 [00:49<00:00,  2.37s/it]\n","Epoch (test) 10:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 10:   9%|▉         | 1/11 [00:05<00:54,  5.44s/it]\n","Epoch (test) 10:  18%|█▊        | 2/11 [00:07<00:33,  3.71s/it]\n","Epoch (test) 10:  27%|██▋       | 3/11 [00:10<00:24,  3.12s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:05:46. Total running time: 13min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   RUNNING                        10                       64              0.000304055        9            741.529   2.72982     0.294852 |\n","| TorchTrainer_e8bbe_00001   PENDING                        20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00002   PENDING                        20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                        10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                        10                       32              0.00185077                                                     |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 10:  36%|███▋      | 4/11 [00:12<00:19,  2.85s/it]\n","Epoch (test) 10:  45%|████▌     | 5/11 [00:15<00:16,  2.78s/it]\n","Epoch (test) 10:  55%|█████▍    | 6/11 [00:19<00:15,  3.13s/it]\n","Epoch (test) 10:  64%|██████▎   | 7/11 [00:20<00:10,  2.59s/it]\n","Epoch (test) 10:  73%|███████▎  | 8/11 [00:22<00:07,  2.34s/it]\n","Epoch (test) 10:  82%|████████▏ | 9/11 [00:24<00:04,  2.26s/it]\n","Epoch (test) 10: 100%|██████████| 11/11 [00:24<00:00,  2.25s/it]\n","\u001b[36m(RayTrainWorker pid=20650)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00000_0_batch_size=64,epochs=10,lr=0.0003_2024-04-14_07-52-15/checkpoint_000009)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial TorchTrainer_e8bbe_00000 completed after 10 iterations at 2024-04-14 08:06:06. Total running time: 13min 51s\n","+---------------------------------------------------------------+\n","| Trial TorchTrainer_e8bbe_00000 result                         |\n","+---------------------------------------------------------------+\n","| checkpoint_dir_name                         checkpoint_000009 |\n","| time_this_iter_s                                     79.49463 |\n","| time_total_s                                        821.02326 |\n","| training_iteration                                         10 |\n","| accuracy                                              0.29485 |\n","| loss                                                  3.12129 |\n","| summary/epoch/0                                           1.0 |\n","| summary/epoch/1                                           2.0 |\n","| summary/epoch/2                                           3.0 |\n","| summary/epoch/3                                           4.0 |\n","| summary/epoch/4                                           5.0 |\n","| summary/epoch/5                                           6.0 |\n","| summary/epoch/6                                           7.0 |\n","| summary/epoch/7                                           8.0 |\n","| summary/epoch/8                                           9.0 |\n","| summary/epoch/9                                          10.0 |\n","| summary/train_acc/0                       0.17486338797814208 |\n","| summary/train_acc/1                        0.2529274004683841 |\n","| summary/train_acc/2                       0.30601092896174864 |\n","| summary/train_acc/3                        0.3700234192037471 |\n","| summary/train_acc/4                        0.4613583138173302 |\n","| summary/train_acc/5                        0.4707259953161593 |\n","| summary/train_acc/6                        0.4847775175644028 |\n","| summary/train_acc/7                        0.5511319281811085 |\n","| summary/train_acc/8                        0.6018735362997658 |\n","| summary/train_acc/9                        0.5909445745511319 |\n","| summary/train_loss/0                        2.620093595413935 |\n","| summary/train_loss/1                        2.222576867966425 |\n","| summary/train_loss/2                        2.017661770184835 |\n","| summary/train_loss/3                       1.9042224884033203 |\n","| summary/train_loss/4                        1.688072227296375 |\n","| summary/train_loss/5                       1.6561498244603474 |\n","| summary/train_loss/6                       1.5934557857967557 |\n","| summary/train_loss/7                        1.296573661622547 |\n","| summary/train_loss/8                         1.22398518096833 |\n","| summary/train_loss/9                       1.2447895322527205 |\n","| summary/val_acc/0                         0.11076443057722309 |\n","| summary/val_acc/1                          0.1856474258970359 |\n","| summary/val_acc/2                         0.26521060842433697 |\n","| summary/val_acc/3                         0.27613104524180965 |\n","| summary/val_acc/4                          0.3166926677067083 |\n","| summary/val_acc/5                            0.31201248049922 |\n","| summary/val_acc/6                         0.29797191887675506 |\n","| summary/val_acc/7                         0.31045241809672386 |\n","| summary/val_acc/8                          0.2948517940717629 |\n","| summary/val_acc/9                          0.2948517940717629 |\n","| summary/val_loss/0                          4.395915855060924 |\n","| summary/val_loss/1                          2.429883285002275 |\n","| summary/val_loss/2                         2.9671179164539683 |\n","| summary/val_loss/3                         2.2418162551793186 |\n","| summary/val_loss/4                         2.1442975889552724 |\n","| summary/val_loss/5                          2.228813041340221 |\n","| summary/val_loss/6                         2.3706761706959116 |\n","| summary/val_loss/7                          2.309501962228255 |\n","| summary/val_loss/8                          2.729822180487893 |\n","| summary/val_loss/9                         3.1212864355607466 |\n","+---------------------------------------------------------------+\n","\n","Trial TorchTrainer_e8bbe_00001 started with configuration:\n","+-----------------------------------------------------------------+\n","| Trial TorchTrainer_e8bbe_00001 config                           |\n","+-----------------------------------------------------------------+\n","| train_loop_config/batch_size                                 32 |\n","| train_loop_config/epochs                                     20 |\n","| train_loop_config/lr                      0.0018874042204500875 |\n","| train_loop_config/train_test_idx           ...20, 11731, 1157]) |\n","+-----------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(TorchTrainer pid=20570)\u001b[0m Started distributed worker processes: \n","\u001b[36m(TorchTrainer pid=20570)\u001b[0m - (ip=172.28.0.12, pid=24142) world_rank=0, local_rank=0, node_rank=0\n","\u001b[36m(RayTrainWorker pid=24142)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[36m(RayTrainWorker pid=24142)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n","\u001b[36m(RayTrainWorker pid=24142)\u001b[0m 2024-04-14 08:06:13.973409: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(RayTrainWorker pid=24142)\u001b[0m 2024-04-14 08:06:13.973462: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(RayTrainWorker pid=24142)\u001b[0m 2024-04-14 08:06:13.974891: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(RayTrainWorker pid=24142)\u001b[0m 2024-04-14 08:06:15.369366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 1 TERMINATED | 1 RUNNING | 3 PENDING\n","Current time: 2024-04-14 08:06:16. Total running time: 14min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00001   RUNNING                          20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10            821.023   3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00002   PENDING                          20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=24142)\u001b[0m Moving model to device: cuda:0\n","Epoch (training) 1:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 1:   5%|▍         | 1/21 [00:08<02:44,  8.21s/it]\n","Epoch (training) 1:  10%|▉         | 2/21 [00:10<01:29,  4.69s/it]\n","Epoch (training) 1:  14%|█▍        | 3/21 [00:12<01:06,  3.67s/it]\n","Epoch (training) 1:  19%|█▉        | 4/21 [00:14<00:49,  2.93s/it]\n","Epoch (training) 1:  24%|██▍       | 5/21 [00:16<00:40,  2.51s/it]\n","Epoch (training) 1:  29%|██▊       | 6/21 [00:19<00:38,  2.59s/it]\n","Epoch (training) 1:  33%|███▎      | 7/21 [00:22<00:39,  2.80s/it]\n","Epoch (training) 1:  38%|███▊      | 8/21 [00:24<00:34,  2.67s/it]\n","Epoch (training) 1:  43%|████▎     | 9/21 [00:26<00:29,  2.42s/it]\n","Epoch (training) 1:  48%|████▊     | 10/21 [00:28<00:25,  2.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 TERMINATED | 1 RUNNING | 3 PENDING\n","Current time: 2024-04-14 08:06:47. Total running time: 14min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00001   RUNNING                          20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10            821.023   3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00002   PENDING                          20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  52%|█████▏    | 11/21 [00:31<00:25,  2.57s/it]\n","Epoch (training) 1:  57%|█████▋    | 12/21 [00:36<00:27,  3.10s/it]\n","Epoch (training) 1:  62%|██████▏   | 13/21 [00:38<00:22,  2.79s/it]\n","Epoch (training) 1:  67%|██████▋   | 14/21 [00:41<00:20,  2.99s/it]\n","Epoch (training) 1:  71%|███████▏  | 15/21 [00:43<00:16,  2.71s/it]\n","Epoch (training) 1:  76%|███████▌  | 16/21 [00:45<00:11,  2.40s/it]\n","Epoch (training) 1:  81%|████████  | 17/21 [00:48<00:10,  2.67s/it]\n","Epoch (training) 1:  86%|████████▌ | 18/21 [00:51<00:08,  2.73s/it]\n","Epoch (training) 1:  90%|█████████ | 19/21 [00:54<00:05,  2.82s/it]\n","Epoch (training) 1:  95%|█████████▌| 20/21 [00:55<00:02,  2.07s/it]\n","Epoch (training) 1: 100%|██████████| 21/21 [00:55<00:00,  2.64s/it]\n","Epoch (test) 1:   0%|          | 0/11 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 TERMINATED | 1 RUNNING | 3 PENDING\n","Current time: 2024-04-14 08:07:17. Total running time: 15min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00001   RUNNING                          20                       32              0.0018874                                                      |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10            821.023   3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00002   PENDING                          20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 1:   9%|▉         | 1/11 [00:04<00:44,  4.42s/it]\n","Epoch (test) 1:  18%|█▊        | 2/11 [00:07<00:30,  3.39s/it]\n","Epoch (test) 1:  27%|██▋       | 3/11 [00:10<00:27,  3.45s/it]\n","Epoch (test) 1:  36%|███▋      | 4/11 [00:13<00:22,  3.24s/it]\n","Epoch (test) 1:  45%|████▌     | 5/11 [00:15<00:17,  2.85s/it]\n","Epoch (test) 1:  55%|█████▍    | 6/11 [00:18<00:14,  2.86s/it]\n","Epoch (test) 1:  64%|██████▎   | 7/11 [00:20<00:09,  2.41s/it]\n","Epoch (test) 1:  73%|███████▎  | 8/11 [00:21<00:06,  2.20s/it]\n","Epoch (test) 1:  82%|████████▏ | 9/11 [00:24<00:04,  2.43s/it]\n","Epoch (test) 1: 100%|██████████| 11/11 [00:24<00:00,  2.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial TorchTrainer_e8bbe_00001 completed after 1 iterations at 2024-04-14 08:07:45. Total running time: 15min 30s\n","+---------------------------------------------------------------+\n","| Trial TorchTrainer_e8bbe_00001 result                         |\n","+---------------------------------------------------------------+\n","| checkpoint_dir_name                         checkpoint_000000 |\n","| time_this_iter_s                                      98.6708 |\n","| time_total_s                                          98.6708 |\n","| training_iteration                                          1 |\n","| accuracy                                              0.10296 |\n","| loss                                                   4.9129 |\n","| summary/epoch/0                                           1.0 |\n","| summary/train_acc/0                       0.16315378610460576 |\n","| summary/train_loss/0                       2.5790883018856956 |\n","| summary/val_acc/0                          0.1029641185647426 |\n","| summary/val_loss/0                          4.912896849892356 |\n","+---------------------------------------------------------------+\n","\n","Trial TorchTrainer_e8bbe_00002 started with configuration:\n","+----------------------------------------------------------------+\n","| Trial TorchTrainer_e8bbe_00002 config                          |\n","+----------------------------------------------------------------+\n","| train_loop_config/batch_size                                32 |\n","| train_loop_config/epochs                                    20 |\n","| train_loop_config/lr                      0.002030709845280093 |\n","| train_loop_config/train_test_idx          ...20, 11731, 1157]) |\n","+----------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=24142)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00001_1_batch_size=32,epochs=20,lr=0.0019_2024-04-14_07-52-15/checkpoint_000000)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:07:47. Total running time: 15min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(TorchTrainer pid=20570)\u001b[0m Started distributed worker processes: \n","\u001b[36m(TorchTrainer pid=20570)\u001b[0m - (ip=172.28.0.12, pid=24730) world_rank=0, local_rank=0, node_rank=0\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m 2024-04-14 08:07:51.558442: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m 2024-04-14 08:07:51.558511: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m 2024-04-14 08:07:51.561533: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m 2024-04-14 08:07:53.560392: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Moving model to device: cuda:0\n","Epoch (training) 1:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 1:   5%|▍         | 1/21 [00:05<01:51,  5.60s/it]\n","Epoch (training) 1:  10%|▉         | 2/21 [00:08<01:16,  4.00s/it]\n","Epoch (training) 1:  14%|█▍        | 3/21 [00:11<00:59,  3.33s/it]\n","Epoch (training) 1:  19%|█▉        | 4/21 [00:12<00:47,  2.77s/it]\n","Epoch (training) 1:  24%|██▍       | 5/21 [00:16<00:50,  3.16s/it]\n","Epoch (training) 1:  29%|██▊       | 6/21 [00:19<00:45,  3.00s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:08:17. Total running time: 16min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  33%|███▎      | 7/21 [00:21<00:36,  2.62s/it]\n","Epoch (training) 1:  38%|███▊      | 8/21 [00:24<00:37,  2.89s/it]\n","Epoch (training) 1:  43%|████▎     | 9/21 [00:27<00:35,  2.93s/it]\n","Epoch (training) 1:  48%|████▊     | 10/21 [00:29<00:28,  2.62s/it]\n","Epoch (training) 1:  52%|█████▏    | 11/21 [00:31<00:25,  2.51s/it]\n","Epoch (training) 1:  57%|█████▋    | 12/21 [00:33<00:20,  2.27s/it]\n","Epoch (training) 1:  62%|██████▏   | 13/21 [00:35<00:16,  2.08s/it]\n","Epoch (training) 1:  67%|██████▋   | 14/21 [00:37<00:13,  1.99s/it]\n","Epoch (training) 1:  71%|███████▏  | 15/21 [00:39<00:12,  2.03s/it]\n","Epoch (training) 1:  76%|███████▌  | 16/21 [00:42<00:11,  2.38s/it]\n","Epoch (training) 1:  81%|████████  | 17/21 [00:45<00:09,  2.48s/it]\n","Epoch (training) 1:  86%|████████▌ | 18/21 [00:47<00:07,  2.45s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:08:47. Total running time: 16min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071                                                     |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  90%|█████████ | 19/21 [00:51<00:05,  2.76s/it]\n","Epoch (training) 1:  95%|█████████▌| 20/21 [00:51<00:02,  2.03s/it]\n","Epoch (training) 1: 100%|██████████| 21/21 [00:51<00:00,  2.46s/it]\n","Epoch (test) 1:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 1:   9%|▉         | 1/11 [00:05<00:53,  5.33s/it]\n","Epoch (test) 1:  18%|█▊        | 2/11 [00:08<00:35,  3.98s/it]\n","Epoch (test) 1:  27%|██▋       | 3/11 [00:10<00:26,  3.26s/it]\n","Epoch (test) 1:  36%|███▋      | 4/11 [00:13<00:20,  2.93s/it]\n","Epoch (test) 1:  45%|████▌     | 5/11 [00:15<00:15,  2.66s/it]\n","Epoch (test) 1:  55%|█████▍    | 6/11 [00:18<00:14,  2.89s/it]\n","Epoch (test) 1:  64%|██████▎   | 7/11 [00:20<00:10,  2.60s/it]\n","Epoch (test) 1:  73%|███████▎  | 8/11 [00:22<00:07,  2.46s/it]\n","Epoch (test) 1:  82%|████████▏ | 9/11 [00:24<00:04,  2.33s/it]\n","Epoch (test) 1: 100%|██████████| 11/11 [00:25<00:00,  2.28s/it]\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00002_2_batch_size=32,epochs=20,lr=0.0020_2024-04-14_07-52-15/checkpoint_000000)\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:09:17. Total running time: 17min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         1            91.4928   4.5178      0.118565 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 2:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 2:   5%|▍         | 1/21 [00:04<01:31,  4.57s/it]\n","Epoch (training) 2:  10%|▉         | 2/21 [00:07<01:11,  3.76s/it]\n","Epoch (training) 2:  14%|█▍        | 3/21 [00:09<00:53,  2.97s/it]\n","Epoch (training) 2:  19%|█▉        | 4/21 [00:12<00:47,  2.82s/it]\n","Epoch (training) 2:  24%|██▍       | 5/21 [00:15<00:44,  2.78s/it]\n","Epoch (training) 2:  29%|██▊       | 6/21 [00:17<00:37,  2.49s/it]\n","Epoch (training) 2:  33%|███▎      | 7/21 [00:21<00:42,  3.05s/it]\n","Epoch (training) 2:  38%|███▊      | 8/21 [00:24<00:40,  3.12s/it]\n","Epoch (training) 2:  43%|████▎     | 9/21 [00:26<00:32,  2.68s/it]\n","Epoch (training) 2:  48%|████▊     | 10/21 [00:28<00:27,  2.47s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:09:47. Total running time: 17min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         1            91.4928   4.5178      0.118565 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 2:  52%|█████▏    | 11/21 [00:30<00:25,  2.52s/it]\n","Epoch (training) 2:  57%|█████▋    | 12/21 [00:32<00:20,  2.31s/it]\n","Epoch (training) 2:  62%|██████▏   | 13/21 [00:36<00:21,  2.74s/it]\n","Epoch (training) 2:  67%|██████▋   | 14/21 [00:38<00:18,  2.63s/it]\n","Epoch (training) 2:  71%|███████▏  | 15/21 [00:41<00:15,  2.65s/it]\n","Epoch (training) 2:  76%|███████▌  | 16/21 [00:43<00:12,  2.57s/it]\n","Epoch (training) 2:  81%|████████  | 17/21 [00:45<00:09,  2.38s/it]\n","Epoch (training) 2:  86%|████████▌ | 18/21 [00:47<00:06,  2.19s/it]\n","Epoch (training) 2:  90%|█████████ | 19/21 [00:50<00:04,  2.33s/it]\n","Epoch (training) 2:  95%|█████████▌| 20/21 [00:50<00:01,  1.73s/it]\n","Epoch (training) 2: 100%|██████████| 21/21 [00:50<00:00,  2.42s/it]\n","Epoch (test) 2:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 2:   9%|▉         | 1/11 [00:04<00:48,  4.85s/it]\n","Epoch (test) 2:  18%|█▊        | 2/11 [00:07<00:31,  3.45s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:10:17. Total running time: 18min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         1            91.4928   4.5178      0.118565 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 2:  27%|██▋       | 3/11 [00:09<00:23,  2.98s/it]\n","Epoch (test) 2:  36%|███▋      | 4/11 [00:12<00:19,  2.82s/it]\n","Epoch (test) 2:  45%|████▌     | 5/11 [00:15<00:17,  2.91s/it]\n","Epoch (test) 2:  55%|█████▍    | 6/11 [00:18<00:15,  3.04s/it]\n","Epoch (test) 2:  64%|██████▎   | 7/11 [00:20<00:10,  2.53s/it]\n","Epoch (test) 2:  73%|███████▎  | 8/11 [00:21<00:06,  2.29s/it]\n","Epoch (test) 2:  82%|████████▏ | 9/11 [00:24<00:04,  2.23s/it]\n","Epoch (test) 2: 100%|██████████| 11/11 [00:24<00:00,  2.20s/it]\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00002_2_batch_size=32,epochs=20,lr=0.0020_2024-04-14_07-52-15/checkpoint_000001)\n","Epoch (training) 3:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 3:   5%|▍         | 1/21 [00:05<01:50,  5.53s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:10:47. Total running time: 18min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         2           175.993    3.63272     0.266771 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 3:  10%|▉         | 2/21 [00:07<01:05,  3.43s/it]\n","Epoch (training) 3:  14%|█▍        | 3/21 [00:10<00:54,  3.01s/it]\n","Epoch (training) 3:  19%|█▉        | 4/21 [00:13<00:51,  3.03s/it]\n","Epoch (training) 3:  24%|██▍       | 5/21 [00:15<00:45,  2.82s/it]\n","Epoch (training) 3:  29%|██▊       | 6/21 [00:18<00:40,  2.72s/it]\n","Epoch (training) 3:  33%|███▎      | 7/21 [00:20<00:36,  2.60s/it]\n","Epoch (training) 3:  38%|███▊      | 8/21 [00:23<00:34,  2.62s/it]\n","Epoch (training) 3:  43%|████▎     | 9/21 [00:25<00:30,  2.55s/it]\n","Epoch (training) 3:  48%|████▊     | 10/21 [00:28<00:30,  2.79s/it]\n","Epoch (training) 3:  52%|█████▏    | 11/21 [00:30<00:25,  2.51s/it]\n","Epoch (training) 3:  57%|█████▋    | 12/21 [00:32<00:20,  2.24s/it]\n","Epoch (training) 3:  62%|██████▏   | 13/21 [00:34<00:17,  2.23s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:11:17. Total running time: 19min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         2           175.993    3.63272     0.266771 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 3:  67%|██████▋   | 14/21 [00:36<00:14,  2.05s/it]\n","Epoch (training) 3:  71%|███████▏  | 15/21 [00:38<00:13,  2.19s/it]\n","Epoch (training) 3:  76%|███████▌  | 16/21 [00:42<00:12,  2.56s/it]\n","Epoch (training) 3:  81%|████████  | 17/21 [00:44<00:10,  2.57s/it]\n","Epoch (training) 3:  86%|████████▌ | 18/21 [00:47<00:07,  2.57s/it]\n","Epoch (training) 3:  90%|█████████ | 19/21 [00:49<00:04,  2.44s/it]\n","Epoch (training) 3:  95%|█████████▌| 20/21 [00:49<00:01,  1.81s/it]\n","Epoch (training) 3: 100%|██████████| 21/21 [00:49<00:00,  2.38s/it]\n","Epoch (test) 3:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 3:   9%|▉         | 1/11 [00:04<00:42,  4.26s/it]\n","Epoch (test) 3:  18%|█▊        | 2/11 [00:07<00:34,  3.80s/it]\n","Epoch (test) 3:  27%|██▋       | 3/11 [00:10<00:27,  3.39s/it]\n","Epoch (test) 3:  36%|███▋      | 4/11 [00:13<00:20,  2.99s/it]\n","Epoch (test) 3:  45%|████▌     | 5/11 [00:15<00:15,  2.65s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:11:47. Total running time: 19min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         2           175.993    3.63272     0.266771 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 3:  55%|█████▍    | 6/11 [00:17<00:13,  2.71s/it]\n","Epoch (test) 3:  64%|██████▎   | 7/11 [00:19<00:09,  2.31s/it]\n","Epoch (test) 3:  73%|███████▎  | 8/11 [00:21<00:07,  2.37s/it]\n","Epoch (test) 3:  82%|████████▏ | 9/11 [00:24<00:04,  2.49s/it]\n","Epoch (test) 3: 100%|██████████| 11/11 [00:24<00:00,  2.25s/it]\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00002_2_batch_size=32,epochs=20,lr=0.0020_2024-04-14_07-52-15/checkpoint_000002)\n","Epoch (training) 4:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 4:   5%|▍         | 1/21 [00:03<01:13,  3.70s/it]\n","Epoch (training) 4:  10%|▉         | 2/21 [00:05<00:49,  2.61s/it]\n","Epoch (training) 4:  14%|█▍        | 3/21 [00:08<00:46,  2.59s/it]\n","Epoch (training) 4:  19%|█▉        | 4/21 [00:11<00:47,  2.80s/it]\n","Epoch (training) 4:  24%|██▍       | 5/21 [00:13<00:42,  2.65s/it]\n","Epoch (training) 4:  29%|██▊       | 6/21 [00:15<00:33,  2.27s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:12:17. Total running time: 20min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         3           254.745    2.86462     0.224649 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 4:  33%|███▎      | 7/21 [00:17<00:32,  2.34s/it]\n","Epoch (training) 4:  38%|███▊      | 8/21 [00:19<00:29,  2.25s/it]\n","Epoch (training) 4:  43%|████▎     | 9/21 [00:23<00:33,  2.78s/it]\n","Epoch (training) 4:  48%|████▊     | 10/21 [00:27<00:33,  3.01s/it]\n","Epoch (training) 4:  52%|█████▏    | 11/21 [00:28<00:25,  2.59s/it]\n","Epoch (training) 4:  57%|█████▋    | 12/21 [00:31<00:24,  2.74s/it]\n","Epoch (training) 4:  62%|██████▏   | 13/21 [00:34<00:20,  2.58s/it]\n","Epoch (training) 4:  67%|██████▋   | 14/21 [00:36<00:17,  2.51s/it]\n","Epoch (training) 4:  71%|███████▏  | 15/21 [00:40<00:17,  2.91s/it]\n","Epoch (training) 4:  76%|███████▌  | 16/21 [00:43<00:14,  2.88s/it]\n","Epoch (training) 4:  81%|████████  | 17/21 [00:45<00:10,  2.74s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:12:47. Total running time: 20min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         3           254.745    2.86462     0.224649 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 4:  86%|████████▌ | 18/21 [00:47<00:07,  2.49s/it]\n","Epoch (training) 4:  90%|█████████ | 19/21 [00:49<00:04,  2.33s/it]\n","Epoch (training) 4:  95%|█████████▌| 20/21 [00:49<00:01,  1.73s/it]\n","Epoch (training) 4: 100%|██████████| 21/21 [00:49<00:00,  2.38s/it]\n","Epoch (test) 4:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 4:   9%|▉         | 1/11 [00:05<00:58,  5.83s/it]\n","Epoch (test) 4:  18%|█▊        | 2/11 [00:08<00:34,  3.87s/it]\n","Epoch (test) 4:  27%|██▋       | 3/11 [00:10<00:25,  3.21s/it]\n","Epoch (test) 4:  36%|███▋      | 4/11 [00:13<00:20,  2.88s/it]\n","Epoch (test) 4:  45%|████▌     | 5/11 [00:15<00:15,  2.60s/it]\n","Epoch (test) 4:  55%|█████▍    | 6/11 [00:19<00:15,  3.17s/it]\n","Epoch (test) 4:  64%|██████▎   | 7/11 [00:21<00:10,  2.69s/it]\n","Epoch (test) 4:  73%|███████▎  | 8/11 [00:23<00:07,  2.40s/it]\n","Epoch (test) 4:  82%|████████▏ | 9/11 [00:25<00:04,  2.30s/it]\n","Epoch (test) 4:  91%|█████████ | 10/11 [00:25<00:01,  1.63s/it]\n","Epoch (test) 4: 100%|██████████| 11/11 [00:25<00:00,  2.29s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:13:17. Total running time: 21min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         3           254.745    2.86462     0.224649 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-14 08:13:34,149\tWARNING util.py:202 -- The `on_step_begin` operation took 13.111 s, which may be a performance bottleneck.\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00002_2_batch_size=32,epochs=20,lr=0.0020_2024-04-14_07-52-15/checkpoint_000003)\n","Epoch (training) 5:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 5:   5%|▍         | 1/21 [00:05<01:44,  5.24s/it]\n","Epoch (training) 5:  10%|▉         | 2/21 [00:07<01:00,  3.20s/it]\n","Epoch (training) 5:  14%|█▍        | 3/21 [00:08<00:42,  2.38s/it]\n","Epoch (training) 5:  19%|█▉        | 4/21 [00:11<00:45,  2.70s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:13:47. Total running time: 21min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         4           349.406    2.39383     0.291732 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 5:  24%|██▍       | 5/21 [00:14<00:44,  2.76s/it]\n","Epoch (training) 5:  29%|██▊       | 6/21 [00:16<00:37,  2.50s/it]\n","Epoch (training) 5:  33%|███▎      | 7/21 [00:19<00:38,  2.78s/it]\n","Epoch (training) 5:  38%|███▊      | 8/21 [00:21<00:32,  2.49s/it]\n","Epoch (training) 5:  43%|████▎     | 9/21 [00:23<00:28,  2.39s/it]\n","Epoch (training) 5:  48%|████▊     | 10/21 [00:26<00:27,  2.48s/it]\n","Epoch (training) 5:  52%|█████▏    | 11/21 [00:29<00:26,  2.63s/it]\n","Epoch (training) 5:  57%|█████▋    | 12/21 [00:32<00:24,  2.70s/it]\n","Epoch (training) 5:  62%|██████▏   | 13/21 [00:34<00:20,  2.52s/it]\n","Epoch (training) 5:  67%|██████▋   | 14/21 [00:36<00:16,  2.36s/it]\n","Epoch (training) 5:  71%|███████▏  | 15/21 [00:37<00:12,  2.10s/it]\n","Epoch (training) 5:  76%|███████▌  | 16/21 [00:41<00:12,  2.43s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:14:17. Total running time: 22min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         4           349.406    2.39383     0.291732 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 5:  81%|████████  | 17/21 [00:44<00:11,  2.76s/it]\n","Epoch (training) 5:  86%|████████▌ | 18/21 [00:46<00:07,  2.49s/it]\n","Epoch (training) 5:  90%|█████████ | 19/21 [00:49<00:05,  2.72s/it]\n","Epoch (training) 5:  95%|█████████▌| 20/21 [00:50<00:01,  2.00s/it]\n","Epoch (training) 5: 100%|██████████| 21/21 [00:50<00:00,  2.40s/it]\n","Epoch (test) 5:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 5:   9%|▉         | 1/11 [00:04<00:43,  4.38s/it]\n","Epoch (test) 5:  18%|█▊        | 2/11 [00:07<00:34,  3.81s/it]\n","Epoch (test) 5:  27%|██▋       | 3/11 [00:10<00:27,  3.44s/it]\n","Epoch (test) 5:  36%|███▋      | 4/11 [00:13<00:21,  3.05s/it]\n","Epoch (test) 5:  45%|████▌     | 5/11 [00:15<00:16,  2.74s/it]\n","Epoch (test) 5:  55%|█████▍    | 6/11 [00:18<00:14,  2.81s/it]\n","Epoch (test) 5:  64%|██████▎   | 7/11 [00:19<00:09,  2.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:14:47. Total running time: 22min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         4           349.406    2.39383     0.291732 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 5:  73%|███████▎  | 8/11 [00:22<00:07,  2.43s/it]\n","Epoch (test) 5:  82%|████████▏ | 9/11 [00:25<00:05,  2.53s/it]\n","Epoch (test) 5: 100%|██████████| 11/11 [00:25<00:00,  2.30s/it]\n","2024-04-14 08:14:58,594\tWARNING util.py:202 -- The `on_step_begin` operation took 4.268 s, which may be a performance bottleneck.\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00002_2_batch_size=32,epochs=20,lr=0.0020_2024-04-14_07-52-15/checkpoint_000004)\n","Epoch (training) 6:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 6:   5%|▍         | 1/21 [00:07<02:25,  7.28s/it]\n","Epoch (training) 6:  10%|▉         | 2/21 [00:09<01:16,  4.02s/it]\n","Epoch (training) 6:  14%|█▍        | 3/21 [00:10<00:53,  2.95s/it]\n","Epoch (training) 6:  19%|█▉        | 4/21 [00:13<00:49,  2.93s/it]\n","Epoch (training) 6:  24%|██▍       | 5/21 [00:15<00:42,  2.64s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:15:17. Total running time: 23min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         5           434.085    2.06911     0.335413 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 6:  29%|██▊       | 6/21 [00:18<00:39,  2.64s/it]\n","Epoch (training) 6:  33%|███▎      | 7/21 [00:21<00:41,  2.95s/it]\n","Epoch (training) 6:  38%|███▊      | 8/21 [00:24<00:37,  2.92s/it]\n","Epoch (training) 6:  43%|████▎     | 9/21 [00:26<00:30,  2.53s/it]\n","Epoch (training) 6:  48%|████▊     | 10/21 [00:28<00:25,  2.30s/it]\n","Epoch (training) 6:  52%|█████▏    | 11/21 [00:29<00:20,  2.05s/it]\n","Epoch (training) 6:  57%|█████▋    | 12/21 [00:33<00:22,  2.49s/it]\n","Epoch (training) 6:  62%|██████▏   | 13/21 [00:35<00:20,  2.55s/it]\n","Epoch (training) 6:  67%|██████▋   | 14/21 [00:38<00:17,  2.44s/it]\n","Epoch (training) 6:  71%|███████▏  | 15/21 [00:39<00:12,  2.10s/it]\n","Epoch (training) 6:  76%|███████▌  | 16/21 [00:42<00:11,  2.32s/it]\n","Epoch (training) 6:  81%|████████  | 17/21 [00:45<00:09,  2.46s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:15:47. Total running time: 23min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         5           434.085    2.06911     0.335413 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 6:  86%|████████▌ | 18/21 [00:48<00:07,  2.62s/it]\n","Epoch (training) 6:  90%|█████████ | 19/21 [00:51<00:05,  2.83s/it]\n","Epoch (training) 6:  95%|█████████▌| 20/21 [00:51<00:02,  2.08s/it]\n","Epoch (training) 6: 100%|██████████| 21/21 [00:51<00:00,  2.47s/it]\n","Epoch (test) 6:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 6:   9%|▉         | 1/11 [00:04<00:43,  4.35s/it]\n","Epoch (test) 6:  18%|█▊        | 2/11 [00:06<00:29,  3.29s/it]\n","Epoch (test) 6:  27%|██▋       | 3/11 [00:09<00:25,  3.18s/it]\n","Epoch (test) 6:  36%|███▋      | 4/11 [00:13<00:22,  3.27s/it]\n","Epoch (test) 6:  45%|████▌     | 5/11 [00:15<00:17,  2.88s/it]\n","Epoch (test) 6:  55%|█████▍    | 6/11 [00:18<00:14,  2.90s/it]\n","Epoch (test) 6:  64%|██████▎   | 7/11 [00:20<00:09,  2.45s/it]\n","Epoch (test) 6:  73%|███████▎  | 8/11 [00:21<00:06,  2.25s/it]\n","Epoch (test) 6:  82%|████████▏ | 9/11 [00:24<00:04,  2.29s/it]\n","Epoch (test) 6: 100%|██████████| 11/11 [00:24<00:00,  2.21s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:16:17. Total running time: 24min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         5           434.085    2.06911     0.335413 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-14 08:16:43,450\tWARNING util.py:202 -- The `on_step_begin` operation took 14.610 s, which may be a performance bottleneck.\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:16:48. Total running time: 24min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         5           434.085    2.06911     0.335413 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-14 08:16:58,819\tWARNING util.py:202 -- The `on_step_begin` operation took 5.361 s, which may be a performance bottleneck.\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00002_2_batch_size=32,epochs=20,lr=0.0020_2024-04-14_07-52-15/checkpoint_000005)\n","Epoch (training) 7:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 7:   5%|▍         | 1/21 [00:05<01:46,  5.35s/it]\n","Epoch (training) 7:  10%|▉         | 2/21 [00:07<01:08,  3.63s/it]\n","Epoch (training) 7:  14%|█▍        | 3/21 [00:10<00:59,  3.33s/it]\n","Epoch (training) 7:  19%|█▉        | 4/21 [00:14<01:00,  3.58s/it]\n","Epoch (training) 7:  24%|██▍       | 5/21 [00:16<00:46,  2.93s/it]\n","Epoch (training) 7:  29%|██▊       | 6/21 [00:18<00:37,  2.52s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:17:18. Total running time: 25min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         6           553.765    2.90402     0.268331 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 7:  33%|███▎      | 7/21 [00:20<00:33,  2.36s/it]\n","Epoch (training) 7:  38%|███▊      | 8/21 [00:22<00:32,  2.48s/it]\n","Epoch (training) 7:  43%|████▎     | 9/21 [00:26<00:32,  2.67s/it]\n","Epoch (training) 7:  48%|████▊     | 10/21 [00:29<00:31,  2.85s/it]\n","Epoch (training) 7:  52%|█████▏    | 11/21 [00:31<00:26,  2.62s/it]\n","Epoch (training) 7:  57%|█████▋    | 12/21 [00:33<00:21,  2.38s/it]\n","Epoch (training) 7:  62%|██████▏   | 13/21 [00:35<00:18,  2.34s/it]\n","Epoch (training) 7:  67%|██████▋   | 14/21 [00:37<00:15,  2.21s/it]\n","Epoch (training) 7:  71%|███████▏  | 15/21 [00:39<00:12,  2.12s/it]\n","Epoch (training) 7:  76%|███████▌  | 16/21 [00:42<00:11,  2.34s/it]\n","Epoch (training) 7:  81%|████████  | 17/21 [00:44<00:09,  2.46s/it]\n","Epoch (training) 7:  86%|████████▌ | 18/21 [00:47<00:07,  2.47s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:17:48. Total running time: 25min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         6           553.765    2.90402     0.268331 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 7:  90%|█████████ | 19/21 [00:49<00:04,  2.28s/it]\n","Epoch (training) 7:  95%|█████████▌| 20/21 [00:49<00:01,  1.69s/it]\n","Epoch (training) 7: 100%|██████████| 21/21 [00:49<00:00,  2.37s/it]\n","Epoch (test) 7:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 7:   9%|▉         | 1/11 [00:04<00:43,  4.31s/it]\n","Epoch (test) 7:  18%|█▊        | 2/11 [00:07<00:33,  3.77s/it]\n","Epoch (test) 7:  27%|██▋       | 3/11 [00:10<00:27,  3.41s/it]\n","Epoch (test) 7:  36%|███▋      | 4/11 [00:13<00:21,  3.03s/it]\n","Epoch (test) 7:  45%|████▌     | 5/11 [00:15<00:16,  2.71s/it]\n","Epoch (test) 7:  55%|█████▍    | 6/11 [00:18<00:13,  2.75s/it]\n","Epoch (test) 7:  64%|██████▎   | 7/11 [00:19<00:09,  2.34s/it]\n","Epoch (test) 7:  73%|███████▎  | 8/11 [00:22<00:07,  2.39s/it]\n","Epoch (test) 7:  82%|████████▏ | 9/11 [00:24<00:05,  2.53s/it]\n","Epoch (test) 7: 100%|██████████| 11/11 [00:25<00:00,  2.28s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:18:18. Total running time: 26min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         6           553.765    2.90402     0.268331 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-14 08:18:19,836\tWARNING util.py:202 -- The `on_step_begin` operation took 0.588 s, which may be a performance bottleneck.\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00002_2_batch_size=32,epochs=20,lr=0.0020_2024-04-14_07-52-15/checkpoint_000006)\n","Epoch (training) 8:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 8:   5%|▍         | 1/21 [00:04<01:39,  5.00s/it]\n","Epoch (training) 8:  10%|▉         | 2/21 [00:07<01:03,  3.36s/it]\n","Epoch (training) 8:  14%|█▍        | 3/21 [00:09<00:51,  2.86s/it]\n","Epoch (training) 8:  19%|█▉        | 4/21 [00:11<00:41,  2.47s/it]\n","Epoch (training) 8:  24%|██▍       | 5/21 [00:13<00:40,  2.50s/it]\n","Epoch (training) 8:  29%|██▊       | 6/21 [00:16<00:35,  2.36s/it]\n","Epoch (training) 8:  33%|███▎      | 7/21 [00:18<00:35,  2.55s/it]\n","Epoch (training) 8:  38%|███▊      | 8/21 [00:22<00:37,  2.88s/it]\n","Epoch (training) 8:  43%|████▎     | 9/21 [00:24<00:31,  2.64s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:18:48. Total running time: 26min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         7           636.53     2.48992     0.308892 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 8:  48%|████▊     | 10/21 [00:26<00:27,  2.52s/it]\n","Epoch (training) 8:  52%|█████▏    | 11/21 [00:30<00:27,  2.80s/it]\n","Epoch (training) 8:  57%|█████▋    | 12/21 [00:32<00:23,  2.61s/it]\n","Epoch (training) 8:  62%|██████▏   | 13/21 [00:34<00:19,  2.39s/it]\n","Epoch (training) 8:  67%|██████▋   | 14/21 [00:37<00:17,  2.53s/it]\n","Epoch (training) 8:  71%|███████▏  | 15/21 [00:39<00:14,  2.39s/it]\n","Epoch (training) 8:  76%|███████▌  | 16/21 [00:41<00:11,  2.28s/it]\n","Epoch (training) 8:  81%|████████  | 17/21 [00:44<00:09,  2.46s/it]\n","Epoch (training) 8:  86%|████████▌ | 18/21 [00:47<00:08,  2.69s/it]\n","Epoch (training) 8:  90%|█████████ | 19/21 [00:50<00:05,  2.70s/it]\n","Epoch (training) 8:  95%|█████████▌| 20/21 [00:50<00:01,  1.99s/it]\n","Epoch (training) 8: 100%|██████████| 21/21 [00:50<00:00,  2.41s/it]\n","Epoch (test) 8:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 8:   9%|▉         | 1/11 [00:04<00:45,  4.51s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:19:18. Total running time: 27min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         7           636.53     2.48992     0.308892 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 8:  18%|█▊        | 2/11 [00:06<00:29,  3.31s/it]\n","Epoch (test) 8:  27%|██▋       | 3/11 [00:09<00:23,  2.90s/it]\n","Epoch (test) 8:  36%|███▋      | 4/11 [00:12<00:20,  2.88s/it]\n","Epoch (test) 8:  45%|████▌     | 5/11 [00:15<00:17,  2.91s/it]\n","Epoch (test) 8:  55%|█████▍    | 6/11 [00:18<00:14,  2.94s/it]\n","Epoch (test) 8:  64%|██████▎   | 7/11 [00:19<00:09,  2.46s/it]\n","Epoch (test) 8:  73%|███████▎  | 8/11 [00:21<00:06,  2.23s/it]\n","Epoch (test) 8:  82%|████████▏ | 9/11 [00:23<00:04,  2.17s/it]\n","Epoch (test) 8:  91%|█████████ | 10/11 [00:23<00:01,  1.54s/it]\n","Epoch (test) 8: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it]\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00002_2_batch_size=32,epochs=20,lr=0.0020_2024-04-14_07-52-15/checkpoint_000007)\n","Epoch (training) 9:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 9:   5%|▍         | 1/21 [00:04<01:36,  4.82s/it]\n","Epoch (training) 9:  10%|▉         | 2/21 [00:06<01:00,  3.16s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:19:48. Total running time: 27min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         8           714.927    3.03073     0.24337  |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 9:  14%|█▍        | 3/21 [00:09<00:49,  2.74s/it]\n","Epoch (training) 9:  19%|█▉        | 4/21 [00:12<00:50,  2.96s/it]\n","Epoch (training) 9:  24%|██▍       | 5/21 [00:14<00:41,  2.61s/it]\n","Epoch (training) 9:  29%|██▊       | 6/21 [00:17<00:43,  2.93s/it]\n","Epoch (training) 9:  33%|███▎      | 7/21 [00:19<00:34,  2.49s/it]\n","Epoch (training) 9:  38%|███▊      | 8/21 [00:21<00:30,  2.34s/it]\n","Epoch (training) 9:  43%|████▎     | 9/21 [00:23<00:27,  2.27s/it]\n","Epoch (training) 9:  48%|████▊     | 10/21 [00:25<00:23,  2.13s/it]\n","Epoch (training) 9:  52%|█████▏    | 11/21 [00:27<00:22,  2.25s/it]\n","Epoch (training) 9:  57%|█████▋    | 12/21 [00:30<00:21,  2.42s/it]\n","Epoch (training) 9:  62%|██████▏   | 13/21 [00:33<00:20,  2.53s/it]\n","Epoch (training) 9:  67%|██████▋   | 14/21 [00:37<00:20,  2.87s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:20:18. Total running time: 28min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         8           714.927    3.03073     0.24337  |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 9:  71%|███████▏  | 15/21 [00:39<00:16,  2.67s/it]\n","Epoch (training) 9:  76%|███████▌  | 16/21 [00:41<00:11,  2.36s/it]\n","Epoch (training) 9:  81%|████████  | 17/21 [00:44<00:10,  2.62s/it]\n","Epoch (training) 9:  86%|████████▌ | 18/21 [00:47<00:08,  2.94s/it]\n","Epoch (training) 9:  90%|█████████ | 19/21 [00:50<00:05,  2.76s/it]\n","Epoch (training) 9:  95%|█████████▌| 20/21 [00:50<00:02,  2.03s/it]\n","Epoch (training) 9: 100%|██████████| 21/21 [00:50<00:00,  2.42s/it]\n","Epoch (test) 9:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 9:   9%|▉         | 1/11 [00:04<00:43,  4.37s/it]\n","Epoch (test) 9:  18%|█▊        | 2/11 [00:06<00:29,  3.26s/it]\n","Epoch (test) 9:  27%|██▋       | 3/11 [00:10<00:26,  3.32s/it]\n","Epoch (test) 9:  36%|███▋      | 4/11 [00:13<00:21,  3.13s/it]\n","Epoch (test) 9:  45%|████▌     | 5/11 [00:15<00:16,  2.77s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:20:48. Total running time: 28min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         8           714.927    3.03073     0.24337  |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 9:  55%|█████▍    | 6/11 [00:18<00:14,  2.80s/it]\n","Epoch (test) 9:  64%|██████▎   | 7/11 [00:19<00:09,  2.37s/it]\n","Epoch (test) 9:  73%|███████▎  | 8/11 [00:21<00:06,  2.18s/it]\n","Epoch (test) 9:  82%|████████▏ | 9/11 [00:24<00:04,  2.35s/it]\n","Epoch (test) 9: 100%|██████████| 11/11 [00:24<00:00,  2.20s/it]\n","2024-04-14 08:21:02,096\tWARNING util.py:202 -- The `on_step_begin` operation took 1.901 s, which may be a performance bottleneck.\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00002_2_batch_size=32,epochs=20,lr=0.0020_2024-04-14_07-52-15/checkpoint_000008)\n","Epoch (training) 10:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 10:   5%|▍         | 1/21 [00:04<01:33,  4.69s/it]\n","Epoch (training) 10:  10%|▉         | 2/21 [00:07<01:04,  3.40s/it]\n","Epoch (training) 10:  14%|█▍        | 3/21 [00:09<00:55,  3.06s/it]\n","Epoch (training) 10:  19%|█▉        | 4/21 [00:12<00:49,  2.90s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:21:18. Total running time: 29min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         9           799.327    2.90557     0.297972 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 10:  24%|██▍       | 5/21 [00:14<00:39,  2.47s/it]\n","Epoch (training) 10:  29%|██▊       | 6/21 [00:16<00:35,  2.34s/it]\n","Epoch (training) 10:  33%|███▎      | 7/21 [00:18<00:33,  2.41s/it]\n","Epoch (training) 10:  38%|███▊      | 8/21 [00:22<00:38,  2.94s/it]\n","Epoch (training) 10:  43%|████▎     | 9/21 [00:24<00:30,  2.55s/it]\n","Epoch (training) 10:  48%|████▊     | 10/21 [00:27<00:30,  2.77s/it]\n","Epoch (training) 10:  52%|█████▏    | 11/21 [00:31<00:28,  2.89s/it]\n","Epoch (training) 10:  57%|█████▋    | 12/21 [00:32<00:22,  2.48s/it]\n","Epoch (training) 10:  62%|██████▏   | 13/21 [00:35<00:20,  2.53s/it]\n","Epoch (training) 10:  67%|██████▋   | 14/21 [00:38<00:18,  2.65s/it]\n","Epoch (training) 10:  71%|███████▏  | 15/21 [00:41<00:16,  2.77s/it]\n","Epoch (training) 10:  76%|███████▌  | 16/21 [00:43<00:12,  2.57s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:21:48. Total running time: 29min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         9           799.327    2.90557     0.297972 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 10:  81%|████████  | 17/21 [00:45<00:09,  2.45s/it]\n","Epoch (training) 10:  86%|████████▌ | 18/21 [00:47<00:07,  2.36s/it]\n","Epoch (training) 10:  90%|█████████ | 19/21 [00:49<00:04,  2.32s/it]\n","Epoch (training) 10:  95%|█████████▌| 20/21 [00:50<00:01,  1.73s/it]\n","Epoch (training) 10: 100%|██████████| 21/21 [00:50<00:00,  2.40s/it]\n","Epoch (test) 10:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 10:   9%|▉         | 1/11 [00:05<00:50,  5.00s/it]\n","Epoch (test) 10:  18%|█▊        | 2/11 [00:07<00:31,  3.52s/it]\n","Epoch (test) 10:  27%|██▋       | 3/11 [00:09<00:23,  2.99s/it]\n","Epoch (test) 10:  36%|███▋      | 4/11 [00:12<00:19,  2.75s/it]\n","Epoch (test) 10:  45%|████▌     | 5/11 [00:15<00:17,  2.84s/it]\n","Epoch (test) 10:  55%|█████▍    | 6/11 [00:18<00:15,  3.06s/it]\n","Epoch (test) 10:  64%|██████▎   | 7/11 [00:20<00:10,  2.54s/it]\n","Epoch (test) 10:  73%|███████▎  | 8/11 [00:21<00:06,  2.29s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:22:18. Total running time: 30min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00002   RUNNING                          20                       32              0.00203071         9           799.327    2.90557     0.297972 |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00003   PENDING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=24730)\u001b[0m \rEpoch (test) 10:  82%|████████▏ | 9/11 [00:24<00:04,  2.22s/it]\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m \rEpoch (test) 10:  91%|█████████ | 10/11 [00:24<00:01,  1.57s/it]\rEpoch (test) 10: 100%|██████████| 11/11 [00:24<00:00,  2.19s/it]\n","2024-04-14 08:22:38,712\tWARNING util.py:202 -- The `on_step_begin` operation took 6.124 s, which may be a performance bottleneck.\n","\u001b[36m(RayTrainWorker pid=24730)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00002_2_batch_size=32,epochs=20,lr=0.0020_2024-04-14_07-52-15/checkpoint_000009)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial TorchTrainer_e8bbe_00002 completed after 10 iterations at 2024-04-14 08:22:45. Total running time: 30min 30s\n","+---------------------------------------------------------------+\n","| Trial TorchTrainer_e8bbe_00002 result                         |\n","+---------------------------------------------------------------+\n","| checkpoint_dir_name                         checkpoint_000009 |\n","| time_this_iter_s                                      99.1124 |\n","| time_total_s                                        898.43934 |\n","| training_iteration                                         10 |\n","| accuracy                                              0.29173 |\n","| loss                                                  3.82133 |\n","| summary/epoch/0                                           1.0 |\n","| summary/epoch/1                                           2.0 |\n","| summary/epoch/2                                           3.0 |\n","| summary/epoch/3                                           4.0 |\n","| summary/epoch/4                                           5.0 |\n","| summary/epoch/5                                           6.0 |\n","| summary/epoch/6                                           7.0 |\n","| summary/epoch/7                                           8.0 |\n","| summary/epoch/8                                           9.0 |\n","| summary/epoch/9                                          10.0 |\n","| summary/train_acc/0                       0.17798594847775176 |\n","| summary/train_acc/1                       0.24824355971896955 |\n","| summary/train_acc/2                         0.336455893832943 |\n","| summary/train_acc/3                        0.3551912568306011 |\n","| summary/train_acc/4                       0.40827478532396566 |\n","| summary/train_acc/5                        0.4676034348165496 |\n","| summary/train_acc/6                        0.4715066354410617 |\n","| summary/train_acc/7                        0.5394223263075723 |\n","| summary/train_acc/8                        0.5729898516783762 |\n","| summary/train_acc/9                         0.594847775175644 |\n","| summary/train_loss/0                       2.4926476251511347 |\n","| summary/train_loss/1                       2.2767212788263955 |\n","| summary/train_loss/2                        2.005890199116298 |\n","| summary/train_loss/3                       1.8045164261545454 |\n","| summary/train_loss/4                       1.8952861740475608 |\n","| summary/train_loss/5                       1.6332002253759474 |\n","| summary/train_loss/6                       1.6727159988312494 |\n","| summary/train_loss/7                        1.444131890932719 |\n","| summary/train_loss/8                       1.2986229431061518 |\n","| summary/train_loss/9                       1.2959395505133129 |\n","| summary/val_acc/0                         0.11856474258970359 |\n","| summary/val_acc/1                          0.2667706708268331 |\n","| summary/val_acc/2                         0.22464898595943839 |\n","| summary/val_acc/3                          0.2917316692667707 |\n","| summary/val_acc/4                         0.33541341653666146 |\n","| summary/val_acc/5                         0.26833073322932915 |\n","| summary/val_acc/6                          0.3088923556942278 |\n","| summary/val_acc/7                         0.24336973478939158 |\n","| summary/val_acc/8                         0.29797191887675506 |\n","| summary/val_acc/9                          0.2917316692667707 |\n","| summary/val_loss/0                          4.517797470092773 |\n","| summary/val_loss/1                          3.632722507823597 |\n","| summary/val_loss/2                         2.8646194718100806 |\n","| summary/val_loss/3                          2.393833344632929 |\n","| summary/val_loss/4                         2.0691088221289893 |\n","| summary/val_loss/5                          2.904024600982666 |\n","| summary/val_loss/6                         2.4899180910804053 |\n","| summary/val_loss/7                         3.0307267037304966 |\n","| summary/val_loss/8                         2.9055731946771797 |\n","| summary/val_loss/9                          3.821334020657973 |\n","+---------------------------------------------------------------+\n","\n","Trial TorchTrainer_e8bbe_00003 started with configuration:\n","+-----------------------------------------------------------------+\n","| Trial TorchTrainer_e8bbe_00003 config                           |\n","+-----------------------------------------------------------------+\n","| train_loop_config/batch_size                                 32 |\n","| train_loop_config/epochs                                     10 |\n","| train_loop_config/lr                      0.0031788899836107695 |\n","| train_loop_config/train_test_idx           ...20, 11731, 1157]) |\n","+-----------------------------------------------------------------+\n","\n","Trial status: 3 TERMINATED | 1 RUNNING | 1 PENDING\n","Current time: 2024-04-14 08:22:48. Total running time: 30min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00003   RUNNING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00002   TERMINATED                       20                       32              0.00203071        10           898.439    3.82133     0.291732 |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(TorchTrainer pid=20570)\u001b[0m Started distributed worker processes: \n","\u001b[36m(TorchTrainer pid=20570)\u001b[0m - (ip=172.28.0.12, pid=28516) world_rank=0, local_rank=0, node_rank=0\n","\u001b[36m(RayTrainWorker pid=28516)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[36m(RayTrainWorker pid=28516)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n","\u001b[36m(RayTrainWorker pid=28516)\u001b[0m 2024-04-14 08:22:53.322250: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(RayTrainWorker pid=28516)\u001b[0m 2024-04-14 08:22:53.322305: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(RayTrainWorker pid=28516)\u001b[0m 2024-04-14 08:22:53.323924: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(RayTrainWorker pid=28516)\u001b[0m 2024-04-14 08:22:55.174501: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[36m(RayTrainWorker pid=28516)\u001b[0m Moving model to device: cuda:0\n","Epoch (training) 1:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 1:   5%|▍         | 1/21 [00:05<01:40,  5.01s/it]\n","Epoch (training) 1:  10%|▉         | 2/21 [00:07<01:07,  3.57s/it]\n","Epoch (training) 1:  14%|█▍        | 3/21 [00:11<01:03,  3.55s/it]\n","Epoch (training) 1:  19%|█▉        | 4/21 [00:13<00:54,  3.20s/it]\n","Epoch (training) 1:  24%|██▍       | 5/21 [00:15<00:42,  2.65s/it]\n","Epoch (training) 1:  29%|██▊       | 6/21 [00:17<00:38,  2.60s/it]\n","Epoch (training) 1:  33%|███▎      | 7/21 [00:21<00:39,  2.81s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 3 TERMINATED | 1 RUNNING | 1 PENDING\n","Current time: 2024-04-14 08:23:19. Total running time: 31min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00003   RUNNING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00002   TERMINATED                       20                       32              0.00203071        10           898.439    3.82133     0.291732 |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  38%|███▊      | 8/21 [00:25<00:41,  3.17s/it]\n","Epoch (training) 1:  43%|████▎     | 9/21 [00:28<00:37,  3.11s/it]\n","Epoch (training) 1:  48%|████▊     | 10/21 [00:31<00:36,  3.33s/it]\n","Epoch (training) 1:  52%|█████▏    | 11/21 [00:34<00:30,  3.06s/it]\n","Epoch (training) 1:  57%|█████▋    | 12/21 [00:35<00:23,  2.60s/it]\n","Epoch (training) 1:  62%|██████▏   | 13/21 [00:38<00:21,  2.71s/it]\n","Epoch (training) 1:  67%|██████▋   | 14/21 [00:41<00:19,  2.81s/it]\n","Epoch (training) 1:  71%|███████▏  | 15/21 [00:43<00:15,  2.59s/it]\n","Epoch (training) 1:  76%|███████▌  | 16/21 [00:45<00:11,  2.31s/it]\n","Epoch (training) 1:  81%|████████  | 17/21 [00:48<00:10,  2.51s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 3 TERMINATED | 1 RUNNING | 1 PENDING\n","Current time: 2024-04-14 08:23:49. Total running time: 31min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00003   RUNNING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00002   TERMINATED                       20                       32              0.00203071        10           898.439    3.82133     0.291732 |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  86%|████████▌ | 18/21 [00:51<00:08,  2.74s/it]\n","Epoch (training) 1:  90%|█████████ | 19/21 [00:53<00:04,  2.46s/it]\n","Epoch (training) 1:  95%|█████████▌| 20/21 [00:54<00:01,  1.82s/it]\n","Epoch (training) 1: 100%|██████████| 21/21 [00:54<00:00,  2.60s/it]\n","Epoch (test) 1:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 1:   9%|▉         | 1/11 [00:05<00:51,  5.15s/it]\n","Epoch (test) 1:  18%|█▊        | 2/11 [00:07<00:32,  3.61s/it]\n","Epoch (test) 1:  27%|██▋       | 3/11 [00:10<00:24,  3.11s/it]\n","Epoch (test) 1:  36%|███▋      | 4/11 [00:12<00:20,  2.96s/it]\n","Epoch (test) 1:  45%|████▌     | 5/11 [00:16<00:18,  3.01s/it]\n","Epoch (test) 1:  55%|█████▍    | 6/11 [00:19<00:15,  3.06s/it]\n","Epoch (test) 1:  64%|██████▎   | 7/11 [00:20<00:10,  2.54s/it]\n","Epoch (test) 1:  73%|███████▎  | 8/11 [00:22<00:06,  2.30s/it]\n","Epoch (test) 1:  82%|████████▏ | 9/11 [00:24<00:04,  2.22s/it]\n","Epoch (test) 1: 100%|██████████| 11/11 [00:24<00:00,  2.24s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 3 TERMINATED | 1 RUNNING | 1 PENDING\n","Current time: 2024-04-14 08:24:19. Total running time: 32min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00003   RUNNING                          10                       32              0.00317889                                                     |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00002   TERMINATED                       20                       32              0.00203071        10           898.439    3.82133     0.291732 |\n","| TorchTrainer_e8bbe_00004   PENDING                          10                       32              0.00185077                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n","Trial TorchTrainer_e8bbe_00003 completed after 1 iterations at 2024-04-14 08:24:24. Total running time: 32min 9s\n","+---------------------------------------------------------------+\n","| Trial TorchTrainer_e8bbe_00003 result                         |\n","+---------------------------------------------------------------+\n","| checkpoint_dir_name                         checkpoint_000000 |\n","| time_this_iter_s                                     98.95957 |\n","| time_total_s                                         98.95957 |\n","| training_iteration                                          1 |\n","| accuracy                                              0.11388 |\n","| loss                                                  4.27579 |\n","| summary/epoch/0                                           1.0 |\n","| summary/train_acc/0                       0.16705698672911787 |\n","| summary/train_loss/0                       2.5860969566163563 |\n","| summary/val_acc/0                         0.11388455538221529 |\n","| summary/val_loss/0                          4.275794419375333 |\n","+---------------------------------------------------------------+\n","\n","Trial TorchTrainer_e8bbe_00004 started with configuration:\n","+-----------------------------------------------------------------+\n","| Trial TorchTrainer_e8bbe_00004 config                           |\n","+-----------------------------------------------------------------+\n","| train_loop_config/batch_size                                 32 |\n","| train_loop_config/epochs                                     10 |\n","| train_loop_config/lr                      0.0018507692215621258 |\n","| train_loop_config/train_test_idx           ...20, 11731, 1157]) |\n","+-----------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=28516)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00003_3_batch_size=32,epochs=10,lr=0.0032_2024-04-14_07-52-15/checkpoint_000000)\n","\u001b[36m(TorchTrainer pid=20570)\u001b[0m Started distributed worker processes: \n","\u001b[36m(TorchTrainer pid=20570)\u001b[0m - (ip=172.28.0.12, pid=28969) world_rank=0, local_rank=0, node_rank=0\n","\u001b[36m(RayTrainWorker pid=28969)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[36m(RayTrainWorker pid=28969)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n","\u001b[36m(RayTrainWorker pid=28969)\u001b[0m 2024-04-14 08:24:30.491631: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(RayTrainWorker pid=28969)\u001b[0m 2024-04-14 08:24:30.491692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(RayTrainWorker pid=28969)\u001b[0m 2024-04-14 08:24:30.493179: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(RayTrainWorker pid=28969)\u001b[0m 2024-04-14 08:24:31.875121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[36m(RayTrainWorker pid=28969)\u001b[0m Moving model to device: cuda:0\n","Epoch (training) 1:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (training) 1:   5%|▍         | 1/21 [00:09<03:10,  9.51s/it]\n","Epoch (training) 1:  10%|▉         | 2/21 [00:11<01:37,  5.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 4 TERMINATED | 1 RUNNING\n","Current time: 2024-04-14 08:24:49. Total running time: 32min 34s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00004   RUNNING                          10                       32              0.00185077                                                     |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00002   TERMINATED                       20                       32              0.00203071        10           898.439    3.82133     0.291732 |\n","| TorchTrainer_e8bbe_00003   TERMINATED                       10                       32              0.00317889         1            98.9596   4.27579     0.113885 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  14%|█▍        | 3/21 [00:15<01:24,  4.69s/it]\n","Epoch (training) 1:  19%|█▉        | 4/21 [00:17<01:01,  3.59s/it]\n","Epoch (training) 1:  24%|██▍       | 5/21 [00:18<00:44,  2.77s/it]\n","Epoch (training) 1:  29%|██▊       | 6/21 [00:22<00:43,  2.90s/it]\n","Epoch (training) 1:  33%|███▎      | 7/21 [00:24<00:36,  2.62s/it]\n","Epoch (training) 1:  38%|███▊      | 8/21 [00:25<00:30,  2.35s/it]\n","Epoch (training) 1:  43%|████▎     | 9/21 [00:28<00:29,  2.49s/it]\n","Epoch (training) 1:  48%|████▊     | 10/21 [00:32<00:32,  2.95s/it]\n","Epoch (training) 1:  52%|█████▏    | 11/21 [00:35<00:28,  2.86s/it]\n","Epoch (training) 1:  57%|█████▋    | 12/21 [00:36<00:21,  2.41s/it]\n","Epoch (training) 1:  62%|██████▏   | 13/21 [00:38<00:18,  2.26s/it]\n","Epoch (training) 1:  67%|██████▋   | 14/21 [00:40<00:14,  2.13s/it]\n","Epoch (training) 1:  71%|███████▏  | 15/21 [00:43<00:14,  2.34s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 4 TERMINATED | 1 RUNNING\n","Current time: 2024-04-14 08:25:19. Total running time: 33min 4s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00004   RUNNING                          10                       32              0.00185077                                                     |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00002   TERMINATED                       20                       32              0.00203071        10           898.439    3.82133     0.291732 |\n","| TorchTrainer_e8bbe_00003   TERMINATED                       10                       32              0.00317889         1            98.9596   4.27579     0.113885 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  76%|███████▌  | 16/21 [00:47<00:14,  2.99s/it]\n","Epoch (training) 1:  81%|████████  | 17/21 [00:49<00:10,  2.67s/it]\n","Epoch (training) 1:  86%|████████▌ | 18/21 [00:52<00:08,  2.71s/it]\n","Epoch (training) 1:  90%|█████████ | 19/21 [00:55<00:05,  2.93s/it]\n","Epoch (training) 1:  95%|█████████▌| 20/21 [00:56<00:02,  2.15s/it]\n","Epoch (training) 1: 100%|██████████| 21/21 [00:56<00:00,  2.70s/it]\n","Epoch (test) 1:   0%|          | 0/11 [00:00<?, ?it/s]\n","Epoch (test) 1:   9%|▉         | 1/11 [00:05<00:59,  6.00s/it]\n","Epoch (test) 1:  18%|█▊        | 2/11 [00:08<00:35,  3.97s/it]\n","Epoch (test) 1:  27%|██▋       | 3/11 [00:11<00:26,  3.33s/it]\n","Epoch (test) 1:  36%|███▋      | 4/11 [00:13<00:21,  3.07s/it]\n","Epoch (test) 1:  45%|████▌     | 5/11 [00:16<00:17,  2.93s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 4 TERMINATED | 1 RUNNING\n","Current time: 2024-04-14 08:25:49. Total running time: 33min 34s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00004   RUNNING                          10                       32              0.00185077                                                     |\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00002   TERMINATED                       20                       32              0.00203071        10           898.439    3.82133     0.291732 |\n","| TorchTrainer_e8bbe_00003   TERMINATED                       10                       32              0.00317889         1            98.9596   4.27579     0.113885 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 1:  55%|█████▍    | 6/11 [00:20<00:16,  3.37s/it]\n","Epoch (test) 1:  64%|██████▎   | 7/11 [00:22<00:11,  2.77s/it]\n","Epoch (test) 1:  73%|███████▎  | 8/11 [00:24<00:07,  2.46s/it]\n","Epoch (test) 1:  82%|████████▏ | 9/11 [00:26<00:04,  2.35s/it]\n","Epoch (test) 1: 100%|██████████| 11/11 [00:26<00:00,  2.39s/it]\n","\u001b[36m(RayTrainWorker pid=28969)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_0/TorchTrainer_e8bbe_00004_4_batch_size=32,epochs=10,lr=0.0019_2024-04-14_07-52-15/checkpoint_000000)\n","2024-04-14 08:26:02,049\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/wide_resnet50_hpt_outer_4_inner_0' in 0.0399s.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial TorchTrainer_e8bbe_00004 completed after 1 iterations at 2024-04-14 08:26:02. Total running time: 33min 46s\n","+---------------------------------------------------------------+\n","| Trial TorchTrainer_e8bbe_00004 result                         |\n","+---------------------------------------------------------------+\n","| checkpoint_dir_name                         checkpoint_000000 |\n","| time_this_iter_s                                     97.13152 |\n","| time_total_s                                         97.13152 |\n","| training_iteration                                          1 |\n","| accuracy                                              0.11076 |\n","| loss                                                  5.00286 |\n","| summary/epoch/0                                           1.0 |\n","| summary/train_acc/0                       0.18188914910226386 |\n","| summary/train_loss/0                       2.6032531829107377 |\n","| summary/val_acc/0                         0.11076443057722309 |\n","| summary/val_loss/0                           5.00286171653054 |\n","+---------------------------------------------------------------+\n","\n","Trial status: 5 TERMINATED\n","Current time: 2024-04-14 08:26:02. Total running time: 33min 46s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_e8bbe_00000   TERMINATED                       10                       64              0.000304055       10           821.023    3.12129     0.294852 |\n","| TorchTrainer_e8bbe_00001   TERMINATED                       20                       32              0.0018874          1            98.6708   4.9129      0.102964 |\n","| TorchTrainer_e8bbe_00002   TERMINATED                       20                       32              0.00203071        10           898.439    3.82133     0.291732 |\n","| TorchTrainer_e8bbe_00003   TERMINATED                       10                       32              0.00317889         1            98.9596   4.27579     0.113885 |\n","| TorchTrainer_e8bbe_00004   TERMINATED                       10                       32              0.00185077         1            97.1315   5.00286     0.110764 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-14 08:26:02,506\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"output_type":"stream","name":"stdout","text":["Outer fold 4, inner fold 1 - number of samples: 1281\n","Tuning hyperparameters for wide_resnet50_hpt_outer_4_inner_1...\n","Defaulting to ASHA scheduler (no scheduler provided or not an instance of TrialScheduler)\n","+----------------------------------------------------------------------+\n","| Configuration for experiment     wide_resnet50_hpt_outer_4_inner_1   |\n","+----------------------------------------------------------------------+\n","| Search algorithm                 BasicVariantGenerator               |\n","| Scheduler                        AsyncHyperBandScheduler             |\n","| Number of trials                 5                                   |\n","+----------------------------------------------------------------------+\n","\n","View detailed results here: /root/ray_results/wide_resnet50_hpt_outer_4_inner_1\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-04-14_07-52-09_892030_20145/artifacts/2024-04-14_08-26-02/wide_resnet50_hpt_outer_4_inner_1/driver_artifacts`\n","\n","Trial status: 5 PENDING\n","Current time: 2024-04-14 08:26:03. Total running time: 0s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr |\n","+----------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   PENDING                        20                       32              0.00122095  |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832  |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551 |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569  |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991 |\n","+----------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(TrainTrainable pid=29424)\u001b[0m 2024-04-14 08:26:09.701034: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(TrainTrainable pid=29424)\u001b[0m 2024-04-14 08:26:09.701091: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(TrainTrainable pid=29424)\u001b[0m 2024-04-14 08:26:09.702620: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(TrainTrainable pid=29424)\u001b[0m 2024-04-14 08:26:11.093217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial TorchTrainer_a1400_00000 started with configuration:\n","+-----------------------------------------------------------------+\n","| Trial TorchTrainer_a1400_00000 config                           |\n","+-----------------------------------------------------------------+\n","| train_loop_config/batch_size                                 32 |\n","| train_loop_config/epochs                                     20 |\n","| train_loop_config/lr                      0.0012209522298131333 |\n","| train_loop_config/train_test_idx           ...30, 5553, 10803]) |\n","+-----------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(TorchTrainer pid=29424)\u001b[0m Started distributed worker processes: \n","\u001b[36m(TorchTrainer pid=29424)\u001b[0m - (ip=172.28.0.12, pid=29490) world_rank=0, local_rank=0, node_rank=0\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m 2024-04-14 08:26:17.190091: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m 2024-04-14 08:26:17.190164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m 2024-04-14 08:26:17.191990: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m 2024-04-14 08:26:19.144520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Moving model to device: cuda:0\n","Epoch (training) 1:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 1:   2%|▏         | 1/41 [00:10<07:06, 10.67s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:26:33. Total running time: 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr |\n","+----------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095  |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832  |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551 |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569  |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991 |\n","+----------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:   5%|▍         | 2/41 [00:13<03:47,  5.84s/it]\n","Epoch (training) 1:   7%|▋         | 3/41 [00:15<02:34,  4.06s/it]\n","Epoch (training) 1:  10%|▉         | 4/41 [00:16<01:49,  2.96s/it]\n","Epoch (training) 1:  12%|█▏        | 5/41 [00:17<01:29,  2.49s/it]\n","Epoch (training) 1:  15%|█▍        | 6/41 [00:19<01:12,  2.07s/it]\n","Epoch (training) 1:  17%|█▋        | 7/41 [00:20<00:56,  1.68s/it]\n","Epoch (training) 1:  20%|█▉        | 8/41 [00:21<00:51,  1.56s/it]\n","Epoch (training) 1:  22%|██▏       | 9/41 [00:22<00:45,  1.41s/it]\n","Epoch (training) 1:  24%|██▍       | 10/41 [00:24<00:48,  1.57s/it]\n","Epoch (training) 1:  27%|██▋       | 11/41 [00:25<00:41,  1.39s/it]\n","Epoch (training) 1:  29%|██▉       | 12/41 [00:26<00:37,  1.31s/it]\n","Epoch (training) 1:  32%|███▏      | 13/41 [00:27<00:35,  1.26s/it]\n","Epoch (training) 1:  34%|███▍      | 14/41 [00:29<00:41,  1.54s/it]\n","Epoch (training) 1:  37%|███▋      | 15/41 [00:30<00:36,  1.39s/it]\n","Epoch (training) 1:  39%|███▉      | 16/41 [00:31<00:31,  1.27s/it]\n","Epoch (training) 1:  41%|████▏     | 17/41 [00:32<00:27,  1.16s/it]\n","Epoch (training) 1:  44%|████▍     | 18/41 [00:35<00:35,  1.54s/it]\n","Epoch (training) 1:  46%|████▋     | 19/41 [00:36<00:31,  1.45s/it]\n","Epoch (training) 1:  49%|████▉     | 20/41 [00:37<00:26,  1.27s/it]\n","Epoch (training) 1:  51%|█████     | 21/41 [00:38<00:24,  1.24s/it]\n","Epoch (training) 1:  54%|█████▎    | 22/41 [00:39<00:23,  1.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:27:03. Total running time: 1min 0s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr |\n","+----------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095  |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832  |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551 |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569  |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991 |\n","+----------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  56%|█████▌    | 23/41 [00:41<00:23,  1.31s/it]\n","Epoch (training) 1:  59%|█████▊    | 24/41 [00:43<00:27,  1.64s/it]\n","Epoch (training) 1:  61%|██████    | 25/41 [00:44<00:23,  1.49s/it]\n","Epoch (training) 1:  63%|██████▎   | 26/41 [00:45<00:18,  1.23s/it]\n","Epoch (training) 1:  66%|██████▌   | 27/41 [00:46<00:16,  1.17s/it]\n","Epoch (training) 1:  68%|██████▊   | 28/41 [00:47<00:14,  1.15s/it]\n","Epoch (training) 1:  71%|███████   | 29/41 [00:48<00:12,  1.06s/it]\n","Epoch (training) 1:  73%|███████▎  | 30/41 [00:50<00:13,  1.25s/it]\n","Epoch (training) 1:  76%|███████▌  | 31/41 [00:51<00:12,  1.21s/it]\n","Epoch (training) 1:  78%|███████▊  | 32/41 [00:52<00:10,  1.14s/it]\n","Epoch (training) 1:  80%|████████  | 33/41 [00:53<00:08,  1.10s/it]\n","Epoch (training) 1:  83%|████████▎ | 34/41 [00:54<00:07,  1.10s/it]\n","Epoch (training) 1:  85%|████████▌ | 35/41 [00:55<00:05,  1.01it/s]\n","Epoch (training) 1:  88%|████████▊ | 36/41 [00:56<00:05,  1.14s/it]\n","Epoch (training) 1:  90%|█████████ | 37/41 [00:57<00:04,  1.14s/it]\n","Epoch (training) 1:  93%|█████████▎| 38/41 [00:59<00:03,  1.33s/it]\n","Epoch (training) 1:  95%|█████████▌| 39/41 [01:00<00:02,  1.33s/it]\n","Epoch (training) 1:  98%|█████████▊| 40/41 [01:00<00:00,  1.02it/s]\n","Epoch (training) 1: 100%|██████████| 41/41 [01:01<00:00,  1.49s/it]\n","Epoch (test) 1:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 1:   5%|▍         | 1/21 [00:02<00:47,  2.40s/it]\n","Epoch (test) 1:  10%|▉         | 2/21 [00:03<00:35,  1.86s/it]\n","Epoch (test) 1:  14%|█▍        | 3/21 [00:05<00:32,  1.79s/it]\n","Epoch (test) 1:  19%|█▉        | 4/21 [00:06<00:22,  1.34s/it]\n","Epoch (test) 1:  24%|██▍       | 5/21 [00:07<00:20,  1.27s/it]\n","Epoch (test) 1:  29%|██▊       | 6/21 [00:08<00:16,  1.10s/it]\n","Epoch (test) 1:  33%|███▎      | 7/21 [00:09<00:14,  1.05s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:27:33. Total running time: 1min 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr |\n","+----------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095  |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832  |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551 |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569  |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991 |\n","+----------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 1:  38%|███▊      | 8/21 [00:11<00:19,  1.52s/it]\n","Epoch (test) 1:  43%|████▎     | 9/21 [00:13<00:19,  1.66s/it]\n","Epoch (test) 1:  48%|████▊     | 10/21 [00:15<00:19,  1.73s/it]\n","Epoch (test) 1:  52%|█████▏    | 11/21 [00:16<00:13,  1.38s/it]\n","Epoch (test) 1:  57%|█████▋    | 12/21 [00:16<00:10,  1.16s/it]\n","Epoch (test) 1:  62%|██████▏   | 13/21 [00:17<00:08,  1.12s/it]\n","Epoch (test) 1:  67%|██████▋   | 14/21 [00:18<00:07,  1.05s/it]\n","Epoch (test) 1:  71%|███████▏  | 15/21 [00:19<00:05,  1.06it/s]\n","Epoch (test) 1:  76%|███████▌  | 16/21 [00:19<00:04,  1.18it/s]\n","Epoch (test) 1:  81%|████████  | 17/21 [00:20<00:03,  1.19it/s]\n","Epoch (test) 1:  86%|████████▌ | 18/21 [00:21<00:02,  1.17it/s]\n","Epoch (test) 1:  90%|█████████ | 19/21 [00:22<00:01,  1.04it/s]\n","Epoch (test) 1: 100%|██████████| 21/21 [00:23<00:00,  1.10s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000000)\n","Epoch (training) 2:   0%|          | 0/41 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:28:03. Total running time: 2min 0s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         1            107.299   20.3262     0.215289 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 2:   2%|▏         | 1/41 [00:04<02:57,  4.44s/it]\n","Epoch (training) 2:   5%|▍         | 2/41 [00:06<01:50,  2.82s/it]\n","Epoch (training) 2:   7%|▋         | 3/41 [00:06<01:10,  1.85s/it]\n","Epoch (training) 2:  10%|▉         | 4/41 [00:07<00:58,  1.57s/it]\n","Epoch (training) 2:  12%|█▏        | 5/41 [00:09<00:49,  1.38s/it]\n","Epoch (training) 2:  15%|█▍        | 6/41 [00:09<00:40,  1.17s/it]\n","Epoch (training) 2:  17%|█▋        | 7/41 [00:10<00:38,  1.13s/it]\n","Epoch (training) 2:  20%|█▉        | 8/41 [00:12<00:44,  1.35s/it]\n","Epoch (training) 2:  22%|██▏       | 9/41 [00:13<00:37,  1.17s/it]\n","Epoch (training) 2:  24%|██▍       | 10/41 [00:14<00:32,  1.05s/it]\n","Epoch (training) 2:  27%|██▋       | 11/41 [00:15<00:36,  1.23s/it]\n","Epoch (training) 2:  29%|██▉       | 12/41 [00:17<00:38,  1.33s/it]\n","Epoch (training) 2:  32%|███▏      | 13/41 [00:18<00:33,  1.21s/it]\n","Epoch (training) 2:  34%|███▍      | 14/41 [00:19<00:35,  1.32s/it]\n","Epoch (training) 2:  37%|███▋      | 15/41 [00:20<00:32,  1.25s/it]\n","Epoch (training) 2:  39%|███▉      | 16/41 [00:22<00:31,  1.26s/it]\n","Epoch (training) 2:  41%|████▏     | 17/41 [00:24<00:35,  1.47s/it]\n","Epoch (training) 2:  44%|████▍     | 18/41 [00:26<00:38,  1.67s/it]\n","Epoch (training) 2:  46%|████▋     | 19/41 [00:27<00:32,  1.48s/it]\n","Epoch (training) 2:  49%|████▉     | 20/41 [00:28<00:26,  1.24s/it]\n","Epoch (training) 2:  51%|█████     | 21/41 [00:29<00:23,  1.16s/it]\n","Epoch (training) 2:  54%|█████▎    | 22/41 [00:30<00:21,  1.16s/it]\n","Epoch (training) 2:  56%|█████▌    | 23/41 [00:31<00:21,  1.21s/it]\n","Epoch (training) 2:  59%|█████▊    | 24/41 [00:32<00:21,  1.27s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:28:33. Total running time: 2min 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         1            107.299   20.3262     0.215289 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 2:  61%|██████    | 25/41 [00:34<00:20,  1.29s/it]\n","Epoch (training) 2:  63%|██████▎   | 26/41 [00:35<00:18,  1.27s/it]\n","Epoch (training) 2:  66%|██████▌   | 27/41 [00:36<00:15,  1.13s/it]\n","Epoch (training) 2:  68%|██████▊   | 28/41 [00:38<00:18,  1.42s/it]\n","Epoch (training) 2:  71%|███████   | 29/41 [00:39<00:16,  1.37s/it]\n","Epoch (training) 2:  73%|███████▎  | 30/41 [00:41<00:15,  1.43s/it]\n","Epoch (training) 2:  76%|███████▌  | 31/41 [00:42<00:12,  1.25s/it]\n","Epoch (training) 2:  78%|███████▊  | 32/41 [00:42<00:10,  1.12s/it]\n","Epoch (training) 2:  80%|████████  | 33/41 [00:43<00:08,  1.06s/it]\n","Epoch (training) 2:  83%|████████▎ | 34/41 [00:45<00:08,  1.17s/it]\n","Epoch (training) 2:  85%|████████▌ | 35/41 [00:46<00:06,  1.11s/it]\n","Epoch (training) 2:  88%|████████▊ | 36/41 [00:48<00:06,  1.37s/it]\n","Epoch (training) 2:  90%|█████████ | 37/41 [00:50<00:06,  1.68s/it]\n","Epoch (training) 2:  93%|█████████▎| 38/41 [00:51<00:04,  1.59s/it]\n","Epoch (training) 2:  95%|█████████▌| 39/41 [00:53<00:03,  1.55s/it]\n","Epoch (training) 2:  98%|█████████▊| 40/41 [00:53<00:01,  1.14s/it]\n","Epoch (training) 2: 100%|██████████| 41/41 [00:53<00:00,  1.31s/it]\n","Epoch (test) 2:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 2:   5%|▍         | 1/21 [00:02<00:46,  2.34s/it]\n","Epoch (test) 2:  10%|▉         | 2/21 [00:03<00:35,  1.86s/it]\n","Epoch (test) 2:  14%|█▍        | 3/21 [00:05<00:31,  1.74s/it]\n","Epoch (test) 2:  19%|█▉        | 4/21 [00:06<00:23,  1.39s/it]\n","Epoch (test) 2:  24%|██▍       | 5/21 [00:07<00:23,  1.46s/it]\n","Epoch (test) 2:  29%|██▊       | 6/21 [00:08<00:19,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:29:03. Total running time: 3min 0s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         1            107.299   20.3262     0.215289 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 2:  33%|███▎      | 7/21 [00:10<00:18,  1.31s/it]\n","Epoch (test) 2:  38%|███▊      | 8/21 [00:11<00:18,  1.45s/it]\n","Epoch (test) 2:  43%|████▎     | 9/21 [00:13<00:17,  1.43s/it]\n","Epoch (test) 2:  48%|████▊     | 10/21 [00:15<00:16,  1.54s/it]\n","Epoch (test) 2:  52%|█████▏    | 11/21 [00:15<00:12,  1.25s/it]\n","Epoch (test) 2:  57%|█████▋    | 12/21 [00:16<00:09,  1.07s/it]\n","Epoch (test) 2:  62%|██████▏   | 13/21 [00:17<00:08,  1.04s/it]\n","Epoch (test) 2:  67%|██████▋   | 14/21 [00:18<00:06,  1.00it/s]\n","Epoch (test) 2:  71%|███████▏  | 15/21 [00:18<00:05,  1.10it/s]\n","Epoch (test) 2:  76%|███████▌  | 16/21 [00:19<00:04,  1.22it/s]\n","Epoch (test) 2:  81%|████████  | 17/21 [00:20<00:03,  1.21it/s]\n","Epoch (test) 2:  86%|████████▌ | 18/21 [00:21<00:02,  1.03it/s]\n","Epoch (test) 2:  90%|█████████ | 19/21 [00:23<00:02,  1.23s/it]\n","Epoch (test) 2: 100%|██████████| 21/21 [00:23<00:00,  1.13s/it]\n","2024-04-14 08:29:25,906\tWARNING util.py:202 -- The `on_step_begin` operation took 2.824 s, which may be a performance bottleneck.\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000001)\n","Epoch (training) 3:   0%|          | 0/41 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:29:33. Total running time: 3min 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         2            200.452   4.43476     0.198128 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 3:   2%|▏         | 1/41 [00:02<01:25,  2.13s/it]\n","Epoch (training) 3:   5%|▍         | 2/41 [00:03<01:01,  1.57s/it]\n","Epoch (training) 3:   7%|▋         | 3/41 [00:04<00:46,  1.23s/it]\n","Epoch (training) 3:  10%|▉         | 4/41 [00:04<00:38,  1.05s/it]\n","Epoch (training) 3:  12%|█▏        | 5/41 [00:06<00:41,  1.17s/it]\n","Epoch (training) 3:  15%|█▍        | 6/41 [00:07<00:36,  1.04s/it]\n","Epoch (training) 3:  17%|█▋        | 7/41 [00:08<00:36,  1.06s/it]\n","Epoch (training) 3:  20%|█▉        | 8/41 [00:10<00:43,  1.32s/it]\n","Epoch (training) 3:  22%|██▏       | 9/41 [00:11<00:40,  1.28s/it]\n","Epoch (training) 3:  24%|██▍       | 10/41 [00:12<00:40,  1.30s/it]\n","Epoch (training) 3:  27%|██▋       | 11/41 [00:14<00:43,  1.47s/it]\n","Epoch (training) 3:  29%|██▉       | 12/41 [00:15<00:40,  1.38s/it]\n","Epoch (training) 3:  32%|███▏      | 13/41 [00:16<00:38,  1.36s/it]\n","Epoch (training) 3:  34%|███▍      | 14/41 [00:17<00:33,  1.23s/it]\n","Epoch (training) 3:  37%|███▋      | 15/41 [00:19<00:33,  1.29s/it]\n","Epoch (training) 3:  39%|███▉      | 16/41 [00:20<00:32,  1.28s/it]\n","Epoch (training) 3:  41%|████▏     | 17/41 [00:21<00:28,  1.17s/it]\n","Epoch (training) 3:  44%|████▍     | 18/41 [00:22<00:26,  1.17s/it]\n","Epoch (training) 3:  46%|████▋     | 19/41 [00:24<00:28,  1.31s/it]\n","Epoch (training) 3:  49%|████▉     | 20/41 [00:25<00:27,  1.32s/it]\n","Epoch (training) 3:  51%|█████     | 21/41 [00:27<00:32,  1.62s/it]\n","Epoch (training) 3:  54%|█████▎    | 22/41 [00:29<00:32,  1.69s/it]\n","Epoch (training) 3:  56%|█████▌    | 23/41 [00:30<00:26,  1.46s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:30:03. Total running time: 4min 0s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         2            200.452   4.43476     0.198128 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 3:  59%|█████▊    | 24/41 [00:32<00:25,  1.51s/it]\n","Epoch (training) 3:  61%|██████    | 25/41 [00:34<00:26,  1.67s/it]\n","Epoch (training) 3:  63%|██████▎   | 26/41 [00:35<00:21,  1.45s/it]\n","Epoch (training) 3:  66%|██████▌   | 27/41 [00:36<00:19,  1.40s/it]\n","Epoch (training) 3:  68%|██████▊   | 28/41 [00:37<00:16,  1.24s/it]\n","Epoch (training) 3:  71%|███████   | 29/41 [00:38<00:14,  1.17s/it]\n","Epoch (training) 3:  73%|███████▎  | 30/41 [00:40<00:14,  1.28s/it]\n","Epoch (training) 3:  76%|███████▌  | 31/41 [00:41<00:12,  1.26s/it]\n","Epoch (training) 3:  78%|███████▊  | 32/41 [00:43<00:14,  1.60s/it]\n","Epoch (training) 3:  80%|████████  | 33/41 [00:45<00:12,  1.54s/it]\n","Epoch (training) 3:  83%|████████▎ | 34/41 [00:46<00:09,  1.41s/it]\n","Epoch (training) 3:  85%|████████▌ | 35/41 [00:47<00:08,  1.36s/it]\n","Epoch (training) 3:  88%|████████▊ | 36/41 [00:48<00:05,  1.18s/it]\n","Epoch (training) 3:  90%|█████████ | 37/41 [00:48<00:04,  1.09s/it]\n","Epoch (training) 3:  93%|█████████▎| 38/41 [00:50<00:03,  1.11s/it]\n","Epoch (training) 3:  95%|█████████▌| 39/41 [00:50<00:02,  1.01s/it]\n","Epoch (training) 3:  98%|█████████▊| 40/41 [00:51<00:00,  1.31it/s]\n","Epoch (training) 3: 100%|██████████| 41/41 [00:51<00:00,  1.25s/it]\n","Epoch (test) 3:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 3:   5%|▍         | 1/21 [00:02<00:46,  2.33s/it]\n","Epoch (test) 3:  10%|▉         | 2/21 [00:04<00:40,  2.12s/it]\n","Epoch (test) 3:  14%|█▍        | 3/21 [00:06<00:39,  2.21s/it]\n","Epoch (test) 3:  19%|█▉        | 4/21 [00:07<00:29,  1.73s/it]\n","Epoch (test) 3:  24%|██▍       | 5/21 [00:08<00:23,  1.50s/it]\n","Epoch (test) 3:  29%|██▊       | 6/21 [00:09<00:18,  1.25s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:30:33. Total running time: 4min 30s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         2            200.452   4.43476     0.198128 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 3:  33%|███▎      | 7/21 [00:10<00:15,  1.13s/it]\n","Epoch (test) 3:  38%|███▊      | 8/21 [00:12<00:17,  1.33s/it]\n","Epoch (test) 3:  43%|████▎     | 9/21 [00:13<00:16,  1.34s/it]\n","Epoch (test) 3:  48%|████▊     | 10/21 [00:15<00:16,  1.48s/it]\n","Epoch (test) 3:  52%|█████▏    | 11/21 [00:15<00:11,  1.20s/it]\n","Epoch (test) 3:  57%|█████▋    | 12/21 [00:16<00:09,  1.04s/it]\n","Epoch (test) 3:  62%|██████▏   | 13/21 [00:17<00:08,  1.02s/it]\n","Epoch (test) 3:  67%|██████▋   | 14/21 [00:18<00:07,  1.10s/it]\n","Epoch (test) 3:  71%|███████▏  | 15/21 [00:19<00:06,  1.05s/it]\n","Epoch (test) 3:  76%|███████▌  | 16/21 [00:20<00:04,  1.01it/s]\n","Epoch (test) 3:  81%|████████  | 17/21 [00:21<00:04,  1.04s/it]\n","Epoch (test) 3:  86%|████████▌ | 18/21 [00:22<00:03,  1.06s/it]\n","Epoch (test) 3:  90%|█████████ | 19/21 [00:24<00:02,  1.12s/it]\n","Epoch (test) 3: 100%|██████████| 21/21 [00:24<00:00,  1.15s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000002)\n","Epoch (training) 4:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 4:   2%|▏         | 1/41 [00:02<01:30,  2.26s/it]\n","Epoch (training) 4:   5%|▍         | 2/41 [00:03<00:56,  1.44s/it]\n","Epoch (training) 4:   7%|▋         | 3/41 [00:05<01:03,  1.67s/it]\n","Epoch (training) 4:  10%|▉         | 4/41 [00:06<00:54,  1.47s/it]\n","Epoch (training) 4:  12%|█▏        | 5/41 [00:08<01:06,  1.85s/it]\n","Epoch (training) 4:  15%|█▍        | 6/41 [00:09<00:55,  1.58s/it]\n","Epoch (training) 4:  17%|█▋        | 7/41 [00:10<00:46,  1.37s/it]\n","Epoch (training) 4:  20%|█▉        | 8/41 [00:11<00:38,  1.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:31:03. Total running time: 5min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         3            280.012   5.36873     0.235569 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 4:  22%|██▏       | 9/41 [00:12<00:34,  1.07s/it]\n","Epoch (training) 4:  24%|██▍       | 10/41 [00:13<00:37,  1.19s/it]\n","Epoch (training) 4:  27%|██▋       | 11/41 [00:16<00:45,  1.51s/it]\n","Epoch (training) 4:  29%|██▉       | 12/41 [00:16<00:37,  1.29s/it]\n","Epoch (training) 4:  32%|███▏      | 13/41 [00:18<00:35,  1.26s/it]\n","Epoch (training) 4:  34%|███▍      | 14/41 [00:19<00:39,  1.45s/it]\n","Epoch (training) 4:  37%|███▋      | 15/41 [00:21<00:37,  1.43s/it]\n","Epoch (training) 4:  39%|███▉      | 16/41 [00:23<00:38,  1.53s/it]\n","Epoch (training) 4:  41%|████▏     | 17/41 [00:23<00:32,  1.34s/it]\n","Epoch (training) 4:  44%|████▍     | 18/41 [00:25<00:30,  1.31s/it]\n","Epoch (training) 4:  46%|████▋     | 19/41 [00:26<00:25,  1.18s/it]\n","Epoch (training) 4:  49%|████▉     | 20/41 [00:27<00:24,  1.14s/it]\n","Epoch (training) 4:  51%|█████     | 21/41 [00:28<00:24,  1.24s/it]\n","Epoch (training) 4:  54%|█████▎    | 22/41 [00:29<00:22,  1.19s/it]\n","Epoch (training) 4:  56%|█████▌    | 23/41 [00:30<00:21,  1.21s/it]\n","Epoch (training) 4:  59%|█████▊    | 24/41 [00:31<00:19,  1.14s/it]\n","Epoch (training) 4:  61%|██████    | 25/41 [00:33<00:19,  1.20s/it]\n","Epoch (training) 4:  63%|██████▎   | 26/41 [00:36<00:26,  1.78s/it]\n","Epoch (training) 4:  66%|██████▌   | 27/41 [00:37<00:21,  1.56s/it]\n","Epoch (training) 4:  68%|██████▊   | 28/41 [00:38<00:20,  1.55s/it]\n","Epoch (training) 4:  71%|███████   | 29/41 [00:39<00:16,  1.38s/it]\n","Epoch (training) 4:  73%|███████▎  | 30/41 [00:40<00:13,  1.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:31:33. Total running time: 5min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         3            280.012   5.36873     0.235569 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 4:  76%|███████▌  | 31/41 [00:41<00:12,  1.20s/it]\n","Epoch (training) 4:  78%|███████▊  | 32/41 [00:43<00:10,  1.19s/it]\n","Epoch (training) 4:  80%|████████  | 33/41 [00:44<00:08,  1.09s/it]\n","Epoch (training) 4:  83%|████████▎ | 34/41 [00:44<00:06,  1.04it/s]\n","Epoch (training) 4:  85%|████████▌ | 35/41 [00:45<00:05,  1.02it/s]\n","Epoch (training) 4:  88%|████████▊ | 36/41 [00:47<00:05,  1.17s/it]\n","Epoch (training) 4:  90%|█████████ | 37/41 [00:48<00:04,  1.09s/it]\n","Epoch (training) 4:  93%|█████████▎| 38/41 [00:51<00:04,  1.64s/it]\n","Epoch (training) 4:  95%|█████████▌| 39/41 [00:52<00:03,  1.63s/it]\n","Epoch (training) 4:  98%|█████████▊| 40/41 [00:52<00:01,  1.20s/it]\n","Epoch (training) 4: 100%|██████████| 41/41 [00:53<00:00,  1.29s/it]\n","Epoch (test) 4:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 4:   5%|▍         | 1/21 [00:02<00:48,  2.42s/it]\n","Epoch (test) 4:  10%|▉         | 2/21 [00:03<00:35,  1.88s/it]\n","Epoch (test) 4:  14%|█▍        | 3/21 [00:05<00:32,  1.80s/it]\n","Epoch (test) 4:  19%|█▉        | 4/21 [00:06<00:22,  1.35s/it]\n","Epoch (test) 4:  24%|██▍       | 5/21 [00:07<00:20,  1.27s/it]\n","Epoch (test) 4:  29%|██▊       | 6/21 [00:08<00:16,  1.10s/it]\n","Epoch (test) 4:  33%|███▎      | 7/21 [00:09<00:14,  1.03s/it]\n","Epoch (test) 4:  38%|███▊      | 8/21 [00:11<00:17,  1.37s/it]\n","Epoch (test) 4:  43%|████▎     | 9/21 [00:13<00:18,  1.55s/it]\n","Epoch (test) 4:  48%|████▊     | 10/21 [00:15<00:19,  1.77s/it]\n","Epoch (test) 4:  52%|█████▏    | 11/21 [00:15<00:14,  1.41s/it]\n","Epoch (test) 4:  57%|█████▋    | 12/21 [00:16<00:10,  1.18s/it]\n","Epoch (test) 4:  62%|██████▏   | 13/21 [00:17<00:08,  1.12s/it]\n","Epoch (test) 4:  67%|██████▋   | 14/21 [00:18<00:07,  1.06s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:32:03. Total running time: 6min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         3            280.012   5.36873     0.235569 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 4:  71%|███████▏  | 15/21 [00:19<00:05,  1.06it/s]\n","Epoch (test) 4:  76%|███████▌  | 16/21 [00:19<00:04,  1.19it/s]\n","Epoch (test) 4:  81%|████████  | 17/21 [00:20<00:03,  1.19it/s]\n","Epoch (test) 4:  86%|████████▌ | 18/21 [00:21<00:02,  1.16it/s]\n","Epoch (test) 4:  90%|█████████ | 19/21 [00:22<00:01,  1.02it/s]\n","Epoch (test) 4: 100%|██████████| 21/21 [00:22<00:00,  1.09s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000003)\n","Epoch (training) 5:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 5:   2%|▏         | 1/41 [00:01<01:10,  1.76s/it]\n","Epoch (training) 5:   5%|▍         | 2/41 [00:03<00:57,  1.47s/it]\n","Epoch (training) 5:   7%|▋         | 3/41 [00:03<00:45,  1.20s/it]\n","Epoch (training) 5:  10%|▉         | 4/41 [00:04<00:39,  1.07s/it]\n","Epoch (training) 5:  12%|█▏        | 5/41 [00:06<00:44,  1.25s/it]\n","Epoch (training) 5:  15%|█▍        | 6/41 [00:07<00:38,  1.11s/it]\n","Epoch (training) 5:  17%|█▋        | 7/41 [00:08<00:39,  1.16s/it]\n","Epoch (training) 5:  20%|█▉        | 8/41 [00:09<00:34,  1.03s/it]\n","Epoch (training) 5:  22%|██▏       | 9/41 [00:10<00:35,  1.10s/it]\n","Epoch (training) 5:  24%|██▍       | 10/41 [00:12<00:38,  1.24s/it]\n","Epoch (training) 5:  27%|██▋       | 11/41 [00:13<00:35,  1.20s/it]\n","Epoch (training) 5:  29%|██▉       | 12/41 [00:14<00:33,  1.15s/it]\n","Epoch (training) 5:  32%|███▏      | 13/41 [00:15<00:36,  1.29s/it]\n","Epoch (training) 5:  34%|███▍      | 14/41 [00:17<00:40,  1.51s/it]\n","Epoch (training) 5:  37%|███▋      | 15/41 [00:18<00:36,  1.40s/it]\n","Epoch (training) 5:  39%|███▉      | 16/41 [00:20<00:34,  1.38s/it]\n","Epoch (training) 5:  41%|████▏     | 17/41 [00:21<00:31,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:32:33. Total running time: 6min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         4            360.011   2.13563      0.25429 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 5:  44%|████▍     | 18/41 [00:22<00:30,  1.32s/it]\n","Epoch (training) 5:  46%|████▋     | 19/41 [00:24<00:33,  1.52s/it]\n","Epoch (training) 5:  49%|████▉     | 20/41 [00:25<00:26,  1.26s/it]\n","Epoch (training) 5:  51%|█████     | 21/41 [00:26<00:25,  1.25s/it]\n","Epoch (training) 5:  54%|█████▎    | 22/41 [00:27<00:21,  1.13s/it]\n","Epoch (training) 5:  56%|█████▌    | 23/41 [00:30<00:29,  1.61s/it]\n","Epoch (training) 5:  59%|█████▊    | 24/41 [00:31<00:27,  1.59s/it]\n","Epoch (training) 5:  61%|██████    | 25/41 [00:33<00:24,  1.51s/it]\n","Epoch (training) 5:  63%|██████▎   | 26/41 [00:34<00:23,  1.58s/it]\n","Epoch (training) 5:  66%|██████▌   | 27/41 [00:35<00:20,  1.43s/it]\n","Epoch (training) 5:  68%|██████▊   | 28/41 [00:37<00:18,  1.44s/it]\n","Epoch (training) 5:  71%|███████   | 29/41 [00:38<00:15,  1.33s/it]\n","Epoch (training) 5:  73%|███████▎  | 30/41 [00:40<00:15,  1.45s/it]\n","Epoch (training) 5:  76%|███████▌  | 31/41 [00:41<00:13,  1.39s/it]\n","Epoch (training) 5:  78%|███████▊  | 32/41 [00:42<00:11,  1.26s/it]\n","Epoch (training) 5:  80%|████████  | 33/41 [00:43<00:10,  1.32s/it]\n","Epoch (training) 5:  83%|████████▎ | 34/41 [00:45<00:10,  1.52s/it]\n","Epoch (training) 5:  85%|████████▌ | 35/41 [00:46<00:08,  1.34s/it]\n","Epoch (training) 5:  88%|████████▊ | 36/41 [00:47<00:06,  1.26s/it]\n","Epoch (training) 5:  90%|█████████ | 37/41 [00:49<00:05,  1.43s/it]\n","Epoch (training) 5:  93%|█████████▎| 38/41 [00:50<00:04,  1.34s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:33:03. Total running time: 7min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         4            360.011   2.13563      0.25429 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 5:  95%|█████████▌| 39/41 [00:51<00:02,  1.28s/it]\n","Epoch (training) 5:  98%|█████████▊| 40/41 [00:52<00:00,  1.05it/s]\n","Epoch (training) 5: 100%|██████████| 41/41 [00:52<00:00,  1.27s/it]\n","Epoch (test) 5:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 5:   5%|▍         | 1/21 [00:02<00:47,  2.36s/it]\n","Epoch (test) 5:  10%|▉         | 2/21 [00:03<00:35,  1.85s/it]\n","Epoch (test) 5:  14%|█▍        | 3/21 [00:05<00:35,  1.96s/it]\n","Epoch (test) 5:  19%|█▉        | 4/21 [00:06<00:26,  1.56s/it]\n","Epoch (test) 5:  24%|██▍       | 5/21 [00:08<00:24,  1.55s/it]\n","Epoch (test) 5:  29%|██▊       | 6/21 [00:09<00:20,  1.37s/it]\n","Epoch (test) 5:  33%|███▎      | 7/21 [00:10<00:16,  1.20s/it]\n","Epoch (test) 5:  38%|███▊      | 8/21 [00:12<00:17,  1.38s/it]\n","Epoch (test) 5:  43%|████▎     | 9/21 [00:13<00:16,  1.38s/it]\n","Epoch (test) 5:  48%|████▊     | 10/21 [00:15<00:16,  1.51s/it]\n","Epoch (test) 5:  52%|█████▏    | 11/21 [00:15<00:12,  1.22s/it]\n","Epoch (test) 5:  57%|█████▋    | 12/21 [00:16<00:09,  1.06s/it]\n","Epoch (test) 5:  62%|██████▏   | 13/21 [00:17<00:08,  1.04s/it]\n","Epoch (test) 5:  67%|██████▋   | 14/21 [00:18<00:07,  1.02s/it]\n","Epoch (test) 5:  71%|███████▏  | 15/21 [00:19<00:05,  1.07it/s]\n","Epoch (test) 5:  76%|███████▌  | 16/21 [00:20<00:04,  1.08it/s]\n","Epoch (test) 5:  81%|████████  | 17/21 [00:21<00:03,  1.01it/s]\n","Epoch (test) 5:  86%|████████▌ | 18/21 [00:22<00:03,  1.08s/it]\n","Epoch (test) 5:  90%|█████████ | 19/21 [00:24<00:02,  1.26s/it]\n","Epoch (test) 5: 100%|██████████| 21/21 [00:24<00:00,  1.16s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000004)\n","Epoch (training) 6:   0%|          | 0/41 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:33:33. Total running time: 7min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         5            440.725   2.27055     0.216849 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 6:   2%|▏         | 1/41 [00:02<01:28,  2.20s/it]\n","Epoch (training) 6:   5%|▍         | 2/41 [00:03<01:00,  1.56s/it]\n","Epoch (training) 6:   7%|▋         | 3/41 [00:04<00:54,  1.44s/it]\n","Epoch (training) 6:  10%|▉         | 4/41 [00:05<00:46,  1.26s/it]\n","Epoch (training) 6:  12%|█▏        | 5/41 [00:08<01:07,  1.88s/it]\n","Epoch (training) 6:  15%|█▍        | 6/41 [00:09<00:54,  1.57s/it]\n","Epoch (training) 6:  17%|█▋        | 7/41 [00:10<00:49,  1.45s/it]\n","Epoch (training) 6:  20%|█▉        | 8/41 [00:11<00:40,  1.21s/it]\n","Epoch (training) 6:  22%|██▏       | 9/41 [00:12<00:36,  1.15s/it]\n","Epoch (training) 6:  24%|██▍       | 10/41 [00:13<00:38,  1.25s/it]\n","Epoch (training) 6:  27%|██▋       | 11/41 [00:15<00:37,  1.25s/it]\n","Epoch (training) 6:  29%|██▉       | 12/41 [00:16<00:35,  1.22s/it]\n","Epoch (training) 6:  32%|███▏      | 13/41 [00:17<00:35,  1.27s/it]\n","Epoch (training) 6:  34%|███▍      | 14/41 [00:18<00:30,  1.13s/it]\n","Epoch (training) 6:  37%|███▋      | 15/41 [00:20<00:35,  1.35s/it]\n","Epoch (training) 6:  39%|███▉      | 16/41 [00:21<00:33,  1.33s/it]\n","Epoch (training) 6:  41%|████▏     | 17/41 [00:22<00:29,  1.25s/it]\n","Epoch (training) 6:  44%|████▍     | 18/41 [00:24<00:30,  1.32s/it]\n","Epoch (training) 6:  46%|████▋     | 19/41 [00:25<00:28,  1.28s/it]\n","Epoch (training) 6:  49%|████▉     | 20/41 [00:26<00:23,  1.11s/it]\n","Epoch (training) 6:  51%|█████     | 21/41 [00:27<00:22,  1.11s/it]\n","Epoch (training) 6:  54%|█████▎    | 22/41 [00:28<00:22,  1.20s/it]\n","Epoch (training) 6:  56%|█████▌    | 23/41 [00:29<00:18,  1.04s/it]\n","Epoch (training) 6:  59%|█████▊    | 24/41 [00:30<00:18,  1.06s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:34:04. Total running time: 8min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         5            440.725   2.27055     0.216849 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 6:  61%|██████    | 25/41 [00:32<00:20,  1.26s/it]\n","Epoch (training) 6:  63%|██████▎   | 26/41 [00:33<00:18,  1.20s/it]\n","Epoch (training) 6:  66%|██████▌   | 27/41 [00:34<00:16,  1.14s/it]\n","Epoch (training) 6:  68%|██████▊   | 28/41 [00:34<00:12,  1.00it/s]\n","Epoch (training) 6:  71%|███████   | 29/41 [00:36<00:14,  1.18s/it]\n","Epoch (training) 6:  73%|███████▎  | 30/41 [00:38<00:17,  1.56s/it]\n","Epoch (training) 6:  76%|███████▌  | 31/41 [00:40<00:15,  1.52s/it]\n","Epoch (training) 6:  78%|███████▊  | 32/41 [00:41<00:12,  1.41s/it]\n","Epoch (training) 6:  80%|████████  | 33/41 [00:42<00:10,  1.37s/it]\n","Epoch (training) 6:  83%|████████▎ | 34/41 [00:43<00:08,  1.20s/it]\n","Epoch (training) 6:  85%|████████▌ | 35/41 [00:44<00:07,  1.22s/it]\n","Epoch (training) 6:  88%|████████▊ | 36/41 [00:47<00:08,  1.64s/it]\n","Epoch (training) 6:  90%|█████████ | 37/41 [00:48<00:05,  1.42s/it]\n","Epoch (training) 6:  93%|█████████▎| 38/41 [00:50<00:04,  1.53s/it]\n","Epoch (training) 6:  95%|█████████▌| 39/41 [00:51<00:03,  1.53s/it]\n","Epoch (training) 6:  98%|█████████▊| 40/41 [00:51<00:01,  1.13s/it]\n","Epoch (training) 6: 100%|██████████| 41/41 [00:52<00:00,  1.27s/it]\n","Epoch (test) 6:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 6:   5%|▍         | 1/21 [00:03<01:03,  3.15s/it]\n","Epoch (test) 6:  10%|▉         | 2/21 [00:04<00:41,  2.17s/it]\n","Epoch (test) 6:  14%|█▍        | 3/21 [00:06<00:34,  1.94s/it]\n","Epoch (test) 6:  19%|█▉        | 4/21 [00:06<00:24,  1.43s/it]\n","Epoch (test) 6:  24%|██▍       | 5/21 [00:08<00:21,  1.33s/it]\n","Epoch (test) 6:  29%|██▊       | 6/21 [00:08<00:17,  1.14s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:34:34. Total running time: 8min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         5            440.725   2.27055     0.216849 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 6:  33%|███▎      | 7/21 [00:09<00:14,  1.06s/it]\n","Epoch (test) 6:  38%|███▊      | 8/21 [00:11<00:16,  1.27s/it]\n","Epoch (test) 6:  43%|████▎     | 9/21 [00:13<00:16,  1.35s/it]\n","Epoch (test) 6:  48%|████▊     | 10/21 [00:15<00:18,  1.72s/it]\n","Epoch (test) 6:  52%|█████▏    | 11/21 [00:16<00:14,  1.44s/it]\n","Epoch (test) 6:  57%|█████▋    | 12/21 [00:17<00:11,  1.28s/it]\n","Epoch (test) 6:  62%|██████▏   | 13/21 [00:18<00:09,  1.19s/it]\n","Epoch (test) 6:  67%|██████▋   | 14/21 [00:19<00:07,  1.10s/it]\n","Epoch (test) 6:  71%|███████▏  | 15/21 [00:19<00:05,  1.02it/s]\n","Epoch (test) 6:  76%|███████▌  | 16/21 [00:20<00:04,  1.15it/s]\n","Epoch (test) 6:  81%|████████  | 17/21 [00:21<00:03,  1.18it/s]\n","Epoch (test) 6:  86%|████████▌ | 18/21 [00:22<00:02,  1.14it/s]\n","Epoch (test) 6:  90%|█████████ | 19/21 [00:23<00:01,  1.01it/s]\n","Epoch (test) 6: 100%|██████████| 21/21 [00:23<00:00,  1.12s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000005)\n","Epoch (training) 7:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 7:   2%|▏         | 1/41 [00:04<03:03,  4.60s/it]\n","Epoch (training) 7:   5%|▍         | 2/41 [00:05<01:32,  2.37s/it]\n","Epoch (training) 7:   7%|▋         | 3/41 [00:06<01:06,  1.74s/it]\n","Epoch (training) 7:  10%|▉         | 4/41 [00:07<00:58,  1.59s/it]\n","Epoch (training) 7:  12%|█▏        | 5/41 [00:08<00:50,  1.40s/it]\n","Epoch (training) 7:  15%|█▍        | 6/41 [00:10<00:55,  1.57s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:35:04. Total running time: 9min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         6            520.329   2.48129     0.216849 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 7:  17%|█▋        | 7/41 [00:12<00:51,  1.50s/it]\n","Epoch (training) 7:  20%|█▉        | 8/41 [00:13<00:44,  1.35s/it]\n","Epoch (training) 7:  22%|██▏       | 9/41 [00:14<00:42,  1.34s/it]\n","Epoch (training) 7:  24%|██▍       | 10/41 [00:16<00:44,  1.43s/it]\n","Epoch (training) 7:  27%|██▋       | 11/41 [00:17<00:41,  1.37s/it]\n","Epoch (training) 7:  29%|██▉       | 12/41 [00:18<00:38,  1.33s/it]\n","Epoch (training) 7:  32%|███▏      | 13/41 [00:19<00:34,  1.25s/it]\n","Epoch (training) 7:  34%|███▍      | 14/41 [00:20<00:30,  1.14s/it]\n","Epoch (training) 7:  37%|███▋      | 15/41 [00:21<00:27,  1.07s/it]\n","Epoch (training) 7:  39%|███▉      | 16/41 [00:22<00:26,  1.05s/it]\n","Epoch (training) 7:  41%|████▏     | 17/41 [00:23<00:27,  1.14s/it]\n","Epoch (training) 7:  44%|████▍     | 18/41 [00:24<00:24,  1.09s/it]\n","Epoch (training) 7:  46%|████▋     | 19/41 [00:25<00:21,  1.03it/s]\n","Epoch (training) 7:  49%|████▉     | 20/41 [00:26<00:24,  1.15s/it]\n","Epoch (training) 7:  51%|█████     | 21/41 [00:27<00:21,  1.09s/it]\n","Epoch (training) 7:  54%|█████▎    | 22/41 [00:30<00:26,  1.41s/it]\n","Epoch (training) 7:  56%|█████▌    | 23/41 [00:32<00:29,  1.66s/it]\n","Epoch (training) 7:  59%|█████▊    | 24/41 [00:33<00:28,  1.65s/it]\n","Epoch (training) 7:  61%|██████    | 25/41 [00:35<00:26,  1.65s/it]\n","Epoch (training) 7:  63%|██████▎   | 26/41 [00:36<00:20,  1.40s/it]\n","Epoch (training) 7:  66%|██████▌   | 27/41 [00:37<00:17,  1.23s/it]\n","Epoch (training) 7:  68%|██████▊   | 28/41 [00:38<00:14,  1.14s/it]\n","Epoch (training) 7:  71%|███████   | 29/41 [00:40<00:16,  1.34s/it]\n","Epoch (training) 7:  73%|███████▎  | 30/41 [00:41<00:14,  1.35s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:35:34. Total running time: 9min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         6            520.329   2.48129     0.216849 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 7:  76%|███████▌  | 31/41 [00:42<00:11,  1.19s/it]\n","Epoch (training) 7:  78%|███████▊  | 32/41 [00:43<00:10,  1.18s/it]\n","Epoch (training) 7:  80%|████████  | 33/41 [00:44<00:10,  1.28s/it]\n","Epoch (training) 7:  83%|████████▎ | 34/41 [00:45<00:08,  1.23s/it]\n","Epoch (training) 7:  85%|████████▌ | 35/41 [00:48<00:09,  1.56s/it]\n","Epoch (training) 7:  88%|████████▊ | 36/41 [00:49<00:07,  1.42s/it]\n","Epoch (training) 7:  90%|█████████ | 37/41 [00:50<00:05,  1.32s/it]\n","Epoch (training) 7:  93%|█████████▎| 38/41 [00:51<00:03,  1.19s/it]\n","Epoch (training) 7:  95%|█████████▌| 39/41 [00:52<00:02,  1.28s/it]\n","Epoch (training) 7:  98%|█████████▊| 40/41 [00:53<00:00,  1.06it/s]\n","Epoch (training) 7: 100%|██████████| 41/41 [00:53<00:00,  1.30s/it]\n","Epoch (test) 7:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 7:   5%|▍         | 1/21 [00:02<00:46,  2.32s/it]\n","Epoch (test) 7:  10%|▉         | 2/21 [00:03<00:35,  1.86s/it]\n","Epoch (test) 7:  14%|█▍        | 3/21 [00:05<00:32,  1.80s/it]\n","Epoch (test) 7:  19%|█▉        | 4/21 [00:06<00:24,  1.46s/it]\n","Epoch (test) 7:  24%|██▍       | 5/21 [00:08<00:23,  1.49s/it]\n","Epoch (test) 7:  29%|██▊       | 6/21 [00:09<00:20,  1.35s/it]\n","Epoch (test) 7:  33%|███▎      | 7/21 [00:10<00:18,  1.29s/it]\n","Epoch (test) 7:  38%|███▊      | 8/21 [00:12<00:18,  1.43s/it]\n","Epoch (test) 7:  43%|████▎     | 9/21 [00:13<00:16,  1.41s/it]\n","Epoch (test) 7:  48%|████▊     | 10/21 [00:15<00:16,  1.54s/it]\n","Epoch (test) 7:  52%|█████▏    | 11/21 [00:15<00:12,  1.25s/it]\n","Epoch (test) 7:  57%|█████▋    | 12/21 [00:16<00:09,  1.07s/it]\n","Epoch (test) 7:  62%|██████▏   | 13/21 [00:17<00:08,  1.04s/it]\n","Epoch (test) 7:  67%|██████▋   | 14/21 [00:18<00:07,  1.01s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:36:04. Total running time: 10min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         6            520.329   2.48129     0.216849 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 7:  71%|███████▏  | 15/21 [00:19<00:05,  1.10it/s]\n","Epoch (test) 7:  76%|███████▌  | 16/21 [00:19<00:04,  1.21it/s]\n","Epoch (test) 7:  81%|████████  | 17/21 [00:20<00:03,  1.14it/s]\n","Epoch (test) 7:  86%|████████▌ | 18/21 [00:22<00:03,  1.00s/it]\n","Epoch (test) 7:  90%|█████████ | 19/21 [00:23<00:02,  1.24s/it]\n","Epoch (test) 7: 100%|██████████| 21/21 [00:23<00:00,  1.14s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000006)\n","Epoch (training) 8:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 8:   2%|▏         | 1/41 [00:02<01:52,  2.80s/it]\n","Epoch (training) 8:   5%|▍         | 2/41 [00:04<01:25,  2.18s/it]\n","Epoch (training) 8:   7%|▋         | 3/41 [00:06<01:17,  2.04s/it]\n","Epoch (training) 8:  10%|▉         | 4/41 [00:07<01:02,  1.70s/it]\n","Epoch (training) 8:  12%|█▏        | 5/41 [00:09<01:03,  1.76s/it]\n","Epoch (training) 8:  15%|█▍        | 6/41 [00:11<01:03,  1.81s/it]\n","Epoch (training) 8:  17%|█▋        | 7/41 [00:13<01:00,  1.77s/it]\n","Epoch (training) 8:  20%|█▉        | 8/41 [00:14<00:53,  1.63s/it]\n","Epoch (training) 8:  22%|██▏       | 9/41 [00:16<00:51,  1.62s/it]\n","Epoch (training) 8:  24%|██▍       | 10/41 [00:17<00:51,  1.66s/it]\n","Epoch (training) 8:  27%|██▋       | 11/41 [00:18<00:43,  1.44s/it]\n","Epoch (training) 8:  29%|██▉       | 12/41 [00:19<00:37,  1.30s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:36:34. Total running time: 10min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         7            601.775   2.02926     0.307332 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 8:  32%|███▏      | 13/41 [00:21<00:40,  1.45s/it]\n","Epoch (training) 8:  34%|███▍      | 14/41 [00:23<00:41,  1.52s/it]\n","Epoch (training) 8:  37%|███▋      | 15/41 [00:24<00:39,  1.51s/it]\n","Epoch (training) 8:  39%|███▉      | 16/41 [00:26<00:42,  1.71s/it]\n","Epoch (training) 8:  41%|████▏     | 17/41 [00:28<00:37,  1.57s/it]\n","Epoch (training) 8:  44%|████▍     | 18/41 [00:28<00:30,  1.34s/it]\n","Epoch (training) 8:  46%|████▋     | 19/41 [00:29<00:26,  1.21s/it]\n","Epoch (training) 8:  49%|████▉     | 20/41 [00:30<00:23,  1.13s/it]\n","Epoch (training) 8:  51%|█████     | 21/41 [00:31<00:21,  1.09s/it]\n","Epoch (training) 8:  54%|█████▎    | 22/41 [00:32<00:18,  1.03it/s]\n","Epoch (training) 8:  56%|█████▌    | 23/41 [00:33<00:17,  1.03it/s]\n","Epoch (training) 8:  59%|█████▊    | 24/41 [00:34<00:17,  1.02s/it]\n","Epoch (training) 8:  61%|██████    | 25/41 [00:35<00:17,  1.11s/it]\n","Epoch (training) 8:  63%|██████▎   | 26/41 [00:37<00:17,  1.19s/it]\n","Epoch (training) 8:  66%|██████▌   | 27/41 [00:38<00:16,  1.20s/it]\n","Epoch (training) 8:  68%|██████▊   | 28/41 [00:39<00:16,  1.27s/it]\n","Epoch (training) 8:  71%|███████   | 29/41 [00:41<00:16,  1.38s/it]\n","Epoch (training) 8:  73%|███████▎  | 30/41 [00:42<00:13,  1.25s/it]\n","Epoch (training) 8:  76%|███████▌  | 31/41 [00:43<00:11,  1.12s/it]\n","Epoch (training) 8:  78%|███████▊  | 32/41 [00:44<00:10,  1.17s/it]\n","Epoch (training) 8:  80%|████████  | 33/41 [00:45<00:08,  1.05s/it]\n","Epoch (training) 8:  83%|████████▎ | 34/41 [00:46<00:07,  1.02s/it]\n","Epoch (training) 8:  85%|████████▌ | 35/41 [00:47<00:06,  1.03s/it]\n","Epoch (training) 8:  88%|████████▊ | 36/41 [00:48<00:04,  1.03it/s]\n","Epoch (training) 8:  90%|█████████ | 37/41 [00:49<00:04,  1.05s/it]\n","Epoch (training) 8:  93%|█████████▎| 38/41 [00:50<00:03,  1.01s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:37:04. Total running time: 11min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         7            601.775   2.02926     0.307332 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=29490)\u001b[0m \rEpoch (training) 8:  95%|█████████▌| 39/41 [00:52<00:02,  1.22s/it]\n","Epoch (training) 8:  98%|█████████▊| 40/41 [00:52<00:00,  1.11it/s]\n","Epoch (training) 8: 100%|██████████| 41/41 [00:52<00:00,  1.28s/it]\n","Epoch (test) 8:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 8:   5%|▍         | 1/21 [00:03<01:08,  3.41s/it]\n","Epoch (test) 8:  10%|▉         | 2/21 [00:04<00:43,  2.31s/it]\n","Epoch (test) 8:  14%|█▍        | 3/21 [00:06<00:35,  1.99s/it]\n","Epoch (test) 8:  19%|█▉        | 4/21 [00:07<00:24,  1.47s/it]\n","Epoch (test) 8:  24%|██▍       | 5/21 [00:08<00:21,  1.34s/it]\n","Epoch (test) 8:  29%|██▊       | 6/21 [00:09<00:17,  1.15s/it]\n","Epoch (test) 8:  33%|███▎      | 7/21 [00:10<00:14,  1.06s/it]\n","Epoch (test) 8:  38%|███▊      | 8/21 [00:11<00:16,  1.27s/it]\n","Epoch (test) 8:  43%|████▎     | 9/21 [00:13<00:15,  1.29s/it]\n","Epoch (test) 8:  48%|████▊     | 10/21 [00:15<00:18,  1.67s/it]\n","Epoch (test) 8:  52%|█████▏    | 11/21 [00:16<00:13,  1.39s/it]\n","Epoch (test) 8:  57%|█████▋    | 12/21 [00:17<00:11,  1.26s/it]\n","Epoch (test) 8:  62%|██████▏   | 13/21 [00:18<00:09,  1.25s/it]\n","Epoch (test) 8:  67%|██████▋   | 14/21 [00:19<00:08,  1.16s/it]\n","Epoch (test) 8:  71%|███████▏  | 15/21 [00:20<00:06,  1.01s/it]\n","Epoch (test) 8:  76%|███████▌  | 16/21 [00:20<00:04,  1.10it/s]\n","Epoch (test) 8:  81%|████████  | 17/21 [00:21<00:03,  1.15it/s]\n","Epoch (test) 8:  86%|████████▌ | 18/21 [00:22<00:02,  1.12it/s]\n","Epoch (test) 8:  90%|█████████ | 19/21 [00:23<00:02,  1.00s/it]\n","Epoch (test) 8: 100%|██████████| 21/21 [00:23<00:00,  1.14s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000007)\n","Epoch (training) 9:   0%|          | 0/41 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:37:34. Total running time: 11min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         8            681.954   3.8532     0.273011 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                    |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                   |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                    |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                   |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 9:   2%|▏         | 1/41 [00:03<02:03,  3.08s/it]\n","Epoch (training) 9:   5%|▍         | 2/41 [00:04<01:28,  2.28s/it]\n","Epoch (training) 9:   7%|▋         | 3/41 [00:06<01:14,  1.96s/it]\n","Epoch (training) 9:  10%|▉         | 4/41 [00:07<00:55,  1.50s/it]\n","Epoch (training) 9:  12%|█▏        | 5/41 [00:07<00:43,  1.21s/it]\n","Epoch (training) 9:  15%|█▍        | 6/41 [00:08<00:41,  1.17s/it]\n","Epoch (training) 9:  17%|█▋        | 7/41 [00:10<00:45,  1.35s/it]\n","Epoch (training) 9:  20%|█▉        | 8/41 [00:12<00:44,  1.34s/it]\n","Epoch (training) 9:  22%|██▏       | 9/41 [00:13<00:42,  1.33s/it]\n","Epoch (training) 9:  24%|██▍       | 10/41 [00:14<00:42,  1.38s/it]\n","Epoch (training) 9:  27%|██▋       | 11/41 [00:16<00:39,  1.33s/it]\n","Epoch (training) 9:  29%|██▉       | 12/41 [00:18<00:45,  1.58s/it]\n","Epoch (training) 9:  32%|███▏      | 13/41 [00:20<00:49,  1.77s/it]\n","Epoch (training) 9:  34%|███▍      | 14/41 [00:21<00:40,  1.48s/it]\n","Epoch (training) 9:  37%|███▋      | 15/41 [00:22<00:39,  1.50s/it]\n","Epoch (training) 9:  39%|███▉      | 16/41 [00:24<00:36,  1.45s/it]\n","Epoch (training) 9:  41%|████▏     | 17/41 [00:24<00:30,  1.27s/it]\n","Epoch (training) 9:  44%|████▍     | 18/41 [00:25<00:25,  1.10s/it]\n","Epoch (training) 9:  46%|████▋     | 19/41 [00:26<00:23,  1.05s/it]\n","Epoch (training) 9:  49%|████▉     | 20/41 [00:27<00:22,  1.08s/it]\n","Epoch (training) 9:  51%|█████     | 21/41 [00:28<00:20,  1.01s/it]\n","Epoch (training) 9:  54%|█████▎    | 22/41 [00:29<00:20,  1.06s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:38:04. Total running time: 12min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         8            681.954   3.8532     0.273011 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                    |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                   |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                    |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                   |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 9:  56%|█████▌    | 23/41 [00:31<00:22,  1.23s/it]\n","Epoch (training) 9:  59%|█████▊    | 24/41 [00:33<00:24,  1.44s/it]\n","Epoch (training) 9:  61%|██████    | 25/41 [00:34<00:20,  1.27s/it]\n","Epoch (training) 9:  63%|██████▎   | 26/41 [00:35<00:18,  1.25s/it]\n","Epoch (training) 9:  66%|██████▌   | 27/41 [00:36<00:16,  1.19s/it]\n","Epoch (training) 9:  68%|██████▊   | 28/41 [00:37<00:14,  1.08s/it]\n","Epoch (training) 9:  71%|███████   | 29/41 [00:38<00:12,  1.02s/it]\n","Epoch (training) 9:  73%|███████▎  | 30/41 [00:39<00:12,  1.12s/it]\n","Epoch (training) 9:  76%|███████▌  | 31/41 [00:41<00:14,  1.49s/it]\n","Epoch (training) 9:  78%|███████▊  | 32/41 [00:42<00:11,  1.33s/it]\n","Epoch (training) 9:  80%|████████  | 33/41 [00:44<00:11,  1.43s/it]\n","Epoch (training) 9:  83%|████████▎ | 34/41 [00:45<00:10,  1.47s/it]\n","Epoch (training) 9:  85%|████████▌ | 35/41 [00:48<00:10,  1.82s/it]\n","Epoch (training) 9:  88%|████████▊ | 36/41 [00:50<00:08,  1.75s/it]\n","Epoch (training) 9:  90%|█████████ | 37/41 [00:51<00:06,  1.56s/it]\n","Epoch (training) 9:  93%|█████████▎| 38/41 [00:51<00:03,  1.28s/it]\n","Epoch (training) 9:  95%|█████████▌| 39/41 [00:52<00:02,  1.10s/it]\n","Epoch (training) 9:  98%|█████████▊| 40/41 [00:52<00:00,  1.22it/s]\n","Epoch (training) 9: 100%|██████████| 41/41 [00:52<00:00,  1.29s/it]\n","Epoch (test) 9:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 9:   5%|▍         | 1/21 [00:02<00:46,  2.35s/it]\n","Epoch (test) 9:  10%|▉         | 2/21 [00:03<00:34,  1.83s/it]\n","Epoch (test) 9:  14%|█▍        | 3/21 [00:05<00:31,  1.76s/it]\n","Epoch (test) 9:  19%|█▉        | 4/21 [00:06<00:22,  1.31s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:38:34. Total running time: 12min 31s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         8            681.954   3.8532     0.273011 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                    |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                   |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                    |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                   |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 9:  24%|██▍       | 5/21 [00:07<00:22,  1.38s/it]\n","Epoch (test) 9:  29%|██▊       | 6/21 [00:08<00:19,  1.28s/it]\n","Epoch (test) 9:  33%|███▎      | 7/21 [00:09<00:17,  1.27s/it]\n","Epoch (test) 9:  38%|███▊      | 8/21 [00:11<00:19,  1.51s/it]\n","Epoch (test) 9:  43%|████▎     | 9/21 [00:13<00:17,  1.48s/it]\n","Epoch (test) 9:  48%|████▊     | 10/21 [00:15<00:17,  1.58s/it]\n","Epoch (test) 9:  52%|█████▏    | 11/21 [00:15<00:12,  1.28s/it]\n","Epoch (test) 9:  57%|█████▋    | 12/21 [00:16<00:09,  1.08s/it]\n","Epoch (test) 9:  62%|██████▏   | 13/21 [00:17<00:08,  1.06s/it]\n","Epoch (test) 9:  67%|██████▋   | 14/21 [00:18<00:07,  1.02s/it]\n","Epoch (test) 9:  71%|███████▏  | 15/21 [00:19<00:05,  1.09it/s]\n","Epoch (test) 9:  76%|███████▌  | 16/21 [00:19<00:04,  1.21it/s]\n","Epoch (test) 9:  81%|████████  | 17/21 [00:20<00:03,  1.21it/s]\n","Epoch (test) 9:  86%|████████▌ | 18/21 [00:21<00:02,  1.12it/s]\n","Epoch (test) 9:  90%|█████████ | 19/21 [00:23<00:02,  1.18s/it]\n","Epoch (test) 9: 100%|██████████| 21/21 [00:23<00:00,  1.12s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000008)\n","Epoch (training) 10:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 10:   2%|▏         | 1/41 [00:02<01:25,  2.14s/it]\n","Epoch (training) 10:   5%|▍         | 2/41 [00:03<01:03,  1.63s/it]\n","Epoch (training) 10:   7%|▋         | 3/41 [00:04<00:57,  1.52s/it]\n","Epoch (training) 10:  10%|▉         | 4/41 [00:05<00:45,  1.23s/it]\n","Epoch (training) 10:  12%|█▏        | 5/41 [00:06<00:46,  1.29s/it]\n","Epoch (training) 10:  15%|█▍        | 6/41 [00:08<00:45,  1.30s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:39:04. Total running time: 13min 1s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         9            763.404   2.11715     0.293292 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 10:  17%|█▋        | 7/41 [00:09<00:45,  1.33s/it]\n","Epoch (training) 10:  20%|█▉        | 8/41 [00:11<00:47,  1.43s/it]\n","Epoch (training) 10:  22%|██▏       | 9/41 [00:13<00:48,  1.52s/it]\n","Epoch (training) 10:  24%|██▍       | 10/41 [00:14<00:43,  1.40s/it]\n","Epoch (training) 10:  27%|██▋       | 11/41 [00:15<00:44,  1.47s/it]\n","Epoch (training) 10:  29%|██▉       | 12/41 [00:16<00:35,  1.21s/it]\n","Epoch (training) 10:  32%|███▏      | 13/41 [00:17<00:31,  1.14s/it]\n","Epoch (training) 10:  34%|███▍      | 14/41 [00:18<00:30,  1.14s/it]\n","Epoch (training) 10:  37%|███▋      | 15/41 [00:20<00:32,  1.26s/it]\n","Epoch (training) 10:  39%|███▉      | 16/41 [00:21<00:31,  1.25s/it]\n","Epoch (training) 10:  41%|████▏     | 17/41 [00:22<00:32,  1.35s/it]\n","Epoch (training) 10:  44%|████▍     | 18/41 [00:24<00:31,  1.36s/it]\n","Epoch (training) 10:  46%|████▋     | 19/41 [00:26<00:37,  1.73s/it]\n","Epoch (training) 10:  49%|████▉     | 20/41 [00:28<00:37,  1.80s/it]\n","Epoch (training) 10:  51%|█████     | 21/41 [00:29<00:29,  1.47s/it]\n","Epoch (training) 10:  54%|█████▎    | 22/41 [00:30<00:23,  1.23s/it]\n","Epoch (training) 10:  56%|█████▌    | 23/41 [00:30<00:19,  1.09s/it]\n","Epoch (training) 10:  59%|█████▊    | 24/41 [00:32<00:18,  1.11s/it]\n","Epoch (training) 10:  61%|██████    | 25/41 [00:33<00:19,  1.22s/it]\n","Epoch (training) 10:  63%|██████▎   | 26/41 [00:34<00:16,  1.13s/it]\n","Epoch (training) 10:  66%|██████▌   | 27/41 [00:35<00:15,  1.10s/it]\n","Epoch (training) 10:  68%|██████▊   | 28/41 [00:37<00:15,  1.21s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:39:34. Total running time: 13min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         9            763.404   2.11715     0.293292 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 10:  71%|███████   | 29/41 [00:39<00:17,  1.49s/it]\n","Epoch (training) 10:  73%|███████▎  | 30/41 [00:41<00:18,  1.64s/it]\n","Epoch (training) 10:  76%|███████▌  | 31/41 [00:42<00:15,  1.52s/it]\n","Epoch (training) 10:  78%|███████▊  | 32/41 [00:43<00:12,  1.33s/it]\n","Epoch (training) 10:  80%|████████  | 33/41 [00:45<00:12,  1.62s/it]\n","Epoch (training) 10:  83%|████████▎ | 34/41 [00:46<00:10,  1.44s/it]\n","Epoch (training) 10:  85%|████████▌ | 35/41 [00:47<00:07,  1.24s/it]\n","Epoch (training) 10:  88%|████████▊ | 36/41 [00:48<00:05,  1.10s/it]\n","Epoch (training) 10:  90%|█████████ | 37/41 [00:48<00:04,  1.03s/it]\n","Epoch (training) 10:  93%|█████████▎| 38/41 [00:49<00:03,  1.01s/it]\n","Epoch (training) 10:  95%|█████████▌| 39/41 [00:51<00:02,  1.11s/it]\n","Epoch (training) 10:  98%|█████████▊| 40/41 [00:51<00:00,  1.17it/s]\n","Epoch (training) 10: 100%|██████████| 41/41 [00:51<00:00,  1.26s/it]\n","Epoch (test) 10:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 10:   5%|▍         | 1/21 [00:03<01:10,  3.51s/it]\n","Epoch (test) 10:  10%|▉         | 2/21 [00:05<00:47,  2.50s/it]\n","Epoch (test) 10:  14%|█▍        | 3/21 [00:06<00:37,  2.10s/it]\n","Epoch (test) 10:  19%|█▉        | 4/21 [00:07<00:26,  1.54s/it]\n","Epoch (test) 10:  24%|██▍       | 5/21 [00:08<00:22,  1.39s/it]\n","Epoch (test) 10:  29%|██▊       | 6/21 [00:09<00:17,  1.19s/it]\n","Epoch (test) 10:  33%|███▎      | 7/21 [00:10<00:15,  1.08s/it]\n","Epoch (test) 10:  38%|███▊      | 8/21 [00:12<00:16,  1.28s/it]\n","Epoch (test) 10:  43%|████▎     | 9/21 [00:13<00:15,  1.31s/it]\n","Epoch (test) 10:  48%|████▊     | 10/21 [00:15<00:17,  1.57s/it]\n","Epoch (test) 10:  52%|█████▏    | 11/21 [00:16<00:13,  1.32s/it]\n","Epoch (test) 10:  57%|█████▋    | 12/21 [00:17<00:10,  1.20s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:40:04. Total running time: 14min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095         9            763.404   2.11715     0.293292 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 10:  62%|██████▏   | 13/21 [00:18<00:10,  1.27s/it]\n","Epoch (test) 10:  67%|██████▋   | 14/21 [00:19<00:08,  1.20s/it]\n","Epoch (test) 10:  71%|███████▏  | 15/21 [00:20<00:06,  1.04s/it]\n","Epoch (test) 10:  76%|███████▌  | 16/21 [00:21<00:04,  1.08it/s]\n","Epoch (test) 10:  81%|████████  | 17/21 [00:21<00:03,  1.12it/s]\n","Epoch (test) 10:  86%|████████▌ | 18/21 [00:22<00:02,  1.11it/s]\n","Epoch (test) 10:  90%|█████████ | 19/21 [00:24<00:02,  1.00s/it]\n","Epoch (test) 10: 100%|██████████| 21/21 [00:24<00:00,  1.15s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000009)\n","Epoch (training) 11:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 11:   2%|▏         | 1/41 [00:02<01:38,  2.47s/it]\n","Epoch (training) 11:   5%|▍         | 2/41 [00:04<01:27,  2.24s/it]\n","Epoch (training) 11:   7%|▋         | 3/41 [00:06<01:14,  1.96s/it]\n","Epoch (training) 11:  10%|▉         | 4/41 [00:07<01:06,  1.79s/it]\n","Epoch (training) 11:  12%|█▏        | 5/41 [00:09<01:03,  1.76s/it]\n","Epoch (training) 11:  15%|█▍        | 6/41 [00:11<01:00,  1.72s/it]\n","Epoch (training) 11:  17%|█▋        | 7/41 [00:12<00:53,  1.56s/it]\n","Epoch (training) 11:  20%|█▉        | 8/41 [00:13<00:46,  1.41s/it]\n","Epoch (training) 11:  22%|██▏       | 9/41 [00:14<00:40,  1.28s/it]\n","Epoch (training) 11:  24%|██▍       | 10/41 [00:17<00:52,  1.71s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:40:34. Total running time: 14min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        10            843.318   2.35273     0.274571 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 11:  27%|██▋       | 11/41 [00:19<00:59,  1.99s/it]\n","Epoch (training) 11:  29%|██▉       | 12/41 [00:21<00:56,  1.96s/it]\n","Epoch (training) 11:  32%|███▏      | 13/41 [00:22<00:46,  1.68s/it]\n","Epoch (training) 11:  34%|███▍      | 14/41 [00:23<00:39,  1.47s/it]\n","Epoch (training) 11:  37%|███▋      | 15/41 [00:24<00:35,  1.38s/it]\n","Epoch (training) 11:  39%|███▉      | 16/41 [00:25<00:30,  1.21s/it]\n","Epoch (training) 11:  41%|████▏     | 17/41 [00:26<00:26,  1.11s/it]\n","Epoch (training) 11:  44%|████▍     | 18/41 [00:27<00:27,  1.19s/it]\n","Epoch (training) 11:  46%|████▋     | 19/41 [00:28<00:25,  1.14s/it]\n","Epoch (training) 11:  49%|████▉     | 20/41 [00:29<00:23,  1.13s/it]\n","Epoch (training) 11:  51%|█████     | 21/41 [00:31<00:22,  1.14s/it]\n","Epoch (training) 11:  54%|█████▎    | 22/41 [00:32<00:23,  1.22s/it]\n","Epoch (training) 11:  56%|█████▌    | 23/41 [00:34<00:26,  1.47s/it]\n","Epoch (training) 11:  59%|█████▊    | 24/41 [00:35<00:24,  1.41s/it]\n","Epoch (training) 11:  61%|██████    | 25/41 [00:36<00:19,  1.24s/it]\n","Epoch (training) 11:  63%|██████▎   | 26/41 [00:37<00:16,  1.08s/it]\n","Epoch (training) 11:  66%|██████▌   | 27/41 [00:38<00:14,  1.04s/it]\n","Epoch (training) 11:  68%|██████▊   | 28/41 [00:39<00:13,  1.02s/it]\n","Epoch (training) 11:  71%|███████   | 29/41 [00:40<00:11,  1.02it/s]\n","Epoch (training) 11:  73%|███████▎  | 30/41 [00:41<00:11,  1.00s/it]\n","Epoch (training) 11:  76%|███████▌  | 31/41 [00:42<00:11,  1.11s/it]\n","Epoch (training) 11:  78%|███████▊  | 32/41 [00:43<00:10,  1.14s/it]\n","Epoch (training) 11:  80%|████████  | 33/41 [00:44<00:07,  1.04it/s]\n","Epoch (training) 11:  83%|████████▎ | 34/41 [00:45<00:06,  1.13it/s]\n","Epoch (training) 11:  85%|████████▌ | 35/41 [00:45<00:05,  1.12it/s]\n","Epoch (training) 11:  88%|████████▊ | 36/41 [00:47<00:05,  1.05s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:41:04. Total running time: 15min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        10            843.318   2.35273     0.274571 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 11:  90%|█████████ | 37/41 [00:49<00:05,  1.33s/it]\n","Epoch (training) 11:  93%|█████████▎| 38/41 [00:50<00:04,  1.41s/it]\n","Epoch (training) 11:  95%|█████████▌| 39/41 [00:52<00:03,  1.50s/it]\n","Epoch (training) 11:  98%|█████████▊| 40/41 [00:52<00:01,  1.11s/it]\n","Epoch (training) 11: 100%|██████████| 41/41 [00:53<00:00,  1.29s/it]\n","Epoch (test) 11:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 11:   5%|▍         | 1/21 [00:02<00:45,  2.29s/it]\n","Epoch (test) 11:  10%|▉         | 2/21 [00:03<00:34,  1.83s/it]\n","Epoch (test) 11:  14%|█▍        | 3/21 [00:05<00:31,  1.74s/it]\n","Epoch (test) 11:  19%|█▉        | 4/21 [00:06<00:22,  1.33s/it]\n","Epoch (test) 11:  24%|██▍       | 5/21 [00:07<00:20,  1.30s/it]\n","Epoch (test) 11:  29%|██▊       | 6/21 [00:08<00:18,  1.24s/it]\n","Epoch (test) 11:  33%|███▎      | 7/21 [00:09<00:17,  1.23s/it]\n","Epoch (test) 11:  38%|███▊      | 8/21 [00:12<00:20,  1.59s/it]\n","Epoch (test) 11:  43%|████▎     | 9/21 [00:13<00:18,  1.52s/it]\n","Epoch (test) 11:  48%|████▊     | 10/21 [00:15<00:17,  1.61s/it]\n","Epoch (test) 11:  52%|█████▏    | 11/21 [00:15<00:12,  1.30s/it]\n","Epoch (test) 11:  57%|█████▋    | 12/21 [00:16<00:10,  1.12s/it]\n","Epoch (test) 11:  62%|██████▏   | 13/21 [00:17<00:08,  1.08s/it]\n","Epoch (test) 11:  67%|██████▋   | 14/21 [00:18<00:07,  1.04s/it]\n","Epoch (test) 11:  71%|███████▏  | 15/21 [00:19<00:05,  1.08it/s]\n","Epoch (test) 11:  76%|███████▌  | 16/21 [00:19<00:04,  1.18it/s]\n","Epoch (test) 11:  81%|████████  | 17/21 [00:20<00:03,  1.21it/s]\n","Epoch (test) 11:  86%|████████▌ | 18/21 [00:21<00:02,  1.16it/s]\n","Epoch (test) 11:  90%|█████████ | 19/21 [00:23<00:02,  1.13s/it]\n","Epoch (test) 11: 100%|██████████| 21/21 [00:23<00:00,  1.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:41:34. Total running time: 15min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        10            843.318   2.35273     0.274571 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000010)\n","Epoch (training) 12:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 12:   2%|▏         | 1/41 [00:02<01:38,  2.47s/it]\n","Epoch (training) 12:   5%|▍         | 2/41 [00:03<01:06,  1.71s/it]\n","Epoch (training) 12:   7%|▋         | 3/41 [00:04<00:57,  1.52s/it]\n","Epoch (training) 12:  10%|▉         | 4/41 [00:06<00:55,  1.50s/it]\n","Epoch (training) 12:  12%|█▏        | 5/41 [00:08<00:55,  1.54s/it]\n","Epoch (training) 12:  15%|█▍        | 6/41 [00:10<01:00,  1.73s/it]\n","Epoch (training) 12:  17%|█▋        | 7/41 [00:11<00:55,  1.63s/it]\n","Epoch (training) 12:  20%|█▉        | 8/41 [00:12<00:45,  1.39s/it]\n","Epoch (training) 12:  22%|██▏       | 9/41 [00:13<00:40,  1.28s/it]\n","Epoch (training) 12:  24%|██▍       | 10/41 [00:14<00:41,  1.35s/it]\n","Epoch (training) 12:  27%|██▋       | 11/41 [00:16<00:40,  1.35s/it]\n","Epoch (training) 12:  29%|██▉       | 12/41 [00:17<00:37,  1.30s/it]\n","Epoch (training) 12:  32%|███▏      | 13/41 [00:18<00:34,  1.25s/it]\n","Epoch (training) 12:  34%|███▍      | 14/41 [00:20<00:37,  1.39s/it]\n","Epoch (training) 12:  37%|███▋      | 15/41 [00:21<00:35,  1.36s/it]\n","Epoch (training) 12:  39%|███▉      | 16/41 [00:23<00:35,  1.42s/it]\n","Epoch (training) 12:  41%|████▏     | 17/41 [00:24<00:33,  1.39s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:42:04. Total running time: 16min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        11            927.831   11.2517     0.162246 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 12:  44%|████▍     | 18/41 [00:25<00:29,  1.29s/it]\n","Epoch (training) 12:  46%|████▋     | 19/41 [00:26<00:26,  1.22s/it]\n","Epoch (training) 12:  49%|████▉     | 20/41 [00:28<00:28,  1.38s/it]\n","Epoch (training) 12:  51%|█████     | 21/41 [00:30<00:31,  1.56s/it]\n","Epoch (training) 12:  54%|█████▎    | 22/41 [00:31<00:26,  1.39s/it]\n","Epoch (training) 12:  56%|█████▌    | 23/41 [00:32<00:21,  1.20s/it]\n","Epoch (training) 12:  59%|█████▊    | 24/41 [00:33<00:21,  1.25s/it]\n","Epoch (training) 12:  61%|██████    | 25/41 [00:35<00:21,  1.36s/it]\n","Epoch (training) 12:  63%|██████▎   | 26/41 [00:36<00:18,  1.26s/it]\n","Epoch (training) 12:  66%|██████▌   | 27/41 [00:37<00:17,  1.27s/it]\n","Epoch (training) 12:  68%|██████▊   | 28/41 [00:38<00:16,  1.28s/it]\n","Epoch (training) 12:  71%|███████   | 29/41 [00:39<00:14,  1.18s/it]\n","Epoch (training) 12:  73%|███████▎  | 30/41 [00:40<00:11,  1.03s/it]\n","Epoch (training) 12:  76%|███████▌  | 31/41 [00:41<00:11,  1.12s/it]\n","Epoch (training) 12:  78%|███████▊  | 32/41 [00:42<00:10,  1.17s/it]\n","Epoch (training) 12:  80%|████████  | 33/41 [00:44<00:09,  1.18s/it]\n","Epoch (training) 12:  83%|████████▎ | 34/41 [00:45<00:07,  1.10s/it]\n","Epoch (training) 12:  85%|████████▌ | 35/41 [00:46<00:07,  1.18s/it]\n","Epoch (training) 12:  88%|████████▊ | 36/41 [00:47<00:05,  1.04s/it]\n","Epoch (training) 12:  90%|█████████ | 37/41 [00:48<00:04,  1.19s/it]\n","Epoch (training) 12:  93%|█████████▎| 38/41 [00:50<00:04,  1.47s/it]\n","Epoch (training) 12:  95%|█████████▌| 39/41 [00:52<00:03,  1.68s/it]\n","Epoch (training) 12:  98%|█████████▊| 40/41 [00:53<00:01,  1.23s/it]\n","Epoch (training) 12: 100%|██████████| 41/41 [00:53<00:00,  1.30s/it]\n","Epoch (test) 12:   0%|          | 0/21 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:42:34. Total running time: 16min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        11            927.831   11.2517     0.162246 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 12:   5%|▍         | 1/21 [00:02<00:46,  2.31s/it]\n","Epoch (test) 12:  10%|▉         | 2/21 [00:03<00:34,  1.83s/it]\n","Epoch (test) 12:  14%|█▍        | 3/21 [00:05<00:31,  1.75s/it]\n","Epoch (test) 12:  19%|█▉        | 4/21 [00:06<00:22,  1.31s/it]\n","Epoch (test) 12:  24%|██▍       | 5/21 [00:07<00:19,  1.25s/it]\n","Epoch (test) 12:  29%|██▊       | 6/21 [00:07<00:16,  1.08s/it]\n","Epoch (test) 12:  33%|███▎      | 7/21 [00:08<00:14,  1.03s/it]\n","Epoch (test) 12:  38%|███▊      | 8/21 [00:10<00:17,  1.34s/it]\n","Epoch (test) 12:  43%|████▎     | 9/21 [00:12<00:18,  1.53s/it]\n","Epoch (test) 12:  48%|████▊     | 10/21 [00:15<00:19,  1.80s/it]\n","Epoch (test) 12:  52%|█████▏    | 11/21 [00:15<00:14,  1.43s/it]\n","Epoch (test) 12:  57%|█████▋    | 12/21 [00:16<00:10,  1.20s/it]\n","Epoch (test) 12:  62%|██████▏   | 13/21 [00:17<00:09,  1.14s/it]\n","Epoch (test) 12:  67%|██████▋   | 14/21 [00:18<00:07,  1.07s/it]\n","Epoch (test) 12:  71%|███████▏  | 15/21 [00:19<00:05,  1.05it/s]\n","Epoch (test) 12:  76%|███████▌  | 16/21 [00:19<00:04,  1.18it/s]\n","Epoch (test) 12:  81%|████████  | 17/21 [00:20<00:03,  1.19it/s]\n","Epoch (test) 12:  86%|████████▌ | 18/21 [00:21<00:02,  1.16it/s]\n","Epoch (test) 12:  90%|█████████ | 19/21 [00:22<00:01,  1.01it/s]\n","Epoch (test) 12: 100%|██████████| 21/21 [00:22<00:00,  1.09s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000011)\n","Epoch (training) 13:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 13:   2%|▏         | 1/41 [00:03<02:14,  3.37s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:43:04. Total running time: 17min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        12            1008.05   2.84665     0.224649 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 13:   5%|▍         | 2/41 [00:05<01:31,  2.35s/it]\n","Epoch (training) 13:   7%|▋         | 3/41 [00:05<01:02,  1.65s/it]\n","Epoch (training) 13:  10%|▉         | 4/41 [00:07<01:08,  1.85s/it]\n","Epoch (training) 13:  12%|█▏        | 5/41 [00:08<00:51,  1.42s/it]\n","Epoch (training) 13:  15%|█▍        | 6/41 [00:09<00:40,  1.15s/it]\n","Epoch (training) 13:  17%|█▋        | 7/41 [00:11<00:47,  1.39s/it]\n","Epoch (training) 13:  20%|█▉        | 8/41 [00:11<00:39,  1.21s/it]\n","Epoch (training) 13:  22%|██▏       | 9/41 [00:13<00:41,  1.30s/it]\n","Epoch (training) 13:  24%|██▍       | 10/41 [00:14<00:37,  1.22s/it]\n","Epoch (training) 13:  27%|██▋       | 11/41 [00:15<00:37,  1.24s/it]\n","Epoch (training) 13:  29%|██▉       | 12/41 [00:17<00:37,  1.30s/it]\n","Epoch (training) 13:  32%|███▏      | 13/41 [00:18<00:36,  1.30s/it]\n","Epoch (training) 13:  34%|███▍      | 14/41 [00:19<00:34,  1.28s/it]\n","Epoch (training) 13:  37%|███▋      | 15/41 [00:20<00:28,  1.10s/it]\n","Epoch (training) 13:  39%|███▉      | 16/41 [00:22<00:34,  1.37s/it]\n","Epoch (training) 13:  41%|████▏     | 17/41 [00:23<00:28,  1.20s/it]\n","Epoch (training) 13:  44%|████▍     | 18/41 [00:24<00:25,  1.13s/it]\n","Epoch (training) 13:  46%|████▋     | 19/41 [00:25<00:28,  1.30s/it]\n","Epoch (training) 13:  49%|████▉     | 20/41 [00:26<00:25,  1.22s/it]\n","Epoch (training) 13:  51%|█████     | 21/41 [00:28<00:24,  1.24s/it]\n","Epoch (training) 13:  54%|█████▎    | 22/41 [00:29<00:25,  1.36s/it]\n","Epoch (training) 13:  56%|█████▌    | 23/41 [00:31<00:26,  1.48s/it]\n","Epoch (training) 13:  59%|█████▊    | 24/41 [00:32<00:22,  1.31s/it]\n","Epoch (training) 13:  61%|██████    | 25/41 [00:33<00:20,  1.27s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:43:34. Total running time: 17min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        12            1008.05   2.84665     0.224649 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 13:  63%|██████▎   | 26/41 [00:34<00:18,  1.24s/it]\n","Epoch (training) 13:  66%|██████▌   | 27/41 [00:36<00:20,  1.49s/it]\n","Epoch (training) 13:  68%|██████▊   | 28/41 [00:38<00:18,  1.44s/it]\n","Epoch (training) 13:  71%|███████   | 29/41 [00:39<00:14,  1.22s/it]\n","Epoch (training) 13:  73%|███████▎  | 30/41 [00:40<00:13,  1.19s/it]\n","Epoch (training) 13:  76%|███████▌  | 31/41 [00:42<00:14,  1.42s/it]\n","Epoch (training) 13:  78%|███████▊  | 32/41 [00:43<00:13,  1.45s/it]\n","Epoch (training) 13:  80%|████████  | 33/41 [00:45<00:12,  1.59s/it]\n","Epoch (training) 13:  83%|████████▎ | 34/41 [00:46<00:09,  1.42s/it]\n","Epoch (training) 13:  85%|████████▌ | 35/41 [00:47<00:07,  1.25s/it]\n","Epoch (training) 13:  88%|████████▊ | 36/41 [00:49<00:06,  1.36s/it]\n","Epoch (training) 13:  90%|█████████ | 37/41 [00:50<00:04,  1.25s/it]\n","Epoch (training) 13:  93%|█████████▎| 38/41 [00:50<00:03,  1.06s/it]\n","Epoch (training) 13:  95%|█████████▌| 39/41 [00:51<00:01,  1.00it/s]\n","Epoch (training) 13:  98%|█████████▊| 40/41 [00:51<00:00,  1.33it/s]\n","Epoch (training) 13: 100%|██████████| 41/41 [00:51<00:00,  1.26s/it]\n","Epoch (test) 13:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 13:   5%|▍         | 1/21 [00:02<00:46,  2.31s/it]\n","Epoch (test) 13:  10%|▉         | 2/21 [00:03<00:35,  1.85s/it]\n","Epoch (test) 13:  14%|█▍        | 3/21 [00:05<00:35,  1.95s/it]\n","Epoch (test) 13:  19%|█▉        | 4/21 [00:06<00:26,  1.55s/it]\n","Epoch (test) 13:  24%|██▍       | 5/21 [00:08<00:24,  1.54s/it]\n","Epoch (test) 13:  29%|██▊       | 6/21 [00:09<00:20,  1.38s/it]\n","Epoch (test) 13:  33%|███▎      | 7/21 [00:10<00:17,  1.22s/it]\n","Epoch (test) 13:  38%|███▊      | 8/21 [00:12<00:17,  1.38s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:44:05. Total running time: 18min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        12            1008.05   2.84665     0.224649 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 13:  43%|████▎     | 9/21 [00:13<00:16,  1.36s/it]\n","Epoch (test) 13:  48%|████▊     | 10/21 [00:15<00:16,  1.52s/it]\n","Epoch (test) 13:  52%|█████▏    | 11/21 [00:15<00:12,  1.22s/it]\n","Epoch (test) 13:  57%|█████▋    | 12/21 [00:16<00:09,  1.06s/it]\n","Epoch (test) 13:  62%|██████▏   | 13/21 [00:17<00:08,  1.05s/it]\n","Epoch (test) 13:  67%|██████▋   | 14/21 [00:18<00:07,  1.02s/it]\n","Epoch (test) 13:  71%|███████▏  | 15/21 [00:19<00:05,  1.10it/s]\n","Epoch (test) 13:  76%|███████▌  | 16/21 [00:19<00:04,  1.15it/s]\n","Epoch (test) 13:  81%|████████  | 17/21 [00:20<00:03,  1.06it/s]\n","Epoch (test) 13:  86%|████████▌ | 18/21 [00:22<00:03,  1.04s/it]\n","Epoch (test) 13:  90%|█████████ | 19/21 [00:24<00:02,  1.26s/it]\n","Epoch (test) 13: 100%|██████████| 21/21 [00:24<00:00,  1.15s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000012)\n","Epoch (training) 14:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 14:   2%|▏         | 1/41 [00:04<02:45,  4.13s/it]\n","Epoch (training) 14:   5%|▍         | 2/41 [00:05<01:35,  2.45s/it]\n","Epoch (training) 14:   7%|▋         | 3/41 [00:07<01:20,  2.11s/it]\n","Epoch (training) 14:  10%|▉         | 4/41 [00:08<01:13,  1.98s/it]\n","Epoch (training) 14:  12%|█▏        | 5/41 [00:09<00:56,  1.58s/it]\n","Epoch (training) 14:  15%|█▍        | 6/41 [00:10<00:50,  1.45s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:44:35. Total running time: 18min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        13            1089.34   2.12365     0.273011 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 14:  17%|█▋        | 7/41 [00:13<00:59,  1.75s/it]\n","Epoch (training) 14:  20%|█▉        | 8/41 [00:14<00:49,  1.49s/it]\n","Epoch (training) 14:  22%|██▏       | 9/41 [00:15<00:49,  1.55s/it]\n","Epoch (training) 14:  24%|██▍       | 10/41 [00:16<00:42,  1.37s/it]\n","Epoch (training) 14:  27%|██▋       | 11/41 [00:18<00:39,  1.31s/it]\n","Epoch (training) 14:  29%|██▉       | 12/41 [00:19<00:34,  1.20s/it]\n","Epoch (training) 14:  32%|███▏      | 13/41 [00:21<00:41,  1.48s/it]\n","Epoch (training) 14:  34%|███▍      | 14/41 [00:22<00:35,  1.33s/it]\n","Epoch (training) 14:  37%|███▋      | 15/41 [00:23<00:35,  1.38s/it]\n","Epoch (training) 14:  39%|███▉      | 16/41 [00:25<00:37,  1.49s/it]\n","Epoch (training) 14:  41%|████▏     | 17/41 [00:26<00:36,  1.51s/it]\n","Epoch (training) 14:  44%|████▍     | 18/41 [00:27<00:30,  1.31s/it]\n","Epoch (training) 14:  46%|████▋     | 19/41 [00:28<00:27,  1.26s/it]\n","Epoch (training) 14:  49%|████▉     | 20/41 [00:29<00:23,  1.12s/it]\n","Epoch (training) 14:  51%|█████     | 21/41 [00:31<00:24,  1.22s/it]\n","Epoch (training) 14:  54%|█████▎    | 22/41 [00:32<00:24,  1.27s/it]\n","Epoch (training) 14:  56%|█████▌    | 23/41 [00:33<00:19,  1.06s/it]\n","Epoch (training) 14:  59%|█████▊    | 24/41 [00:34<00:17,  1.00s/it]\n","Epoch (training) 14:  61%|██████    | 25/41 [00:35<00:17,  1.09s/it]\n","Epoch (training) 14:  63%|██████▎   | 26/41 [00:36<00:16,  1.12s/it]\n","Epoch (training) 14:  66%|██████▌   | 27/41 [00:38<00:19,  1.37s/it]\n","Epoch (training) 14:  68%|██████▊   | 28/41 [00:39<00:17,  1.36s/it]\n","Epoch (training) 14:  71%|███████   | 29/41 [00:40<00:14,  1.21s/it]\n","Epoch (training) 14:  73%|███████▎  | 30/41 [00:41<00:12,  1.13s/it]\n","Epoch (training) 14:  76%|███████▌  | 31/41 [00:42<00:10,  1.03s/it]\n","Epoch (training) 14:  78%|███████▊  | 32/41 [00:43<00:08,  1.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:45:05. Total running time: 19min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        13            1089.34   2.12365     0.273011 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 14:  80%|████████  | 33/41 [00:44<00:08,  1.05s/it]\n","Epoch (training) 14:  83%|████████▎ | 34/41 [00:45<00:08,  1.16s/it]\n","Epoch (training) 14:  85%|████████▌ | 35/41 [00:47<00:07,  1.21s/it]\n","Epoch (training) 14:  88%|████████▊ | 36/41 [00:47<00:05,  1.08s/it]\n","Epoch (training) 14:  90%|█████████ | 37/41 [00:49<00:04,  1.08s/it]\n","Epoch (training) 14:  93%|█████████▎| 38/41 [00:50<00:03,  1.16s/it]\n","Epoch (training) 14:  95%|█████████▌| 39/41 [00:52<00:02,  1.38s/it]\n","Epoch (training) 14:  98%|█████████▊| 40/41 [00:52<00:01,  1.02s/it]\n","Epoch (training) 14: 100%|██████████| 41/41 [00:52<00:00,  1.28s/it]\n","Epoch (test) 14:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 14:   5%|▍         | 1/21 [00:02<00:50,  2.55s/it]\n","Epoch (test) 14:  10%|▉         | 2/21 [00:04<00:36,  1.92s/it]\n","Epoch (test) 14:  14%|█▍        | 3/21 [00:05<00:32,  1.80s/it]\n","Epoch (test) 14:  19%|█▉        | 4/21 [00:06<00:22,  1.35s/it]\n","Epoch (test) 14:  24%|██▍       | 5/21 [00:07<00:20,  1.28s/it]\n","Epoch (test) 14:  29%|██▊       | 6/21 [00:08<00:16,  1.11s/it]\n","Epoch (test) 14:  33%|███▎      | 7/21 [00:09<00:14,  1.05s/it]\n","Epoch (test) 14:  38%|███▊      | 8/21 [00:10<00:16,  1.27s/it]\n","Epoch (test) 14:  43%|████▎     | 9/21 [00:12<00:17,  1.48s/it]\n","Epoch (test) 14:  48%|████▊     | 10/21 [00:15<00:20,  1.83s/it]\n","Epoch (test) 14:  52%|█████▏    | 11/21 [00:16<00:14,  1.45s/it]\n","Epoch (test) 14:  57%|█████▋    | 12/21 [00:16<00:10,  1.22s/it]\n","Epoch (test) 14:  62%|██████▏   | 13/21 [00:17<00:09,  1.16s/it]\n","Epoch (test) 14:  67%|██████▋   | 14/21 [00:18<00:07,  1.08s/it]\n","Epoch (test) 14:  71%|███████▏  | 15/21 [00:19<00:05,  1.03it/s]\n","Epoch (test) 14:  76%|███████▌  | 16/21 [00:20<00:04,  1.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:45:35. Total running time: 19min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        13            1089.34   2.12365     0.273011 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 14:  81%|████████  | 17/21 [00:20<00:03,  1.18it/s]\n","Epoch (test) 14:  86%|████████▌ | 18/21 [00:21<00:02,  1.14it/s]\n","Epoch (test) 14:  90%|█████████ | 19/21 [00:23<00:01,  1.01it/s]\n","Epoch (test) 14: 100%|██████████| 21/21 [00:23<00:00,  1.10s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000013)\n","Epoch (training) 15:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 15:   2%|▏         | 1/41 [00:01<01:05,  1.63s/it]\n","Epoch (training) 15:   5%|▍         | 2/41 [00:03<01:01,  1.57s/it]\n","Epoch (training) 15:   7%|▋         | 3/41 [00:04<00:50,  1.33s/it]\n","Epoch (training) 15:  10%|▉         | 4/41 [00:05<00:46,  1.26s/it]\n","Epoch (training) 15:  12%|█▏        | 5/41 [00:06<00:39,  1.09s/it]\n","Epoch (training) 15:  15%|█▍        | 6/41 [00:07<00:40,  1.16s/it]\n","Epoch (training) 15:  17%|█▋        | 7/41 [00:10<00:59,  1.74s/it]\n","Epoch (training) 15:  20%|█▉        | 8/41 [00:11<00:54,  1.66s/it]\n","Epoch (training) 15:  22%|██▏       | 9/41 [00:13<00:55,  1.73s/it]\n","Epoch (training) 15:  24%|██▍       | 10/41 [00:14<00:43,  1.41s/it]\n","Epoch (training) 15:  27%|██▋       | 11/41 [00:16<00:49,  1.65s/it]\n","Epoch (training) 15:  29%|██▉       | 12/41 [00:17<00:44,  1.53s/it]\n","Epoch (training) 15:  32%|███▏      | 13/41 [00:18<00:36,  1.31s/it]\n","Epoch (training) 15:  34%|███▍      | 14/41 [00:19<00:32,  1.19s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:46:05. Total running time: 20min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        14            1172.51     2.11      0.26053 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                    |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                   |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                    |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                   |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 15:  37%|███▋      | 15/41 [00:21<00:33,  1.30s/it]\n","Epoch (training) 15:  39%|███▉      | 16/41 [00:22<00:33,  1.33s/it]\n","Epoch (training) 15:  41%|████▏     | 17/41 [00:24<00:35,  1.47s/it]\n","Epoch (training) 15:  44%|████▍     | 18/41 [00:25<00:33,  1.46s/it]\n","Epoch (training) 15:  46%|████▋     | 19/41 [00:27<00:33,  1.51s/it]\n","Epoch (training) 15:  49%|████▉     | 20/41 [00:28<00:29,  1.41s/it]\n","Epoch (training) 15:  51%|█████     | 21/41 [00:29<00:23,  1.19s/it]\n","Epoch (training) 15:  54%|█████▎    | 22/41 [00:30<00:20,  1.08s/it]\n","Epoch (training) 15:  56%|█████▌    | 23/41 [00:32<00:27,  1.52s/it]\n","Epoch (training) 15:  59%|█████▊    | 24/41 [00:34<00:25,  1.49s/it]\n","Epoch (training) 15:  61%|██████    | 25/41 [00:35<00:21,  1.36s/it]\n","Epoch (training) 15:  63%|██████▎   | 26/41 [00:36<00:18,  1.24s/it]\n","Epoch (training) 15:  66%|██████▌   | 27/41 [00:37<00:17,  1.22s/it]\n","Epoch (training) 15:  68%|██████▊   | 28/41 [00:38<00:17,  1.31s/it]\n","Epoch (training) 15:  71%|███████   | 29/41 [00:40<00:16,  1.37s/it]\n","Epoch (training) 15:  73%|███████▎  | 30/41 [00:41<00:13,  1.24s/it]\n","Epoch (training) 15:  76%|███████▌  | 31/41 [00:43<00:14,  1.45s/it]\n","Epoch (training) 15:  78%|███████▊  | 32/41 [00:44<00:11,  1.32s/it]\n","Epoch (training) 15:  80%|████████  | 33/41 [00:44<00:09,  1.16s/it]\n","Epoch (training) 15:  83%|████████▎ | 34/41 [00:46<00:08,  1.22s/it]\n","Epoch (training) 15:  85%|████████▌ | 35/41 [00:47<00:07,  1.20s/it]\n","Epoch (training) 15:  88%|████████▊ | 36/41 [00:48<00:06,  1.27s/it]\n","Epoch (training) 15:  90%|█████████ | 37/41 [00:49<00:04,  1.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:46:35. Total running time: 20min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        14            1172.51     2.11      0.26053 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                    |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                   |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                    |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                   |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 15:  93%|█████████▎| 38/41 [00:50<00:03,  1.09s/it]\n","Epoch (training) 15:  95%|█████████▌| 39/41 [00:52<00:02,  1.15s/it]\n","Epoch (training) 15:  98%|█████████▊| 40/41 [00:52<00:00,  1.17it/s]\n","Epoch (training) 15: 100%|██████████| 41/41 [00:52<00:00,  1.28s/it]\n","Epoch (test) 15:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 15:   5%|▍         | 1/21 [00:03<01:07,  3.40s/it]\n","Epoch (test) 15:  10%|▉         | 2/21 [00:05<00:50,  2.66s/it]\n","Epoch (test) 15:  14%|█▍        | 3/21 [00:07<00:39,  2.20s/it]\n","Epoch (test) 15:  19%|█▉        | 4/21 [00:07<00:27,  1.60s/it]\n","Epoch (test) 15:  24%|██▍       | 5/21 [00:08<00:22,  1.42s/it]\n","Epoch (test) 15:  29%|██▊       | 6/21 [00:09<00:18,  1.20s/it]\n","Epoch (test) 15:  33%|███▎      | 7/21 [00:10<00:15,  1.10s/it]\n","Epoch (test) 15:  38%|███▊      | 8/21 [00:12<00:16,  1.30s/it]\n","Epoch (test) 15:  43%|████▎     | 9/21 [00:13<00:15,  1.32s/it]\n","Epoch (test) 15:  48%|████▊     | 10/21 [00:15<00:16,  1.51s/it]\n","Epoch (test) 15:  52%|█████▏    | 11/21 [00:16<00:12,  1.28s/it]\n","Epoch (test) 15:  57%|█████▋    | 12/21 [00:17<00:10,  1.17s/it]\n","Epoch (test) 15:  62%|██████▏   | 13/21 [00:18<00:10,  1.25s/it]\n","Epoch (test) 15:  67%|██████▋   | 14/21 [00:20<00:08,  1.28s/it]\n","Epoch (test) 15:  71%|███████▏  | 15/21 [00:20<00:06,  1.11s/it]\n","Epoch (test) 15:  76%|███████▌  | 16/21 [00:21<00:04,  1.04it/s]\n","Epoch (test) 15:  81%|████████  | 17/21 [00:22<00:03,  1.08it/s]\n","Epoch (test) 15:  86%|████████▌ | 18/21 [00:23<00:02,  1.08it/s]\n","Epoch (test) 15:  90%|█████████ | 19/21 [00:24<00:02,  1.04s/it]\n","Epoch (test) 15: 100%|██████████| 21/21 [00:24<00:00,  1.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:47:05. Total running time: 21min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        14            1172.51     2.11      0.26053 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                    |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                   |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                    |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                   |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000014)\n","Epoch (training) 16:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 16:   2%|▏         | 1/41 [00:03<02:25,  3.63s/it]\n","Epoch (training) 16:   5%|▍         | 2/41 [00:04<01:23,  2.13s/it]\n","Epoch (training) 16:   7%|▋         | 3/41 [00:06<01:23,  2.19s/it]\n","Epoch (training) 16:  10%|▉         | 4/41 [00:08<01:10,  1.90s/it]\n","Epoch (training) 16:  12%|█▏        | 5/41 [00:09<01:01,  1.70s/it]\n","Epoch (training) 16:  15%|█▍        | 6/41 [00:10<00:49,  1.42s/it]\n","Epoch (training) 16:  17%|█▋        | 7/41 [00:11<00:42,  1.26s/it]\n","Epoch (training) 16:  20%|█▉        | 8/41 [00:13<00:43,  1.31s/it]\n","Epoch (training) 16:  22%|██▏       | 9/41 [00:14<00:44,  1.39s/it]\n","Epoch (training) 16:  24%|██▍       | 10/41 [00:16<00:45,  1.47s/it]\n","Epoch (training) 16:  27%|██▋       | 11/41 [00:17<00:45,  1.51s/it]\n","Epoch (training) 16:  29%|██▉       | 12/41 [00:18<00:40,  1.39s/it]\n","Epoch (training) 16:  32%|███▏      | 13/41 [00:20<00:38,  1.36s/it]\n","Epoch (training) 16:  34%|███▍      | 14/41 [00:21<00:32,  1.20s/it]\n","Epoch (training) 16:  37%|███▋      | 15/41 [00:21<00:27,  1.07s/it]\n","Epoch (training) 16:  39%|███▉      | 16/41 [00:23<00:33,  1.34s/it]\n","Epoch (training) 16:  41%|████▏     | 17/41 [00:24<00:28,  1.19s/it]\n","Epoch (training) 16:  44%|████▍     | 18/41 [00:26<00:29,  1.29s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:47:35. Total running time: 21min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        15            1256.36   2.10914      0.26209 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 16:  46%|████▋     | 19/41 [00:27<00:29,  1.33s/it]\n","Epoch (training) 16:  49%|████▉     | 20/41 [00:28<00:27,  1.30s/it]\n","Epoch (training) 16:  51%|█████     | 21/41 [00:31<00:31,  1.58s/it]\n","Epoch (training) 16:  54%|█████▎    | 22/41 [00:32<00:32,  1.70s/it]\n","Epoch (training) 16:  56%|█████▌    | 23/41 [00:34<00:26,  1.49s/it]\n","Epoch (training) 16:  59%|█████▊    | 24/41 [00:35<00:23,  1.39s/it]\n","Epoch (training) 16:  61%|██████    | 25/41 [00:36<00:20,  1.26s/it]\n","Epoch (training) 16:  63%|██████▎   | 26/41 [00:37<00:18,  1.26s/it]\n","Epoch (training) 16:  66%|██████▌   | 27/41 [00:38<00:15,  1.11s/it]\n","Epoch (training) 16:  68%|██████▊   | 28/41 [00:38<00:13,  1.02s/it]\n","Epoch (training) 16:  71%|███████   | 29/41 [00:39<00:11,  1.06it/s]\n","Epoch (training) 16:  73%|███████▎  | 30/41 [00:40<00:09,  1.15it/s]\n","Epoch (training) 16:  76%|███████▌  | 31/41 [00:41<00:09,  1.01it/s]\n","Epoch (training) 16:  78%|███████▊  | 32/41 [00:43<00:11,  1.30s/it]\n","Epoch (training) 16:  80%|████████  | 33/41 [00:46<00:13,  1.66s/it]\n","Epoch (training) 16:  83%|████████▎ | 34/41 [00:47<00:10,  1.55s/it]\n","Epoch (training) 16:  85%|████████▌ | 35/41 [00:48<00:08,  1.50s/it]\n","Epoch (training) 16:  88%|████████▊ | 36/41 [00:49<00:06,  1.26s/it]\n","Epoch (training) 16:  90%|█████████ | 37/41 [00:50<00:04,  1.14s/it]\n","Epoch (training) 16:  93%|█████████▎| 38/41 [00:51<00:03,  1.14s/it]\n","Epoch (training) 16:  95%|█████████▌| 39/41 [00:52<00:02,  1.14s/it]\n","Epoch (training) 16:  98%|█████████▊| 40/41 [00:52<00:00,  1.18it/s]\n","Epoch (training) 16: 100%|██████████| 41/41 [00:53<00:00,  1.29s/it]\n","Epoch (test) 16:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 16:   5%|▍         | 1/21 [00:02<00:47,  2.40s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:48:05. Total running time: 22min 2s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        15            1256.36   2.10914      0.26209 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 16:  10%|▉         | 2/21 [00:03<00:35,  1.88s/it]\n","Epoch (test) 16:  14%|█▍        | 3/21 [00:06<00:35,  1.98s/it]\n","Epoch (test) 16:  19%|█▉        | 4/21 [00:06<00:26,  1.57s/it]\n","Epoch (test) 16:  24%|██▍       | 5/21 [00:08<00:25,  1.57s/it]\n","Epoch (test) 16:  29%|██▊       | 6/21 [00:09<00:20,  1.39s/it]\n","Epoch (test) 16:  33%|███▎      | 7/21 [00:10<00:17,  1.22s/it]\n","Epoch (test) 16:  38%|███▊      | 8/21 [00:12<00:18,  1.39s/it]\n","Epoch (test) 16:  43%|████▎     | 9/21 [00:13<00:16,  1.38s/it]\n","Epoch (test) 16:  48%|████▊     | 10/21 [00:15<00:16,  1.53s/it]\n","Epoch (test) 16:  52%|█████▏    | 11/21 [00:15<00:12,  1.23s/it]\n","Epoch (test) 16:  57%|█████▋    | 12/21 [00:16<00:09,  1.06s/it]\n","Epoch (test) 16:  62%|██████▏   | 13/21 [00:17<00:08,  1.04s/it]\n","Epoch (test) 16:  67%|██████▋   | 14/21 [00:18<00:07,  1.01s/it]\n","Epoch (test) 16:  71%|███████▏  | 15/21 [00:19<00:05,  1.09it/s]\n","Epoch (test) 16:  76%|███████▌  | 16/21 [00:20<00:04,  1.12it/s]\n","Epoch (test) 16:  81%|████████  | 17/21 [00:21<00:03,  1.03it/s]\n","Epoch (test) 16:  86%|████████▌ | 18/21 [00:22<00:03,  1.07s/it]\n","Epoch (test) 16:  90%|█████████ | 19/21 [00:24<00:02,  1.29s/it]\n","Epoch (test) 16: 100%|██████████| 21/21 [00:24<00:00,  1.16s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:48:35. Total running time: 22min 32s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        15            1256.36   2.10914      0.26209 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000015)\n","Epoch (training) 17:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 17:   2%|▏         | 1/41 [00:02<01:55,  2.89s/it]\n","Epoch (training) 17:   5%|▍         | 2/41 [00:04<01:15,  1.94s/it]\n","Epoch (training) 17:   7%|▋         | 3/41 [00:05<01:08,  1.80s/it]\n","Epoch (training) 17:  10%|▉         | 4/41 [00:08<01:13,  2.00s/it]\n","Epoch (training) 17:  12%|█▏        | 5/41 [00:09<01:08,  1.91s/it]\n","Epoch (training) 17:  15%|█▍        | 6/41 [00:11<00:59,  1.71s/it]\n","Epoch (training) 17:  17%|█▋        | 7/41 [00:12<00:48,  1.43s/it]\n","Epoch (training) 17:  20%|█▉        | 8/41 [00:13<00:48,  1.47s/it]\n","Epoch (training) 17:  22%|██▏       | 9/41 [00:14<00:43,  1.35s/it]\n","Epoch (training) 17:  24%|██▍       | 10/41 [00:16<00:42,  1.37s/it]\n","Epoch (training) 17:  27%|██▋       | 11/41 [00:17<00:39,  1.32s/it]\n","Epoch (training) 17:  29%|██▉       | 12/41 [00:18<00:37,  1.30s/it]\n","Epoch (training) 17:  32%|███▏      | 13/41 [00:20<00:38,  1.38s/it]\n","Epoch (training) 17:  34%|███▍      | 14/41 [00:20<00:31,  1.16s/it]\n","Epoch (training) 17:  37%|███▋      | 15/41 [00:22<00:30,  1.19s/it]\n","Epoch (training) 17:  39%|███▉      | 16/41 [00:23<00:28,  1.16s/it]\n","Epoch (training) 17:  41%|████▏     | 17/41 [00:24<00:29,  1.25s/it]\n","Epoch (training) 17:  44%|████▍     | 18/41 [00:25<00:26,  1.15s/it]\n","Epoch (training) 17:  46%|████▋     | 19/41 [00:26<00:24,  1.10s/it]\n","Epoch (training) 17:  49%|████▉     | 20/41 [00:27<00:21,  1.02s/it]\n","Epoch (training) 17:  51%|█████     | 21/41 [00:29<00:24,  1.24s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:49:05. Total running time: 23min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        16            1343.56   2.04043     0.293292 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 17:  54%|█████▎    | 22/41 [00:29<00:21,  1.14s/it]\n","Epoch (training) 17:  56%|█████▌    | 23/41 [00:31<00:21,  1.22s/it]\n","Epoch (training) 17:  59%|█████▊    | 24/41 [00:32<00:20,  1.18s/it]\n","Epoch (training) 17:  61%|██████    | 25/41 [00:34<00:21,  1.31s/it]\n","Epoch (training) 17:  63%|██████▎   | 26/41 [00:35<00:17,  1.20s/it]\n","Epoch (training) 17:  66%|██████▌   | 27/41 [00:36<00:16,  1.15s/it]\n","Epoch (training) 17:  68%|██████▊   | 28/41 [00:37<00:16,  1.23s/it]\n","Epoch (training) 17:  71%|███████   | 29/41 [00:38<00:13,  1.16s/it]\n","Epoch (training) 17:  73%|███████▎  | 30/41 [00:39<00:12,  1.18s/it]\n","Epoch (training) 17:  76%|███████▌  | 31/41 [00:41<00:12,  1.27s/it]\n","Epoch (training) 17:  78%|███████▊  | 32/41 [00:42<00:12,  1.43s/it]\n","Epoch (training) 17:  80%|████████  | 33/41 [00:43<00:10,  1.25s/it]\n","Epoch (training) 17:  83%|████████▎ | 34/41 [00:45<00:08,  1.26s/it]\n","Epoch (training) 17:  85%|████████▌ | 35/41 [00:46<00:08,  1.35s/it]\n","Epoch (training) 17:  88%|████████▊ | 36/41 [00:48<00:08,  1.64s/it]\n","Epoch (training) 17:  90%|█████████ | 37/41 [00:50<00:06,  1.55s/it]\n","Epoch (training) 17:  93%|█████████▎| 38/41 [00:51<00:04,  1.58s/it]\n","Epoch (training) 17:  95%|█████████▌| 39/41 [00:52<00:02,  1.40s/it]\n","Epoch (training) 17:  98%|█████████▊| 40/41 [00:53<00:01,  1.03s/it]\n","Epoch (training) 17: 100%|██████████| 41/41 [00:53<00:00,  1.30s/it]\n","Epoch (test) 17:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 17:   5%|▍         | 1/21 [00:02<00:48,  2.40s/it]\n","Epoch (test) 17:  10%|▉         | 2/21 [00:03<00:35,  1.88s/it]\n","Epoch (test) 17:  14%|█▍        | 3/21 [00:05<00:31,  1.78s/it]\n","Epoch (test) 17:  19%|█▉        | 4/21 [00:06<00:23,  1.39s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:49:35. Total running time: 23min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        16            1343.56   2.04043     0.293292 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 17:  24%|██▍       | 5/21 [00:07<00:23,  1.47s/it]\n","Epoch (test) 17:  29%|██▊       | 6/21 [00:09<00:20,  1.34s/it]\n","Epoch (test) 17:  33%|███▎      | 7/21 [00:10<00:18,  1.32s/it]\n","Epoch (test) 17:  38%|███▊      | 8/21 [00:12<00:19,  1.49s/it]\n","Epoch (test) 17:  43%|████▎     | 9/21 [00:13<00:17,  1.46s/it]\n","Epoch (test) 17:  48%|████▊     | 10/21 [00:15<00:17,  1.58s/it]\n","Epoch (test) 17:  52%|█████▏    | 11/21 [00:16<00:12,  1.28s/it]\n","Epoch (test) 17:  57%|█████▋    | 12/21 [00:16<00:09,  1.09s/it]\n","Epoch (test) 17:  62%|██████▏   | 13/21 [00:17<00:08,  1.07s/it]\n","Epoch (test) 17:  67%|██████▋   | 14/21 [00:18<00:07,  1.02s/it]\n","Epoch (test) 17:  71%|███████▏  | 15/21 [00:19<00:05,  1.07it/s]\n","Epoch (test) 17:  76%|███████▌  | 16/21 [00:19<00:04,  1.19it/s]\n","Epoch (test) 17:  81%|████████  | 17/21 [00:20<00:03,  1.19it/s]\n","Epoch (test) 17:  86%|████████▌ | 18/21 [00:22<00:02,  1.02it/s]\n","Epoch (test) 17:  90%|█████████ | 19/21 [00:23<00:02,  1.21s/it]\n","Epoch (test) 17: 100%|██████████| 21/21 [00:23<00:00,  1.14s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000016)\n","Epoch (training) 18:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 18:   2%|▏         | 1/41 [00:02<01:46,  2.66s/it]\n","Epoch (training) 18:   5%|▍         | 2/41 [00:03<01:04,  1.66s/it]\n","Epoch (training) 18:   7%|▋         | 3/41 [00:04<00:53,  1.40s/it]\n","Epoch (training) 18:  10%|▉         | 4/41 [00:06<00:51,  1.39s/it]\n","Epoch (training) 18:  12%|█▏        | 5/41 [00:06<00:40,  1.13s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:50:05. Total running time: 24min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        17            1424.91   1.96011     0.294852 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 18:  15%|█▍        | 6/41 [00:08<00:45,  1.29s/it]\n","Epoch (training) 18:  17%|█▋        | 7/41 [00:09<00:40,  1.19s/it]\n","Epoch (training) 18:  20%|█▉        | 8/41 [00:10<00:36,  1.09s/it]\n","Epoch (training) 18:  22%|██▏       | 9/41 [00:11<00:37,  1.18s/it]\n","Epoch (training) 18:  24%|██▍       | 10/41 [00:12<00:37,  1.22s/it]\n","Epoch (training) 18:  27%|██▋       | 11/41 [00:13<00:34,  1.16s/it]\n","Epoch (training) 18:  29%|██▉       | 12/41 [00:14<00:30,  1.05s/it]\n","Epoch (training) 18:  32%|███▏      | 13/41 [00:17<00:39,  1.43s/it]\n","Epoch (training) 18:  34%|███▍      | 14/41 [00:17<00:33,  1.26s/it]\n","Epoch (training) 18:  37%|███▋      | 15/41 [00:19<00:35,  1.36s/it]\n","Epoch (training) 18:  39%|███▉      | 16/41 [00:20<00:31,  1.25s/it]\n","Epoch (training) 18:  41%|████▏     | 17/41 [00:21<00:26,  1.12s/it]\n","Epoch (training) 18:  44%|████▍     | 18/41 [00:22<00:25,  1.11s/it]\n","Epoch (training) 18:  46%|████▋     | 19/41 [00:24<00:31,  1.44s/it]\n","Epoch (training) 18:  49%|████▉     | 20/41 [00:25<00:28,  1.34s/it]\n","Epoch (training) 18:  51%|█████     | 21/41 [00:27<00:29,  1.46s/it]\n","Epoch (training) 18:  54%|█████▎    | 22/41 [00:28<00:25,  1.35s/it]\n","Epoch (training) 18:  56%|█████▌    | 23/41 [00:29<00:23,  1.32s/it]\n","Epoch (training) 18:  59%|█████▊    | 24/41 [00:30<00:21,  1.26s/it]\n","Epoch (training) 18:  61%|██████    | 25/41 [00:32<00:20,  1.27s/it]\n","Epoch (training) 18:  63%|██████▎   | 26/41 [00:33<00:18,  1.25s/it]\n","Epoch (training) 18:  66%|██████▌   | 27/41 [00:34<00:17,  1.26s/it]\n","Epoch (training) 18:  68%|██████▊   | 28/41 [00:35<00:15,  1.17s/it]\n","Epoch (training) 18:  71%|███████   | 29/41 [00:36<00:12,  1.02s/it]\n","Epoch (training) 18:  73%|███████▎  | 30/41 [00:38<00:13,  1.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:50:35. Total running time: 24min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        17            1424.91   1.96011     0.294852 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 18:  76%|███████▌  | 31/41 [00:41<00:17,  1.74s/it]\n","Epoch (training) 18:  78%|███████▊  | 32/41 [00:42<00:14,  1.66s/it]\n","Epoch (training) 18:  80%|████████  | 33/41 [00:44<00:14,  1.81s/it]\n","Epoch (training) 18:  83%|████████▎ | 34/41 [00:46<00:12,  1.79s/it]\n","Epoch (training) 18:  85%|████████▌ | 35/41 [00:47<00:09,  1.53s/it]\n","Epoch (training) 18:  88%|████████▊ | 36/41 [00:48<00:07,  1.44s/it]\n","Epoch (training) 18:  90%|█████████ | 37/41 [00:49<00:05,  1.34s/it]\n","Epoch (training) 18:  93%|█████████▎| 38/41 [00:50<00:03,  1.22s/it]\n","Epoch (training) 18:  95%|█████████▌| 39/41 [00:51<00:02,  1.24s/it]\n","Epoch (training) 18:  98%|█████████▊| 40/41 [00:52<00:00,  1.08it/s]\n","Epoch (training) 18: 100%|██████████| 41/41 [00:52<00:00,  1.27s/it]\n","Epoch (test) 18:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 18:   5%|▍         | 1/21 [00:03<01:08,  3.45s/it]\n","Epoch (test) 18:  10%|▉         | 2/21 [00:05<00:47,  2.49s/it]\n","Epoch (test) 18:  14%|█▍        | 3/21 [00:06<00:38,  2.12s/it]\n","Epoch (test) 18:  19%|█▉        | 4/21 [00:07<00:26,  1.54s/it]\n","Epoch (test) 18:  24%|██▍       | 5/21 [00:08<00:22,  1.39s/it]\n","Epoch (test) 18:  29%|██▊       | 6/21 [00:09<00:17,  1.17s/it]\n","Epoch (test) 18:  33%|███▎      | 7/21 [00:10<00:15,  1.08s/it]\n","Epoch (test) 18:  38%|███▊      | 8/21 [00:12<00:16,  1.29s/it]\n","Epoch (test) 18:  43%|████▎     | 9/21 [00:13<00:15,  1.32s/it]\n","Epoch (test) 18:  48%|████▊     | 10/21 [00:15<00:17,  1.56s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:51:05. Total running time: 25min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        17            1424.91   1.96011     0.294852 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 18:  52%|█████▏    | 11/21 [00:16<00:13,  1.33s/it]\n","Epoch (test) 18:  57%|█████▋    | 12/21 [00:17<00:10,  1.21s/it]\n","Epoch (test) 18:  62%|██████▏   | 13/21 [00:18<00:10,  1.27s/it]\n","Epoch (test) 18:  67%|██████▋   | 14/21 [00:19<00:08,  1.20s/it]\n","Epoch (test) 18:  71%|███████▏  | 15/21 [00:20<00:06,  1.05s/it]\n","Epoch (test) 18:  76%|███████▌  | 16/21 [00:21<00:04,  1.09it/s]\n","Epoch (test) 18:  81%|████████  | 17/21 [00:21<00:03,  1.13it/s]\n","Epoch (test) 18:  86%|████████▌ | 18/21 [00:22<00:02,  1.13it/s]\n","Epoch (test) 18:  90%|█████████ | 19/21 [00:24<00:02,  1.00s/it]\n","Epoch (test) 18: 100%|██████████| 21/21 [00:24<00:00,  1.15s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000017)\n","Epoch (training) 19:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 19:   2%|▏         | 1/41 [00:02<01:22,  2.05s/it]\n","Epoch (training) 19:   5%|▍         | 2/41 [00:03<01:02,  1.61s/it]\n","Epoch (training) 19:   7%|▋         | 3/41 [00:05<01:17,  2.03s/it]\n","Epoch (training) 19:  10%|▉         | 4/41 [00:07<01:06,  1.79s/it]\n","Epoch (training) 19:  12%|█▏        | 5/41 [00:08<00:56,  1.57s/it]\n","Epoch (training) 19:  15%|█▍        | 6/41 [00:09<00:52,  1.50s/it]\n","Epoch (training) 19:  17%|█▋        | 7/41 [00:10<00:42,  1.26s/it]\n","Epoch (training) 19:  20%|█▉        | 8/41 [00:11<00:35,  1.09s/it]\n","Epoch (training) 19:  22%|██▏       | 9/41 [00:12<00:35,  1.10s/it]\n","Epoch (training) 19:  24%|██▍       | 10/41 [00:13<00:31,  1.03s/it]\n","Epoch (training) 19:  27%|██▋       | 11/41 [00:14<00:33,  1.12s/it]\n","Epoch (training) 19:  29%|██▉       | 12/41 [00:15<00:34,  1.18s/it]\n","Epoch (training) 19:  32%|███▏      | 13/41 [00:17<00:36,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:51:35. Total running time: 25min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        18            1505.34   1.9547     0.319813 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                    |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                   |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                    |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                   |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 19:  34%|███▍      | 14/41 [00:18<00:35,  1.32s/it]\n","Epoch (training) 19:  37%|███▋      | 15/41 [00:20<00:36,  1.39s/it]\n","Epoch (training) 19:  39%|███▉      | 16/41 [00:22<00:38,  1.55s/it]\n","Epoch (training) 19:  41%|████▏     | 17/41 [00:23<00:33,  1.41s/it]\n","Epoch (training) 19:  44%|████▍     | 18/41 [00:24<00:31,  1.36s/it]\n","Epoch (training) 19:  46%|████▋     | 19/41 [00:25<00:26,  1.19s/it]\n","Epoch (training) 19:  49%|████▉     | 20/41 [00:26<00:24,  1.15s/it]\n","Epoch (training) 19:  51%|█████     | 21/41 [00:27<00:23,  1.17s/it]\n","Epoch (training) 19:  54%|█████▎    | 22/41 [00:28<00:19,  1.03s/it]\n","Epoch (training) 19:  56%|█████▌    | 23/41 [00:30<00:24,  1.39s/it]\n","Epoch (training) 19:  59%|█████▊    | 24/41 [00:32<00:23,  1.39s/it]\n","Epoch (training) 19:  61%|██████    | 25/41 [00:34<00:25,  1.62s/it]\n","Epoch (training) 19:  63%|██████▎   | 26/41 [00:36<00:24,  1.66s/it]\n","Epoch (training) 19:  66%|██████▌   | 27/41 [00:36<00:18,  1.36s/it]\n","Epoch (training) 19:  68%|██████▊   | 28/41 [00:38<00:20,  1.59s/it]\n","Epoch (training) 19:  71%|███████   | 29/41 [00:40<00:18,  1.54s/it]\n","Epoch (training) 19:  73%|███████▎  | 30/41 [00:41<00:15,  1.41s/it]\n","Epoch (training) 19:  76%|███████▌  | 31/41 [00:42<00:12,  1.28s/it]\n","Epoch (training) 19:  78%|███████▊  | 32/41 [00:43<00:11,  1.26s/it]\n","Epoch (training) 19:  80%|████████  | 33/41 [00:44<00:09,  1.17s/it]\n","Epoch (training) 19:  83%|████████▎ | 34/41 [00:46<00:10,  1.45s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:52:05. Total running time: 26min 3s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        18            1505.34   1.9547     0.319813 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                    |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                   |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                    |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                   |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 19:  85%|████████▌ | 35/41 [00:48<00:08,  1.49s/it]\n","Epoch (training) 19:  88%|████████▊ | 36/41 [00:49<00:07,  1.55s/it]\n","Epoch (training) 19:  90%|█████████ | 37/41 [00:51<00:05,  1.45s/it]\n","Epoch (training) 19:  93%|█████████▎| 38/41 [00:52<00:04,  1.33s/it]\n","Epoch (training) 19:  95%|█████████▌| 39/41 [00:52<00:02,  1.18s/it]\n","Epoch (training) 19:  98%|█████████▊| 40/41 [00:53<00:00,  1.15it/s]\n","Epoch (training) 19: 100%|██████████| 41/41 [00:53<00:00,  1.30s/it]\n","Epoch (test) 19:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 19:   5%|▍         | 1/21 [00:02<00:46,  2.34s/it]\n","Epoch (test) 19:  10%|▉         | 2/21 [00:03<00:35,  1.84s/it]\n","Epoch (test) 19:  14%|█▍        | 3/21 [00:05<00:31,  1.76s/it]\n","Epoch (test) 19:  19%|█▉        | 4/21 [00:06<00:22,  1.35s/it]\n","Epoch (test) 19:  24%|██▍       | 5/21 [00:07<00:21,  1.36s/it]\n","Epoch (test) 19:  29%|██▊       | 6/21 [00:08<00:19,  1.27s/it]\n","Epoch (test) 19:  33%|███▎      | 7/21 [00:09<00:17,  1.25s/it]\n","Epoch (test) 19:  38%|███▊      | 8/21 [00:12<00:20,  1.55s/it]\n","Epoch (test) 19:  43%|████▎     | 9/21 [00:13<00:17,  1.49s/it]\n","Epoch (test) 19:  48%|████▊     | 10/21 [00:15<00:17,  1.62s/it]\n","Epoch (test) 19:  52%|█████▏    | 11/21 [00:15<00:12,  1.29s/it]\n","Epoch (test) 19:  57%|█████▋    | 12/21 [00:16<00:10,  1.12s/it]\n","Epoch (test) 19:  62%|██████▏   | 13/21 [00:17<00:08,  1.08s/it]\n","Epoch (test) 19:  67%|██████▋   | 14/21 [00:18<00:07,  1.04s/it]\n","Epoch (test) 19:  71%|███████▏  | 15/21 [00:19<00:05,  1.07it/s]\n","Epoch (test) 19:  76%|███████▌  | 16/21 [00:19<00:04,  1.17it/s]\n","Epoch (test) 19:  81%|████████  | 17/21 [00:20<00:03,  1.19it/s]\n","Epoch (test) 19:  86%|████████▌ | 18/21 [00:21<00:02,  1.09it/s]\n","Epoch (test) 19:  90%|█████████ | 19/21 [00:23<00:02,  1.17s/it]\n","Epoch (test) 19: 100%|██████████| 21/21 [00:23<00:00,  1.13s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:52:36. Total running time: 26min 33s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        18            1505.34   1.9547     0.319813 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                    |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                   |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                    |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                   |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-14 08:53:08,721\tWARNING util.py:202 -- The `on_step_begin` operation took 5.200 s, which may be a performance bottleneck.\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:53:08. Total running time: 27min 6s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)     loss     accuracy |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        18            1505.34   1.9547     0.319813 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                    |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                   |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                    |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                   |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-14 08:53:19,863\tWARNING util.py:202 -- The `on_step_begin` operation took 1.058 s, which may be a performance bottleneck.\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000018)\n","Epoch (training) 20:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 20:   2%|▏         | 1/41 [00:02<01:36,  2.41s/it]\n","Epoch (training) 20:   5%|▍         | 2/41 [00:04<01:23,  2.13s/it]\n","Epoch (training) 20:   7%|▋         | 3/41 [00:06<01:13,  1.93s/it]\n","Epoch (training) 20:  10%|▉         | 4/41 [00:07<00:59,  1.61s/it]\n","Epoch (training) 20:  12%|█▏        | 5/41 [00:07<00:46,  1.30s/it]\n","Epoch (training) 20:  15%|█▍        | 6/41 [00:08<00:39,  1.12s/it]\n","Epoch (training) 20:  17%|█▋        | 7/41 [00:09<00:37,  1.10s/it]\n","Epoch (training) 20:  20%|█▉        | 8/41 [00:10<00:36,  1.11s/it]\n","Epoch (training) 20:  22%|██▏       | 9/41 [00:11<00:31,  1.00it/s]\n","Epoch (training) 20:  24%|██▍       | 10/41 [00:12<00:31,  1.01s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:53:38. Total running time: 27min 36s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        19            1633.26   1.99673     0.283931 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 20:  27%|██▋       | 11/41 [00:14<00:34,  1.15s/it]\n","Epoch (training) 20:  29%|██▉       | 12/41 [00:14<00:29,  1.01s/it]\n","Epoch (training) 20:  32%|███▏      | 13/41 [00:16<00:38,  1.36s/it]\n","Epoch (training) 20:  34%|███▍      | 14/41 [00:18<00:34,  1.29s/it]\n","Epoch (training) 20:  37%|███▋      | 15/41 [00:20<00:40,  1.57s/it]\n","Epoch (training) 20:  39%|███▉      | 16/41 [00:21<00:37,  1.51s/it]\n","Epoch (training) 20:  41%|████▏     | 17/41 [00:22<00:33,  1.42s/it]\n","Epoch (training) 20:  44%|████▍     | 18/41 [00:23<00:28,  1.22s/it]\n","Epoch (training) 20:  46%|████▋     | 19/41 [00:25<00:28,  1.29s/it]\n","Epoch (training) 20:  49%|████▉     | 20/41 [00:26<00:28,  1.35s/it]\n","Epoch (training) 20:  51%|█████     | 21/41 [00:27<00:25,  1.26s/it]\n","Epoch (training) 20:  54%|█████▎    | 22/41 [00:28<00:22,  1.21s/it]\n","Epoch (training) 20:  56%|█████▌    | 23/41 [00:30<00:22,  1.27s/it]\n","Epoch (training) 20:  59%|█████▊    | 24/41 [00:32<00:26,  1.55s/it]\n","Epoch (training) 20:  61%|██████    | 25/41 [00:34<00:25,  1.62s/it]\n","Epoch (training) 20:  63%|██████▎   | 26/41 [00:35<00:21,  1.46s/it]\n","Epoch (training) 20:  66%|██████▌   | 27/41 [00:36<00:19,  1.42s/it]\n","Epoch (training) 20:  68%|██████▊   | 28/41 [00:37<00:17,  1.38s/it]\n","Epoch (training) 20:  71%|███████   | 29/41 [00:38<00:15,  1.26s/it]\n","Epoch (training) 20:  73%|███████▎  | 30/41 [00:39<00:13,  1.18s/it]\n","Epoch (training) 20:  76%|███████▌  | 31/41 [00:40<00:10,  1.07s/it]\n","Epoch (training) 20:  78%|███████▊  | 32/41 [00:42<00:10,  1.17s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:54:08. Total running time: 28min 6s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        19            1633.26   1.99673     0.283931 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 20:  80%|████████  | 33/41 [00:43<00:09,  1.16s/it]\n","Epoch (training) 20:  83%|████████▎ | 34/41 [00:44<00:09,  1.30s/it]\n","Epoch (training) 20:  85%|████████▌ | 35/41 [00:47<00:10,  1.72s/it]\n","Epoch (training) 20:  88%|████████▊ | 36/41 [00:49<00:08,  1.67s/it]\n","Epoch (training) 20:  90%|█████████ | 37/41 [00:50<00:06,  1.65s/it]\n","Epoch (training) 20:  93%|█████████▎| 38/41 [00:51<00:04,  1.39s/it]\n","Epoch (training) 20:  95%|█████████▌| 39/41 [00:52<00:02,  1.29s/it]\n","Epoch (training) 20:  98%|█████████▊| 40/41 [00:52<00:00,  1.05it/s]\n","Epoch (training) 20: 100%|██████████| 41/41 [00:52<00:00,  1.29s/it]\n","Epoch (test) 20:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 20:   5%|▍         | 1/21 [00:02<00:47,  2.35s/it]\n","Epoch (test) 20:  10%|▉         | 2/21 [00:03<00:35,  1.86s/it]\n","Epoch (test) 20:  14%|█▍        | 3/21 [00:05<00:31,  1.77s/it]\n","Epoch (test) 20:  19%|█▉        | 4/21 [00:06<00:22,  1.34s/it]\n","Epoch (test) 20:  24%|██▍       | 5/21 [00:07<00:22,  1.41s/it]\n","Epoch (test) 20:  29%|██▊       | 6/21 [00:08<00:19,  1.31s/it]\n","Epoch (test) 20:  33%|███▎      | 7/21 [00:10<00:18,  1.29s/it]\n","Epoch (test) 20:  38%|███▊      | 8/21 [00:12<00:19,  1.52s/it]\n","Epoch (test) 20:  43%|████▎     | 9/21 [00:13<00:17,  1.48s/it]\n","Epoch (test) 20:  48%|████▊     | 10/21 [00:15<00:17,  1.57s/it]\n","Epoch (test) 20:  52%|█████▏    | 11/21 [00:15<00:12,  1.27s/it]\n","Epoch (test) 20:  57%|█████▋    | 12/21 [00:16<00:09,  1.09s/it]\n","Epoch (test) 20:  62%|██████▏   | 13/21 [00:17<00:08,  1.06s/it]\n","Epoch (test) 20:  67%|██████▋   | 14/21 [00:18<00:07,  1.01s/it]\n","Epoch (test) 20:  71%|███████▏  | 15/21 [00:19<00:05,  1.09it/s]\n","Epoch (test) 20:  76%|███████▌  | 16/21 [00:19<00:04,  1.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 RUNNING | 4 PENDING\n","Current time: 2024-04-14 08:54:38. Total running time: 28min 36s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status       ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   RUNNING                        20                       32              0.00122095        19            1633.26   1.99673     0.283931 |\n","| TorchTrainer_a1400_00001   PENDING                        10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00002   PENDING                        10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                        10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                        10                       64              0.000382991                                                    |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 20:  81%|████████  | 17/21 [00:20<00:03,  1.23it/s]\n","Epoch (test) 20:  86%|████████▌ | 18/21 [00:21<00:02,  1.12it/s]\n","Epoch (test) 20:  90%|█████████ | 19/21 [00:23<00:02,  1.16s/it]\n","Epoch (test) 20: 100%|██████████| 21/21 [00:23<00:00,  1.12s/it]\n","\u001b[36m(RayTrainWorker pid=29490)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00000_0_batch_size=32,epochs=20,lr=0.0012_2024-04-14_08-26-02/checkpoint_000019)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial TorchTrainer_a1400_00000 completed after 20 iterations at 2024-04-14 08:54:52. Total running time: 28min 50s\n","+---------------------------------------------------------------+\n","| Trial TorchTrainer_a1400_00000 result                         |\n","+---------------------------------------------------------------+\n","| checkpoint_dir_name                         checkpoint_000019 |\n","| time_this_iter_s                                     85.71624 |\n","| time_total_s                                       1718.97815 |\n","| training_iteration                                         20 |\n","| accuracy                                              0.29953 |\n","| loss                                                  2.02252 |\n","| summary/epoch/0                                           1.0 |\n","| summary/epoch/1                                           2.0 |\n","| summary/epoch/10                                         11.0 |\n","| summary/epoch/11                                         12.0 |\n","| summary/epoch/12                                         13.0 |\n","| summary/epoch/13                                         14.0 |\n","| summary/epoch/14                                         15.0 |\n","| summary/epoch/15                                         16.0 |\n","| summary/epoch/16                                         17.0 |\n","| summary/epoch/17                                         18.0 |\n","| summary/epoch/18                                         19.0 |\n","| summary/epoch/19                                         20.0 |\n","| summary/epoch/2                                           3.0 |\n","| summary/epoch/3                                           4.0 |\n","| summary/epoch/4                                           5.0 |\n","| summary/epoch/5                                           6.0 |\n","| summary/epoch/6                                           7.0 |\n","| summary/epoch/7                                           8.0 |\n","| summary/epoch/8                                           9.0 |\n","| summary/epoch/9                                          10.0 |\n","| summary/train_acc/0                        0.1725214676034348 |\n","| summary/train_acc/1                       0.20921155347384857 |\n","| summary/train_acc/10                       0.3200624512099922 |\n","| summary/train_acc/11                      0.22092115534738485 |\n","| summary/train_acc/12                      0.25917252146760345 |\n","| summary/train_acc/13                      0.29430132708821233 |\n","| summary/train_acc/14                       0.2693208430913349 |\n","| summary/train_acc/15                       0.3114754098360656 |\n","| summary/train_acc/16                      0.33021077283372363 |\n","| summary/train_acc/17                      0.33411397345823574 |\n","| summary/train_acc/18                       0.2779078844652615 |\n","| summary/train_acc/19                      0.32084309133489464 |\n","| summary/train_acc/2                       0.23341139734582358 |\n","| summary/train_acc/3                        0.2466822794691647 |\n","| summary/train_acc/4                       0.26697892271662765 |\n","| summary/train_acc/5                       0.28337236533957844 |\n","| summary/train_acc/6                        0.2935206869633099 |\n","| summary/train_acc/7                        0.3075722092115535 |\n","| summary/train_acc/8                        0.3192818110850898 |\n","| summary/train_acc/9                       0.34270101483216237 |\n","| summary/train_loss/0                       2.8295525225197395 |\n","| summary/train_loss/1                        2.406312643027887 |\n","| summary/train_loss/10                      2.0668560440947368 |\n","| summary/train_loss/11                      2.3249656398121905 |\n","| summary/train_loss/12                      2.1249935946813445 |\n","| summary/train_loss/13                      2.0591252577014085 |\n","| summary/train_loss/14                      2.1266959091512168 |\n","| summary/train_loss/15                       2.030775044022537 |\n","| summary/train_loss/16                        2.00675723029346 |\n","| summary/train_loss/17                      1.9749293618085908 |\n","| summary/train_loss/18                        2.12230458492186 |\n","| summary/train_loss/19                      2.0526873164060637 |\n","| summary/train_loss/2                         2.23533783598644 |\n","| summary/train_loss/3                       2.2598302364349365 |\n","| summary/train_loss/4                       2.1491127653819757 |\n","| summary/train_loss/5                       2.0709512208293126 |\n","| summary/train_loss/6                       2.1048315559945454 |\n","| summary/train_loss/7                       2.0213793865064296 |\n","| summary/train_loss/8                        1.979736831130051 |\n","| summary/train_loss/9                       1.8791196462584705 |\n","| summary/val_acc/0                         0.21528861154446177 |\n","| summary/val_acc/1                          0.1981279251170047 |\n","| summary/val_acc/10                         0.1622464898595944 |\n","| summary/val_acc/11                        0.22464898595943839 |\n","| summary/val_acc/12                        0.27301092043681746 |\n","| summary/val_acc/13                        0.26053042121684866 |\n","| summary/val_acc/14                         0.2620904836193448 |\n","| summary/val_acc/15                        0.29329173166926675 |\n","| summary/val_acc/16                         0.2948517940717629 |\n","| summary/val_acc/17                        0.31981279251170047 |\n","| summary/val_acc/18                         0.2839313572542902 |\n","| summary/val_acc/19                         0.2995319812792512 |\n","| summary/val_acc/2                         0.23556942277691106 |\n","| summary/val_acc/3                          0.2542901716068643 |\n","| summary/val_acc/4                         0.21684867394695787 |\n","| summary/val_acc/5                         0.21684867394695787 |\n","| summary/val_acc/6                          0.3073322932917317 |\n","| summary/val_acc/7                         0.27301092043681746 |\n","| summary/val_acc/8                         0.29329173166926675 |\n","| summary/val_acc/9                          0.2745709828393136 |\n","| summary/val_loss/0                         20.326230736005876 |\n","| summary/val_loss/1                          4.434763897032965 |\n","| summary/val_loss/10                        11.251733416602725 |\n","| summary/val_loss/11                        2.8466533365703763 |\n","| summary/val_loss/12                         2.123652594430106 |\n","| summary/val_loss/13                         2.110000031335013 |\n","| summary/val_loss/14                         2.109143955366952 |\n","| summary/val_loss/15                           2.0404345591863 |\n","| summary/val_loss/16                        1.9601060435885476 |\n","| summary/val_loss/17                        1.9547012874058314 |\n","| summary/val_loss/18                          1.99672916389647 |\n","| summary/val_loss/19                         2.022516443615868 |\n","| summary/val_loss/2                          5.368728001912435 |\n","| summary/val_loss/3                          2.135626333100455 |\n","| summary/val_loss/4                           2.27054914974031 |\n","| summary/val_loss/5                         2.4812936896369573 |\n","| summary/val_loss/6                         2.0292636780511764 |\n","| summary/val_loss/7                         3.8532016220546903 |\n","| summary/val_loss/8                          2.117150999250866 |\n","| summary/val_loss/9                         2.3527288834253945 |\n","+---------------------------------------------------------------+\n","\n","Trial TorchTrainer_a1400_00001 started with configuration:\n","+-----------------------------------------------------------------+\n","| Trial TorchTrainer_a1400_00001 config                           |\n","+-----------------------------------------------------------------+\n","| train_loop_config/batch_size                                 32 |\n","| train_loop_config/epochs                                     10 |\n","| train_loop_config/lr                      0.0017883186914910397 |\n","| train_loop_config/train_test_idx           ...30, 5553, 10803]) |\n","+-----------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(TorchTrainer pid=29424)\u001b[0m Started distributed worker processes: \n","\u001b[36m(TorchTrainer pid=29424)\u001b[0m - (ip=172.28.0.12, pid=36850) world_rank=0, local_rank=0, node_rank=0\n","\u001b[36m(RayTrainWorker pid=36850)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[36m(RayTrainWorker pid=36850)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n","\u001b[36m(RayTrainWorker pid=36850)\u001b[0m 2024-04-14 08:55:01.185633: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(RayTrainWorker pid=36850)\u001b[0m 2024-04-14 08:55:01.185702: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(RayTrainWorker pid=36850)\u001b[0m 2024-04-14 08:55:01.187101: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(RayTrainWorker pid=36850)\u001b[0m 2024-04-14 08:55:02.559993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[36m(RayTrainWorker pid=36850)\u001b[0m Moving model to device: cuda:0\n","Epoch (training) 1:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 1:   2%|▏         | 1/41 [00:03<02:24,  3.62s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 1 TERMINATED | 1 RUNNING | 3 PENDING\n","Current time: 2024-04-14 08:55:09. Total running time: 29min 6s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00001   RUNNING                          10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20            1718.98   2.02252     0.299532 |\n","| TorchTrainer_a1400_00002   PENDING                          10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                          10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                          10                       64              0.000382991                                                    |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:   5%|▍         | 2/41 [00:04<01:24,  2.15s/it]\n","Epoch (training) 1:   7%|▋         | 3/41 [00:06<01:08,  1.81s/it]\n","Epoch (training) 1:  10%|▉         | 4/41 [00:07<00:58,  1.57s/it]\n","Epoch (training) 1:  12%|█▏        | 5/41 [00:09<01:05,  1.81s/it]\n","Epoch (training) 1:  15%|█▍        | 6/41 [00:10<00:54,  1.57s/it]\n","Epoch (training) 1:  17%|█▋        | 7/41 [00:12<00:58,  1.73s/it]\n","Epoch (training) 1:  20%|█▉        | 8/41 [00:13<00:50,  1.53s/it]\n","Epoch (training) 1:  22%|██▏       | 9/41 [00:14<00:44,  1.41s/it]\n","Epoch (training) 1:  24%|██▍       | 10/41 [00:16<00:44,  1.44s/it]\n","Epoch (training) 1:  27%|██▋       | 11/41 [00:17<00:43,  1.45s/it]\n","Epoch (training) 1:  29%|██▉       | 12/41 [00:19<00:41,  1.43s/it]\n","Epoch (training) 1:  32%|███▏      | 13/41 [00:20<00:39,  1.41s/it]\n","Epoch (training) 1:  34%|███▍      | 14/41 [00:22<00:44,  1.64s/it]\n","Epoch (training) 1:  37%|███▋      | 15/41 [00:25<00:47,  1.82s/it]\n","Epoch (training) 1:  39%|███▉      | 16/41 [00:25<00:36,  1.47s/it]\n","Epoch (training) 1:  41%|████▏     | 17/41 [00:26<00:32,  1.35s/it]\n","Epoch (training) 1:  44%|████▍     | 18/41 [00:28<00:31,  1.35s/it]\n","Epoch (training) 1:  46%|████▋     | 19/41 [00:29<00:29,  1.32s/it]\n","Epoch (training) 1:  49%|████▉     | 20/41 [00:30<00:26,  1.28s/it]\n","Epoch (training) 1:  51%|█████     | 21/41 [00:31<00:22,  1.10s/it]\n","Epoch (training) 1:  54%|█████▎    | 22/41 [00:32<00:20,  1.08s/it]\n","Epoch (training) 1:  56%|█████▌    | 23/41 [00:33<00:18,  1.01s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 TERMINATED | 1 RUNNING | 3 PENDING\n","Current time: 2024-04-14 08:55:39. Total running time: 29min 36s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00001   RUNNING                          10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20            1718.98   2.02252     0.299532 |\n","| TorchTrainer_a1400_00002   PENDING                          10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                          10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                          10                       64              0.000382991                                                    |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  59%|█████▊    | 24/41 [00:35<00:25,  1.50s/it]\n","Epoch (training) 1:  61%|██████    | 25/41 [00:37<00:22,  1.41s/it]\n","Epoch (training) 1:  63%|██████▎   | 26/41 [00:39<00:24,  1.63s/it]\n","Epoch (training) 1:  66%|██████▌   | 27/41 [00:41<00:23,  1.69s/it]\n","Epoch (training) 1:  68%|██████▊   | 28/41 [00:41<00:18,  1.40s/it]\n","Epoch (training) 1:  71%|███████   | 29/41 [00:42<00:14,  1.21s/it]\n","Epoch (training) 1:  73%|███████▎  | 30/41 [00:43<00:13,  1.25s/it]\n","Epoch (training) 1:  76%|███████▌  | 31/41 [00:44<00:10,  1.09s/it]\n","Epoch (training) 1:  78%|███████▊  | 32/41 [00:45<00:09,  1.02s/it]\n","Epoch (training) 1:  80%|████████  | 33/41 [00:46<00:08,  1.05s/it]\n","Epoch (training) 1:  83%|████████▎ | 34/41 [00:47<00:08,  1.14s/it]\n","Epoch (training) 1:  85%|████████▌ | 35/41 [00:48<00:06,  1.04s/it]\n","Epoch (training) 1:  88%|████████▊ | 36/41 [00:50<00:05,  1.14s/it]\n","Epoch (training) 1:  90%|█████████ | 37/41 [00:51<00:05,  1.33s/it]\n","Epoch (training) 1:  93%|█████████▎| 38/41 [00:53<00:04,  1.42s/it]\n","Epoch (training) 1:  95%|█████████▌| 39/41 [00:54<00:02,  1.34s/it]\n","Epoch (training) 1:  98%|█████████▊| 40/41 [00:54<00:00,  1.01it/s]\n","Epoch (training) 1: 100%|██████████| 41/41 [00:55<00:00,  1.34s/it]\n","Epoch (test) 1:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 1:   5%|▍         | 1/21 [00:02<00:45,  2.27s/it]\n","Epoch (test) 1:  10%|▉         | 2/21 [00:03<00:34,  1.82s/it]\n","Epoch (test) 1:  14%|█▍        | 3/21 [00:05<00:31,  1.73s/it]\n","Epoch (test) 1:  19%|█▉        | 4/21 [00:06<00:22,  1.32s/it]\n","Epoch (test) 1:  24%|██▍       | 5/21 [00:07<00:19,  1.25s/it]\n","Epoch (test) 1:  29%|██▊       | 6/21 [00:07<00:16,  1.09s/it]\n","Epoch (test) 1:  33%|███▎      | 7/21 [00:08<00:14,  1.04s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 1 TERMINATED | 1 RUNNING | 3 PENDING\n","Current time: 2024-04-14 08:56:09. Total running time: 30min 6s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)      loss     accuracy |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00001   RUNNING                          10                       32              0.00178832                                                     |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20            1718.98   2.02252     0.299532 |\n","| TorchTrainer_a1400_00002   PENDING                          10                       32              0.000704551                                                    |\n","| TorchTrainer_a1400_00003   PENDING                          10                       32              0.00024569                                                     |\n","| TorchTrainer_a1400_00004   PENDING                          10                       64              0.000382991                                                    |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 1:  38%|███▊      | 8/21 [00:11<00:19,  1.52s/it]\n","Epoch (test) 1:  43%|████▎     | 9/21 [00:13<00:19,  1.63s/it]\n","Epoch (test) 1:  48%|████▊     | 10/21 [00:15<00:18,  1.70s/it]\n","Epoch (test) 1:  52%|█████▏    | 11/21 [00:15<00:13,  1.35s/it]\n","Epoch (test) 1:  57%|█████▋    | 12/21 [00:16<00:10,  1.15s/it]\n","Epoch (test) 1:  62%|██████▏   | 13/21 [00:17<00:08,  1.10s/it]\n","Epoch (test) 1:  67%|██████▋   | 14/21 [00:18<00:07,  1.05s/it]\n","Epoch (test) 1:  71%|███████▏  | 15/21 [00:19<00:05,  1.07it/s]\n","Epoch (test) 1:  76%|███████▌  | 16/21 [00:19<00:04,  1.18it/s]\n","Epoch (test) 1:  81%|████████  | 17/21 [00:20<00:03,  1.20it/s]\n","Epoch (test) 1:  86%|████████▌ | 18/21 [00:21<00:02,  1.15it/s]\n","Epoch (test) 1:  90%|█████████ | 19/21 [00:22<00:01,  1.02it/s]\n","Epoch (test) 1: 100%|██████████| 21/21 [00:22<00:00,  1.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial TorchTrainer_a1400_00001 completed after 1 iterations at 2024-04-14 08:56:36. Total running time: 30min 34s\n","+---------------------------------------------------------------+\n","| Trial TorchTrainer_a1400_00001 result                         |\n","+---------------------------------------------------------------+\n","| checkpoint_dir_name                         checkpoint_000000 |\n","| time_this_iter_s                                    104.03096 |\n","| time_total_s                                        104.03096 |\n","| training_iteration                                          1 |\n","| accuracy                                              0.17785 |\n","| loss                                                 25.71688 |\n","| summary/epoch/0                                           1.0 |\n","| summary/train_acc/0                       0.15456674473067916 |\n","| summary/train_loss/0                         2.67365470455914 |\n","| summary/val_acc/0                         0.17784711388455537 |\n","| summary/val_loss/0                          25.71688096863883 |\n","+---------------------------------------------------------------+\n","\n","Trial TorchTrainer_a1400_00002 started with configuration:\n","+----------------------------------------------------------------+\n","| Trial TorchTrainer_a1400_00002 config                          |\n","+----------------------------------------------------------------+\n","| train_loop_config/batch_size                                32 |\n","| train_loop_config/epochs                                    10 |\n","| train_loop_config/lr                      0.000704550834548804 |\n","| train_loop_config/train_test_idx          ...30, 5553, 10803]) |\n","+----------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=36850)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00001_1_batch_size=32,epochs=10,lr=0.0018_2024-04-14_08-26-02/checkpoint_000000)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:56:39. Total running time: 30min 36s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)       loss     accuracy |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00002   RUNNING                          10                       32              0.000704551                                                     |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20           1718.98     2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1            104.031   25.7169      0.177847 |\n","| TorchTrainer_a1400_00003   PENDING                          10                       32              0.00024569                                                      |\n","| TorchTrainer_a1400_00004   PENDING                          10                       64              0.000382991                                                     |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(TorchTrainer pid=29424)\u001b[0m Started distributed worker processes: \n","\u001b[36m(TorchTrainer pid=29424)\u001b[0m - (ip=172.28.0.12, pid=37322) world_rank=0, local_rank=0, node_rank=0\n","\u001b[36m(RayTrainWorker pid=37322)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[36m(RayTrainWorker pid=37322)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n","\u001b[36m(RayTrainWorker pid=37322)\u001b[0m 2024-04-14 08:56:43.917477: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(RayTrainWorker pid=37322)\u001b[0m 2024-04-14 08:56:43.917534: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(RayTrainWorker pid=37322)\u001b[0m 2024-04-14 08:56:43.918935: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(RayTrainWorker pid=37322)\u001b[0m 2024-04-14 08:56:45.288582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[36m(RayTrainWorker pid=37322)\u001b[0m Moving model to device: cuda:0\n","Epoch (training) 1:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 1:   2%|▏         | 1/41 [00:03<02:38,  3.96s/it]\n","Epoch (training) 1:   5%|▍         | 2/41 [00:05<01:29,  2.30s/it]\n","Epoch (training) 1:   7%|▋         | 3/41 [00:06<01:12,  1.90s/it]\n","Epoch (training) 1:  10%|▉         | 4/41 [00:08<01:04,  1.75s/it]\n","Epoch (training) 1:  12%|█▏        | 5/41 [00:09<00:54,  1.51s/it]\n","Epoch (training) 1:  15%|█▍        | 6/41 [00:10<00:52,  1.51s/it]\n","Epoch (training) 1:  17%|█▋        | 7/41 [00:12<00:52,  1.53s/it]\n","Epoch (training) 1:  20%|█▉        | 8/41 [00:13<00:46,  1.40s/it]\n","Epoch (training) 1:  22%|██▏       | 9/41 [00:14<00:39,  1.23s/it]\n","Epoch (training) 1:  24%|██▍       | 10/41 [00:14<00:33,  1.07s/it]\n","Epoch (training) 1:  27%|██▋       | 11/41 [00:16<00:35,  1.19s/it]\n","Epoch (training) 1:  29%|██▉       | 12/41 [00:17<00:30,  1.06s/it]\n","Epoch (training) 1:  32%|███▏      | 13/41 [00:17<00:27,  1.01it/s]\n","Epoch (training) 1:  34%|███▍      | 14/41 [00:19<00:29,  1.09s/it]\n","Epoch (training) 1:  37%|███▋      | 15/41 [00:21<00:35,  1.35s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:57:09. Total running time: 31min 6s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)       loss     accuracy |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00002   RUNNING                          10                       32              0.000704551                                                     |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20           1718.98     2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1            104.031   25.7169      0.177847 |\n","| TorchTrainer_a1400_00003   PENDING                          10                       32              0.00024569                                                      |\n","| TorchTrainer_a1400_00004   PENDING                          10                       64              0.000382991                                                     |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  39%|███▉      | 16/41 [00:22<00:36,  1.47s/it]\n","Epoch (training) 1:  41%|████▏     | 17/41 [00:24<00:32,  1.36s/it]\n","Epoch (training) 1:  44%|████▍     | 18/41 [00:25<00:32,  1.40s/it]\n","Epoch (training) 1:  46%|████▋     | 19/41 [00:26<00:28,  1.30s/it]\n","Epoch (training) 1:  49%|████▉     | 20/41 [00:28<00:30,  1.47s/it]\n","Epoch (training) 1:  51%|█████     | 21/41 [00:29<00:29,  1.46s/it]\n","Epoch (training) 1:  54%|█████▎    | 22/41 [00:31<00:26,  1.41s/it]\n","Epoch (training) 1:  56%|█████▌    | 23/41 [00:32<00:23,  1.29s/it]\n","Epoch (training) 1:  59%|█████▊    | 24/41 [00:33<00:24,  1.42s/it]\n","Epoch (training) 1:  61%|██████    | 25/41 [00:35<00:23,  1.46s/it]\n","Epoch (training) 1:  63%|██████▎   | 26/41 [00:37<00:23,  1.56s/it]\n","Epoch (training) 1:  66%|██████▌   | 27/41 [00:38<00:20,  1.47s/it]\n","Epoch (training) 1:  68%|██████▊   | 28/41 [00:39<00:18,  1.42s/it]\n","Epoch (training) 1:  71%|███████   | 29/41 [00:41<00:17,  1.42s/it]\n","Epoch (training) 1:  73%|███████▎  | 30/41 [00:42<00:14,  1.32s/it]\n","Epoch (training) 1:  76%|███████▌  | 31/41 [00:43<00:13,  1.36s/it]\n","Epoch (training) 1:  78%|███████▊  | 32/41 [00:44<00:11,  1.27s/it]\n","Epoch (training) 1:  80%|████████  | 33/41 [00:45<00:09,  1.18s/it]\n","Epoch (training) 1:  83%|████████▎ | 34/41 [00:46<00:08,  1.16s/it]\n","Epoch (training) 1:  85%|████████▌ | 35/41 [00:47<00:06,  1.07s/it]\n","Epoch (training) 1:  88%|████████▊ | 36/41 [00:50<00:07,  1.56s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:57:39. Total running time: 31min 36s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)       loss     accuracy |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00002   RUNNING                          10                       32              0.000704551                                                     |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20           1718.98     2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1            104.031   25.7169      0.177847 |\n","| TorchTrainer_a1400_00003   PENDING                          10                       32              0.00024569                                                      |\n","| TorchTrainer_a1400_00004   PENDING                          10                       64              0.000382991                                                     |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  90%|█████████ | 37/41 [00:53<00:07,  1.94s/it]\n","Epoch (training) 1:  93%|█████████▎| 38/41 [00:54<00:05,  1.68s/it]\n","Epoch (training) 1:  95%|█████████▌| 39/41 [00:55<00:02,  1.41s/it]\n","Epoch (training) 1:  98%|█████████▊| 40/41 [00:55<00:01,  1.04s/it]\n","Epoch (training) 1: 100%|██████████| 41/41 [00:55<00:00,  1.36s/it]\n","Epoch (test) 1:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 1:   5%|▍         | 1/21 [00:02<00:45,  2.29s/it]\n","Epoch (test) 1:  10%|▉         | 2/21 [00:03<00:34,  1.84s/it]\n","Epoch (test) 1:  14%|█▍        | 3/21 [00:05<00:31,  1.74s/it]\n","Epoch (test) 1:  19%|█▉        | 4/21 [00:06<00:22,  1.33s/it]\n","Epoch (test) 1:  24%|██▍       | 5/21 [00:07<00:20,  1.25s/it]\n","Epoch (test) 1:  29%|██▊       | 6/21 [00:08<00:18,  1.20s/it]\n","Epoch (test) 1:  33%|███▎      | 7/21 [00:09<00:17,  1.21s/it]\n","Epoch (test) 1:  38%|███▊      | 8/21 [00:12<00:20,  1.61s/it]\n","Epoch (test) 1:  43%|████▎     | 9/21 [00:13<00:18,  1.54s/it]\n","Epoch (test) 1:  48%|████▊     | 10/21 [00:15<00:17,  1.62s/it]\n","Epoch (test) 1:  52%|█████▏    | 11/21 [00:15<00:12,  1.29s/it]\n","Epoch (test) 1:  57%|█████▋    | 12/21 [00:16<00:10,  1.11s/it]\n","Epoch (test) 1:  62%|██████▏   | 13/21 [00:17<00:08,  1.07s/it]\n","Epoch (test) 1:  67%|██████▋   | 14/21 [00:18<00:07,  1.03s/it]\n","Epoch (test) 1:  71%|███████▏  | 15/21 [00:19<00:05,  1.08it/s]\n","Epoch (test) 1:  76%|███████▌  | 16/21 [00:19<00:04,  1.19it/s]\n","Epoch (test) 1:  81%|████████  | 17/21 [00:20<00:03,  1.22it/s]\n","Epoch (test) 1:  86%|████████▌ | 18/21 [00:21<00:02,  1.17it/s]\n","Epoch (test) 1:  90%|█████████ | 19/21 [00:23<00:02,  1.07s/it]\n","Epoch (test) 1: 100%|██████████| 21/21 [00:23<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 2 TERMINATED | 1 RUNNING | 2 PENDING\n","Current time: 2024-04-14 08:58:09. Total running time: 32min 6s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)       loss     accuracy |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00002   RUNNING                          10                       32              0.000704551                                                     |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20           1718.98     2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1            104.031   25.7169      0.177847 |\n","| TorchTrainer_a1400_00003   PENDING                          10                       32              0.00024569                                                      |\n","| TorchTrainer_a1400_00004   PENDING                          10                       64              0.000382991                                                     |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n","Trial TorchTrainer_a1400_00002 completed after 1 iterations at 2024-04-14 08:58:20. Total running time: 32min 17s\n","+---------------------------------------------------------------+\n","| Trial TorchTrainer_a1400_00002 result                         |\n","+---------------------------------------------------------------+\n","| checkpoint_dir_name                         checkpoint_000000 |\n","| time_this_iter_s                                     103.4644 |\n","| time_total_s                                         103.4644 |\n","| training_iteration                                          1 |\n","| accuracy                                              0.12793 |\n","| loss                                                106.75682 |\n","| summary/epoch/0                                           1.0 |\n","| summary/train_acc/0                        0.1483216237314598 |\n","| summary/train_loss/0                       2.8704699830311102 |\n","| summary/val_acc/0                         0.12792511700468018 |\n","| summary/val_loss/0                         106.75682104201545 |\n","+---------------------------------------------------------------+\n","\n","Trial TorchTrainer_a1400_00003 started with configuration:\n","+-----------------------------------------------------------------+\n","| Trial TorchTrainer_a1400_00003 config                           |\n","+-----------------------------------------------------------------+\n","| train_loop_config/batch_size                                 32 |\n","| train_loop_config/epochs                                     10 |\n","| train_loop_config/lr                      0.0002456897019532545 |\n","| train_loop_config/train_test_idx           ...30, 5553, 10803]) |\n","+-----------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=37322)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00002_2_batch_size=32,epochs=10,lr=0.0007_2024-04-14_08-26-02/checkpoint_000000)\n","\u001b[36m(TorchTrainer pid=29424)\u001b[0m Started distributed worker processes: \n","\u001b[36m(TorchTrainer pid=29424)\u001b[0m - (ip=172.28.0.12, pid=37796) world_rank=0, local_rank=0, node_rank=0\n","\u001b[36m(RayTrainWorker pid=37796)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[36m(RayTrainWorker pid=37796)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n","\u001b[36m(RayTrainWorker pid=37796)\u001b[0m 2024-04-14 08:58:27.397907: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(RayTrainWorker pid=37796)\u001b[0m 2024-04-14 08:58:27.397958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(RayTrainWorker pid=37796)\u001b[0m 2024-04-14 08:58:27.399393: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(RayTrainWorker pid=37796)\u001b[0m 2024-04-14 08:58:28.787705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[36m(RayTrainWorker pid=37796)\u001b[0m Moving model to device: cuda:0\n","Epoch (training) 1:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 1:   2%|▏         | 1/41 [00:01<01:15,  1.90s/it]\n","Epoch (training) 1:   5%|▍         | 2/41 [00:03<01:04,  1.65s/it]\n","Epoch (training) 1:   7%|▋         | 3/41 [00:05<01:06,  1.75s/it]\n","Epoch (training) 1:  10%|▉         | 4/41 [00:06<00:59,  1.60s/it]\n","Epoch (training) 1:  12%|█▏        | 5/41 [00:08<00:58,  1.62s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 3 TERMINATED | 1 RUNNING | 1 PENDING\n","Current time: 2024-04-14 08:58:39. Total running time: 32min 36s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)        loss     accuracy |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00003   RUNNING                          10                       32              0.00024569                                                       |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20           1718.98      2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1            104.031    25.7169      0.177847 |\n","| TorchTrainer_a1400_00002   TERMINATED                       10                       32              0.000704551        1            103.464   106.757       0.127925 |\n","| TorchTrainer_a1400_00004   PENDING                          10                       64              0.000382991                                                      |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  15%|█▍        | 6/41 [00:09<00:53,  1.54s/it]\n","Epoch (training) 1:  17%|█▋        | 7/41 [00:11<00:54,  1.59s/it]\n","Epoch (training) 1:  20%|█▉        | 8/41 [00:12<00:46,  1.41s/it]\n","Epoch (training) 1:  22%|██▏       | 9/41 [00:14<00:47,  1.49s/it]\n","Epoch (training) 1:  24%|██▍       | 10/41 [00:14<00:37,  1.22s/it]\n","Epoch (training) 1:  27%|██▋       | 11/41 [00:16<00:40,  1.37s/it]\n","Epoch (training) 1:  29%|██▉       | 12/41 [00:17<00:35,  1.21s/it]\n","Epoch (training) 1:  32%|███▏      | 13/41 [00:18<00:31,  1.12s/it]\n","Epoch (training) 1:  34%|███▍      | 14/41 [00:20<00:36,  1.36s/it]\n","Epoch (training) 1:  37%|███▋      | 15/41 [00:21<00:32,  1.26s/it]\n","Epoch (training) 1:  39%|███▉      | 16/41 [00:22<00:35,  1.41s/it]\n","Epoch (training) 1:  41%|████▏     | 17/41 [00:23<00:30,  1.28s/it]\n","Epoch (training) 1:  44%|████▍     | 18/41 [00:25<00:31,  1.39s/it]\n","Epoch (training) 1:  46%|████▋     | 19/41 [00:27<00:37,  1.73s/it]\n","Epoch (training) 1:  49%|████▉     | 20/41 [00:29<00:32,  1.57s/it]\n","Epoch (training) 1:  51%|█████     | 21/41 [00:30<00:28,  1.43s/it]\n","Epoch (training) 1:  54%|█████▎    | 22/41 [00:30<00:23,  1.21s/it]\n","Epoch (training) 1:  56%|█████▌    | 23/41 [00:32<00:24,  1.38s/it]\n","Epoch (training) 1:  59%|█████▊    | 24/41 [00:34<00:27,  1.60s/it]\n","Epoch (training) 1:  61%|██████    | 25/41 [00:37<00:30,  1.89s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 3 TERMINATED | 1 RUNNING | 1 PENDING\n","Current time: 2024-04-14 08:59:09. Total running time: 33min 6s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)        loss     accuracy |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00003   RUNNING                          10                       32              0.00024569                                                       |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20           1718.98      2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1            104.031    25.7169      0.177847 |\n","| TorchTrainer_a1400_00002   TERMINATED                       10                       32              0.000704551        1            103.464   106.757       0.127925 |\n","| TorchTrainer_a1400_00004   PENDING                          10                       64              0.000382991                                                      |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  63%|██████▎   | 26/41 [00:38<00:24,  1.65s/it]\n","Epoch (training) 1:  66%|██████▌   | 27/41 [00:39<00:20,  1.45s/it]\n","Epoch (training) 1:  68%|██████▊   | 28/41 [00:40<00:16,  1.28s/it]\n","Epoch (training) 1:  71%|███████   | 29/41 [00:41<00:13,  1.10s/it]\n","Epoch (training) 1:  73%|███████▎  | 30/41 [00:42<00:12,  1.12s/it]\n","Epoch (training) 1:  76%|███████▌  | 31/41 [00:43<00:11,  1.14s/it]\n","Epoch (training) 1:  78%|███████▊  | 32/41 [00:44<00:09,  1.04s/it]\n","Epoch (training) 1:  80%|████████  | 33/41 [00:45<00:08,  1.03s/it]\n","Epoch (training) 1:  83%|████████▎ | 34/41 [00:47<00:09,  1.40s/it]\n","Epoch (training) 1:  85%|████████▌ | 35/41 [00:49<00:08,  1.47s/it]\n","Epoch (training) 1:  88%|████████▊ | 36/41 [00:50<00:06,  1.39s/it]\n","Epoch (training) 1:  90%|█████████ | 37/41 [00:51<00:05,  1.38s/it]\n","Epoch (training) 1:  93%|█████████▎| 38/41 [00:53<00:04,  1.57s/it]\n","Epoch (training) 1:  95%|█████████▌| 39/41 [00:54<00:02,  1.44s/it]\n","Epoch (training) 1:  98%|█████████▊| 40/41 [00:54<00:01,  1.06s/it]\n","Epoch (training) 1: 100%|██████████| 41/41 [00:55<00:00,  1.35s/it]\n","Epoch (test) 1:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 1:   5%|▍         | 1/21 [00:02<00:47,  2.40s/it]\n","Epoch (test) 1:  10%|▉         | 2/21 [00:03<00:35,  1.87s/it]\n","Epoch (test) 1:  14%|█▍        | 3/21 [00:05<00:32,  1.80s/it]\n","Epoch (test) 1:  19%|█▉        | 4/21 [00:06<00:23,  1.35s/it]\n","Epoch (test) 1:  24%|██▍       | 5/21 [00:07<00:20,  1.30s/it]\n","Epoch (test) 1:  29%|██▊       | 6/21 [00:08<00:18,  1.23s/it]\n","Epoch (test) 1:  33%|███▎      | 7/21 [00:09<00:17,  1.24s/it]\n","Epoch (test) 1:  38%|███▊      | 8/21 [00:12<00:20,  1.61s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 3 TERMINATED | 1 RUNNING | 1 PENDING\n","Current time: 2024-04-14 08:59:39. Total running time: 33min 36s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)        loss     accuracy |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00003   RUNNING                          10                       32              0.00024569                                                       |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20           1718.98      2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1            104.031    25.7169      0.177847 |\n","| TorchTrainer_a1400_00002   TERMINATED                       10                       32              0.000704551        1            103.464   106.757       0.127925 |\n","| TorchTrainer_a1400_00004   PENDING                          10                       64              0.000382991                                                      |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (test) 1:  43%|████▎     | 9/21 [00:13<00:18,  1.55s/it]\n","Epoch (test) 1:  48%|████▊     | 10/21 [00:15<00:17,  1.63s/it]\n","Epoch (test) 1:  52%|█████▏    | 11/21 [00:16<00:13,  1.31s/it]\n","Epoch (test) 1:  57%|█████▋    | 12/21 [00:16<00:10,  1.13s/it]\n","Epoch (test) 1:  62%|██████▏   | 13/21 [00:17<00:08,  1.10s/it]\n","Epoch (test) 1:  67%|██████▋   | 14/21 [00:18<00:07,  1.04s/it]\n","Epoch (test) 1:  71%|███████▏  | 15/21 [00:19<00:05,  1.06it/s]\n","Epoch (test) 1:  76%|███████▌  | 16/21 [00:20<00:04,  1.18it/s]\n","Epoch (test) 1:  81%|████████  | 17/21 [00:20<00:03,  1.16it/s]\n","Epoch (test) 1:  86%|████████▌ | 18/21 [00:21<00:02,  1.14it/s]\n","Epoch (test) 1:  90%|█████████ | 19/21 [00:23<00:02,  1.15s/it]\n","Epoch (test) 1: 100%|██████████| 21/21 [00:23<00:00,  1.13s/it]\n","2024-04-14 08:59:56,282\tWARNING util.py:202 -- The `on_step_begin` operation took 2.994 s, which may be a performance bottleneck.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial TorchTrainer_a1400_00003 completed after 1 iterations at 2024-04-14 08:59:59. Total running time: 33min 56s\n","+---------------------------------------------------------------+\n","| Trial TorchTrainer_a1400_00003 result                         |\n","+---------------------------------------------------------------+\n","| checkpoint_dir_name                         checkpoint_000000 |\n","| time_this_iter_s                                     98.97576 |\n","| time_total_s                                         98.97576 |\n","| training_iteration                                          1 |\n","| accuracy                                              0.19501 |\n","| loss                                                  4.03232 |\n","| summary/epoch/0                                           1.0 |\n","| summary/train_acc/0                       0.13895394223263074 |\n","| summary/train_loss/0                       2.8467650326286873 |\n","| summary/val_acc/0                         0.19500780031201248 |\n","| summary/val_loss/0                           4.03231992608025 |\n","+---------------------------------------------------------------+\n","\n","Trial TorchTrainer_a1400_00004 started with configuration:\n","+------------------------------------------------------------------+\n","| Trial TorchTrainer_a1400_00004 config                            |\n","+------------------------------------------------------------------+\n","| train_loop_config/batch_size                                  64 |\n","| train_loop_config/epochs                                      10 |\n","| train_loop_config/lr                      0.00038299077783474945 |\n","| train_loop_config/train_test_idx            ...30, 5553, 10803]) |\n","+------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=37796)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00003_3_batch_size=32,epochs=10,lr=0.0002_2024-04-14_08-26-02/checkpoint_000000)\n","\u001b[36m(TorchTrainer pid=29424)\u001b[0m Started distributed worker processes: \n","\u001b[36m(TorchTrainer pid=29424)\u001b[0m - (ip=172.28.0.12, pid=38251) world_rank=0, local_rank=0, node_rank=0\n","\u001b[36m(RayTrainWorker pid=38251)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[36m(RayTrainWorker pid=38251)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n","\u001b[36m(RayTrainWorker pid=38251)\u001b[0m 2024-04-14 09:00:06.553425: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(RayTrainWorker pid=38251)\u001b[0m 2024-04-14 09:00:06.553495: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(RayTrainWorker pid=38251)\u001b[0m 2024-04-14 09:00:06.555361: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(RayTrainWorker pid=38251)\u001b[0m 2024-04-14 09:00:08.147845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial status: 4 TERMINATED | 1 RUNNING\n","Current time: 2024-04-14 09:00:09. Total running time: 34min 6s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)        loss     accuracy |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00004   RUNNING                          10                       64              0.000382991                                                      |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20          1718.98       2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1           104.031     25.7169      0.177847 |\n","| TorchTrainer_a1400_00002   TERMINATED                       10                       32              0.000704551        1           103.464    106.757       0.127925 |\n","| TorchTrainer_a1400_00003   TERMINATED                       10                       32              0.00024569         1            98.9758     4.03232     0.195008 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=38251)\u001b[0m Moving model to device: cuda:0\n","Epoch (training) 1:   0%|          | 0/41 [00:00<?, ?it/s]\n","Epoch (training) 1:   2%|▏         | 1/41 [00:08<05:25,  8.13s/it]\n","Epoch (training) 1:   5%|▍         | 2/41 [00:10<02:55,  4.51s/it]\n","Epoch (training) 1:   7%|▋         | 3/41 [00:12<02:07,  3.36s/it]\n","Epoch (training) 1:  10%|▉         | 4/41 [00:13<01:30,  2.43s/it]\n","Epoch (training) 1:  12%|█▏        | 5/41 [00:14<01:09,  1.93s/it]\n","Epoch (training) 1:  15%|█▍        | 6/41 [00:15<00:55,  1.57s/it]\n","Epoch (training) 1:  17%|█▋        | 7/41 [00:16<00:47,  1.39s/it]\n","Epoch (training) 1:  20%|█▉        | 8/41 [00:16<00:39,  1.20s/it]\n","Epoch (training) 1:  22%|██▏       | 9/41 [00:18<00:40,  1.26s/it]\n","Epoch (training) 1:  24%|██▍       | 10/41 [00:19<00:35,  1.15s/it]\n","Epoch (training) 1:  27%|██▋       | 11/41 [00:20<00:39,  1.33s/it]\n","Epoch (training) 1:  29%|██▉       | 12/41 [00:21<00:35,  1.21s/it]\n","Epoch (training) 1:  32%|███▏      | 13/41 [00:22<00:31,  1.12s/it]\n","Epoch (training) 1:  34%|███▍      | 14/41 [00:24<00:39,  1.46s/it]\n","Epoch (training) 1:  37%|███▋      | 15/41 [00:26<00:38,  1.47s/it]\n","Epoch (training) 1:  39%|███▉      | 16/41 [00:27<00:35,  1.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 4 TERMINATED | 1 RUNNING\n","Current time: 2024-04-14 09:00:39. Total running time: 34min 37s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)        loss     accuracy |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00004   RUNNING                          10                       64              0.000382991                                                      |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20          1718.98       2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1           104.031     25.7169      0.177847 |\n","| TorchTrainer_a1400_00002   TERMINATED                       10                       32              0.000704551        1           103.464    106.757       0.127925 |\n","| TorchTrainer_a1400_00003   TERMINATED                       10                       32              0.00024569         1            98.9758     4.03232     0.195008 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 1:  41%|████▏     | 17/41 [00:29<00:36,  1.52s/it]\n","Epoch (training) 1:  44%|████▍     | 18/41 [00:30<00:31,  1.38s/it]\n","Epoch (training) 1:  46%|████▋     | 19/41 [00:31<00:30,  1.37s/it]\n","Epoch (training) 1:  49%|████▉     | 20/41 [00:32<00:24,  1.18s/it]\n","Epoch (training) 1:  51%|█████     | 21/41 [00:33<00:22,  1.12s/it]\n","Epoch (training) 1:  54%|█████▎    | 22/41 [00:34<00:21,  1.13s/it]\n","Epoch (training) 1:  56%|█████▌    | 23/41 [00:38<00:32,  1.82s/it]\n","Epoch (training) 1:  59%|█████▊    | 24/41 [00:39<00:28,  1.66s/it]\n","Epoch (training) 1:  61%|██████    | 25/41 [00:41<00:27,  1.72s/it]\n","Epoch (training) 1:  63%|██████▎   | 26/41 [00:42<00:21,  1.41s/it]\n","Epoch (training) 1:  66%|██████▌   | 27/41 [00:43<00:17,  1.27s/it]\n","Epoch (training) 1:  68%|██████▊   | 28/41 [00:44<00:15,  1.23s/it]\n","Epoch (training) 1:  71%|███████   | 29/41 [00:45<00:15,  1.31s/it]\n","Epoch (training) 1:  73%|███████▎  | 30/41 [00:46<00:13,  1.23s/it]\n","Epoch (training) 1:  76%|███████▌  | 31/41 [00:48<00:13,  1.33s/it]\n","Epoch (training) 1:  78%|███████▊  | 32/41 [00:49<00:11,  1.24s/it]\n","Epoch (training) 1:  80%|████████  | 33/41 [00:50<00:09,  1.18s/it]\n","Epoch (training) 1:  83%|████████▎ | 34/41 [00:51<00:08,  1.25s/it]\n","Epoch (training) 1:  85%|████████▌ | 35/41 [00:53<00:07,  1.30s/it]\n","Epoch (training) 1:  88%|████████▊ | 36/41 [00:54<00:06,  1.30s/it]\n","Epoch (training) 1:  90%|█████████ | 37/41 [00:56<00:05,  1.49s/it]\n","Epoch (training) 1:  93%|█████████▎| 38/41 [00:58<00:04,  1.60s/it]\n","Epoch (training) 1:  95%|█████████▌| 39/41 [00:59<00:02,  1.36s/it]\n","Epoch (training) 1:  98%|█████████▊| 40/41 [00:59<00:01,  1.01s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 4 TERMINATED | 1 RUNNING\n","Current time: 2024-04-14 09:01:09. Total running time: 35min 7s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)        loss     accuracy |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00004   RUNNING                          10                       64              0.000382991                                                      |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20          1718.98       2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1           104.031     25.7169      0.177847 |\n","| TorchTrainer_a1400_00002   TERMINATED                       10                       32              0.000704551        1           103.464    106.757       0.127925 |\n","| TorchTrainer_a1400_00003   TERMINATED                       10                       32              0.00024569         1            98.9758     4.03232     0.195008 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(RayTrainWorker pid=38251)\u001b[0m \rEpoch (training) 1: 100%|██████████| 41/41 [00:59<00:00,  1.28it/s]\rEpoch (training) 1: 100%|██████████| 41/41 [00:59<00:00,  1.45s/it]\n","Epoch (test) 1:   0%|          | 0/21 [00:00<?, ?it/s]\n","Epoch (test) 1:   5%|▍         | 1/21 [00:02<00:47,  2.40s/it]\n","Epoch (test) 1:  10%|▉         | 2/21 [00:03<00:36,  1.90s/it]\n","Epoch (test) 1:  14%|█▍        | 3/21 [00:05<00:32,  1.81s/it]\n","Epoch (test) 1:  19%|█▉        | 4/21 [00:06<00:23,  1.36s/it]\n","Epoch (test) 1:  24%|██▍       | 5/21 [00:07<00:23,  1.44s/it]\n","Epoch (test) 1:  29%|██▊       | 6/21 [00:09<00:19,  1.33s/it]\n","Epoch (test) 1:  33%|███▎      | 7/21 [00:10<00:18,  1.30s/it]\n","Epoch (test) 1:  38%|███▊      | 8/21 [00:12<00:20,  1.54s/it]\n","Epoch (test) 1:  43%|████▎     | 9/21 [00:13<00:17,  1.49s/it]\n","Epoch (test) 1:  48%|████▊     | 10/21 [00:15<00:17,  1.62s/it]\n","Epoch (test) 1:  52%|█████▏    | 11/21 [00:16<00:12,  1.29s/it]\n","Epoch (test) 1:  57%|█████▋    | 12/21 [00:16<00:10,  1.12s/it]\n","Epoch (test) 1:  62%|██████▏   | 13/21 [00:17<00:08,  1.07s/it]\n","Epoch (test) 1:  67%|██████▋   | 14/21 [00:18<00:07,  1.05s/it]\n","Epoch (test) 1:  71%|███████▏  | 15/21 [00:19<00:05,  1.06it/s]\n","Epoch (test) 1:  76%|███████▌  | 16/21 [00:20<00:04,  1.17it/s]\n","Epoch (test) 1:  81%|████████  | 17/21 [00:20<00:03,  1.19it/s]\n","Epoch (test) 1:  86%|████████▌ | 18/21 [00:22<00:02,  1.03it/s]\n","Epoch (test) 1:  90%|█████████ | 19/21 [00:23<00:02,  1.20s/it]\n","Epoch (test) 1: 100%|██████████| 21/21 [00:24<00:00,  1.15s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Trial status: 4 TERMINATED | 1 RUNNING\n","Current time: 2024-04-14 09:01:42. Total running time: 35min 40s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)        loss     accuracy |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00004   RUNNING                          10                       64              0.000382991                                                      |\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20          1718.98       2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1           104.031     25.7169      0.177847 |\n","| TorchTrainer_a1400_00002   TERMINATED                       10                       32              0.000704551        1           103.464    106.757       0.127925 |\n","| TorchTrainer_a1400_00003   TERMINATED                       10                       32              0.00024569         1            98.9758     4.03232     0.195008 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-14 09:01:48,422\tWARNING util.py:202 -- The `on_step_begin` operation took 1.509 s, which may be a performance bottleneck.\n","\u001b[36m(RayTrainWorker pid=38251)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_hpt_outer_4_inner_1/TorchTrainer_a1400_00004_4_batch_size=64,epochs=10,lr=0.0004_2024-04-14_08-26-02/checkpoint_000000)\n","2024-04-14 09:01:48,657\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/wide_resnet50_hpt_outer_4_inner_1' in 0.0514s.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Trial TorchTrainer_a1400_00004 completed after 1 iterations at 2024-04-14 09:01:48. Total running time: 35min 45s\n","+---------------------------------------------------------------+\n","| Trial TorchTrainer_a1400_00004 result                         |\n","+---------------------------------------------------------------+\n","| checkpoint_dir_name                         checkpoint_000000 |\n","| time_this_iter_s                                    109.00794 |\n","| time_total_s                                        109.00794 |\n","| training_iteration                                          1 |\n","| accuracy                                              0.15445 |\n","| loss                                                 18.97903 |\n","| summary/epoch/0                                           1.0 |\n","| summary/train_acc/0                       0.15378610460577674 |\n","| summary/train_loss/0                        2.832206237606886 |\n","| summary/val_acc/0                          0.1544461778471139 |\n","| summary/val_loss/0                          18.97902798652649 |\n","+---------------------------------------------------------------+\n","\n","Trial status: 5 TERMINATED\n","Current time: 2024-04-14 09:01:48. Total running time: 35min 46s\n","Logical resource usage: 0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| Trial name                 status         ...oop_config/epochs     ...config/batch_size     train_loop_config/lr     iter     total time (s)        loss     accuracy |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","| TorchTrainer_a1400_00000   TERMINATED                       20                       32              0.00122095        20          1718.98       2.02252     0.299532 |\n","| TorchTrainer_a1400_00001   TERMINATED                       10                       32              0.00178832         1           104.031     25.7169      0.177847 |\n","| TorchTrainer_a1400_00002   TERMINATED                       10                       32              0.000704551        1           103.464    106.757       0.127925 |\n","| TorchTrainer_a1400_00003   TERMINATED                       10                       32              0.00024569         1            98.9758     4.03232     0.195008 |\n","| TorchTrainer_a1400_00004   TERMINATED                       10                       64              0.000382991        1           109.008     18.979       0.154446 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-14 09:01:49,143\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n","2024-04-14 09:01:49,186\tINFO tune_controller.py:445 -- Restoring the run from the latest experiment state file: experiment_state-2024-04-14_07-25-24.json\n"]},{"output_type":"stream","name":"stdout","text":["Outer fold 4, inner fold 2 - number of samples: 1282\n","Tuning hyperparameters for wide_resnet50_hpt_outer_4_inner_2...\n","Defaulting to ASHA scheduler (no scheduler provided or not an instance of TrialScheduler)\n","Restoring tuner from path /root/ray_results/wide_resnet50_hpt_outer_4_inner_2\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-14 09:01:49,509\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/wide_resnet50_hpt_outer_4_inner_2' in 0.1955s.\n"]},{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------------------+\n","| Configuration for experiment     wide_resnet50_hpt_outer_4_inner_2   |\n","+----------------------------------------------------------------------+\n","| Search algorithm                 BasicVariantGenerator               |\n","| Scheduler                        AsyncHyperBandScheduler             |\n","| Number of trials                 5                                   |\n","+----------------------------------------------------------------------+\n","\n","View detailed results here: /root/ray_results/wide_resnet50_hpt_outer_4_inner_2\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-04-14_07-52-09_892030_20145/artifacts/2024-04-14_07-25-24/wide_resnet50_hpt_outer_4_inner_2/driver_artifacts`\n","\n","Trial status: 5 TERMINATED\n","Current time: 2024-04-14 09:01:49. Total running time: 0s\n","Logical resource usage: 0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:V100)\n","+-----------------------------------------------------------------------------------------------+\n","| Trial name                 status         iter     total time (s)           loss     accuracy |\n","+-----------------------------------------------------------------------------------------------+\n","| TorchTrainer_28880_00004   TERMINATED        1            104.299    1.03908e+08    0.078125  |\n","| TorchTrainer_28880_00003   TERMINATED        4            333.998    3.15531        0.1       |\n","| TorchTrainer_28880_00002   TERMINATED        1            114.292    1.58994e+08    0.0828125 |\n","| TorchTrainer_28880_00001   TERMINATED        1            100.039    1.66761e+07    0.0828125 |\n","| TorchTrainer_28880_00000   TERMINATED        5            596.311   12.4705         0.154688  |\n","+-----------------------------------------------------------------------------------------------+\n","\n"]}],"source":["hp_nest_cv = ciri_trainer.cross_validate(\n","    run_name=\"wide_resnet50_hpt\",\n","    config=search_space,\n","    outer_cv_k=5,\n","    inner_cv_k=3,\n","    tune_hyperparams=True,\n","    num_samples=5,\n","    results_persist_dir=persistence_path,\n","    start_fold=(4, 0)\n",")"]},{"cell_type":"markdown","source":["## Examine results\n"],"metadata":{"id":"jNANHUqp4_Xp"}},{"cell_type":"code","source":["import json\n","import re\n","import pandas as pd\n","\n","from pprint import pprint"],"metadata":{"id":"e5w3hhlj5AYW","executionInfo":{"status":"ok","timestamp":1713123102971,"user_tz":-120,"elapsed":22,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["best_experiments = []\n","for i in range(5):\n","  for j in range(3):\n","    file_summary = f\"hpt_wide_resnet50_hpt_outer_{i}_inner_{j}_exp_summary.csv\"\n","    file_path = os.path.join(persistence_path, file_summary)\n","    tmp_df = pd.read_csv(file_path, usecols=[\"loss\", \"accuracy\", \"trial_id\", \"time_total_s\"])\n","    tmp_df = tmp_df.loc[tmp_df['accuracy'] == tmp_df['accuracy'].max()]\n","    tmp_df['outer_fold'] = i\n","    tmp_df['inner_fold'] = j\n","    best_experiments.append(\n","        tmp_df\n","    )\n","\n","best_experiments = pd.concat(best_experiments)\n","best_experiments = best_experiments.sort_values(by=['accuracy', 'loss', 'time_total_s'], ascending=[False, True, True])\n","best_experiments"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"irkEn4CL5CDb","executionInfo":{"status":"ok","timestamp":1713123109635,"user_tz":-120,"elapsed":6686,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"}},"outputId":"f3b3e7b8-155c-4d26-f0a9-bdd9b276579b"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        loss  accuracy     trial_id  time_total_s  outer_fold  inner_fold\n","2   1.901282  0.371295  8d8f0_00002   1690.489108           2           0\n","1   2.407765  0.344774  d2735_00001    835.887733           2           1\n","0   2.556820  0.341654  9d196_00000   1743.971443           1           0\n","0   2.075537  0.305772  998b8_00000    433.088491           3           0\n","0   2.112708  0.304688  0c78b_00000   1535.406898           0           2\n","0   2.022516  0.299532  a1400_00000   1718.978152           4           1\n","0   3.121286  0.294852  e8bbe_00000    821.023257           4           0\n","0   2.097283  0.290625  cf44b_00000   1547.026404           0           1\n","0   2.013552  0.276131  116e1_00000   1656.248230           0           0\n","0   2.211824  0.256250  c540c_00000   1668.311860           2           2\n","1   2.586996  0.221529  ef5d3_00001    828.974152           3           1\n","3   3.888501  0.215625  357d8_00003    332.179120           1           1\n","0   2.378601  0.210938  24347_00000    414.197532           1           2\n","0   2.389249  0.193750  58c3d_00000    975.227409           3           2\n","4  12.470464  0.154688  28880_00000    596.311049           4           2"],"text/html":["\n","  <div id=\"df-008b9c65-0a5f-45ba-8bac-7b750d2fe291\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss</th>\n","      <th>accuracy</th>\n","      <th>trial_id</th>\n","      <th>time_total_s</th>\n","      <th>outer_fold</th>\n","      <th>inner_fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>1.901282</td>\n","      <td>0.371295</td>\n","      <td>8d8f0_00002</td>\n","      <td>1690.489108</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.407765</td>\n","      <td>0.344774</td>\n","      <td>d2735_00001</td>\n","      <td>835.887733</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2.556820</td>\n","      <td>0.341654</td>\n","      <td>9d196_00000</td>\n","      <td>1743.971443</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2.075537</td>\n","      <td>0.305772</td>\n","      <td>998b8_00000</td>\n","      <td>433.088491</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2.112708</td>\n","      <td>0.304688</td>\n","      <td>0c78b_00000</td>\n","      <td>1535.406898</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2.022516</td>\n","      <td>0.299532</td>\n","      <td>a1400_00000</td>\n","      <td>1718.978152</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>3.121286</td>\n","      <td>0.294852</td>\n","      <td>e8bbe_00000</td>\n","      <td>821.023257</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2.097283</td>\n","      <td>0.290625</td>\n","      <td>cf44b_00000</td>\n","      <td>1547.026404</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2.013552</td>\n","      <td>0.276131</td>\n","      <td>116e1_00000</td>\n","      <td>1656.248230</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2.211824</td>\n","      <td>0.256250</td>\n","      <td>c540c_00000</td>\n","      <td>1668.311860</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.586996</td>\n","      <td>0.221529</td>\n","      <td>ef5d3_00001</td>\n","      <td>828.974152</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.888501</td>\n","      <td>0.215625</td>\n","      <td>357d8_00003</td>\n","      <td>332.179120</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2.378601</td>\n","      <td>0.210938</td>\n","      <td>24347_00000</td>\n","      <td>414.197532</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2.389249</td>\n","      <td>0.193750</td>\n","      <td>58c3d_00000</td>\n","      <td>975.227409</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12.470464</td>\n","      <td>0.154688</td>\n","      <td>28880_00000</td>\n","      <td>596.311049</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-008b9c65-0a5f-45ba-8bac-7b750d2fe291')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-008b9c65-0a5f-45ba-8bac-7b750d2fe291 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-008b9c65-0a5f-45ba-8bac-7b750d2fe291');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-27c8f1a7-3642-4c87-9255-91937eaab4b8\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-27c8f1a7-3642-4c87-9255-91937eaab4b8')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-27c8f1a7-3642-4c87-9255-91937eaab4b8 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"best_experiments","summary":"{\n  \"name\": \"best_experiments\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6468700890171863,\n        \"min\": 1.9012821231569563,\n        \"max\": 12.470463752746582,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          2.2118235349655158,\n          3.888501381874085,\n          1.9012821231569563\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061787360688832976,\n        \"min\": 0.1546875,\n        \"max\": 0.3712948517940718,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.25625,\n          0.215625,\n          0.3712948517940718\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trial_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"c540c_00000\",\n          \"357d8_00003\",\n          \"8d8f0_00002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_total_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 544.9360024036431,\n        \"min\": 332.1791203022003,\n        \"max\": 1743.9714426994324,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          1668.311859846115,\n          332.1791203022003,\n          1690.4891080856323\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"outer_fold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inner_fold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["#best_experiments.to_csv(os.path.join(persistence_path, f\"HP_RANKING.{selected_model}_overview.csv\"), index=False)"],"metadata":{"id":"DOwFYnlq5T2h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_params_path = os.path.join(persistence_path,\n","                                f\"wide_resnet50_hpt_outer_{best_experiments.iloc[0].outer_fold}_inner_{best_experiments.iloc[0].inner_fold}\",\n","                                \"params.json\")\n","with open(best_params_path, 'r') as params_file:\n","  best_params = json.load(params_file)\n","\n","best_params = {k: v for k, v in best_params['train_loop_config'].items() if k in search_space.keys()}\n","\n","pprint(best_params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QsYj51UT5Wj7","executionInfo":{"status":"ok","timestamp":1713123110453,"user_tz":-120,"elapsed":824,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"}},"outputId":"40942f2c-6c5c-448d-9f02-d3d508d208fa"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["{'batch_size': 32, 'epochs': 5, 'lr': 0.00010777744580116128}\n"]}]},{"cell_type":"markdown","source":["# Cross-validation on entire dataset\n"],"metadata":{"id":"yaNOXAGX7j64"}},{"cell_type":"code","source":["ciri_trainer = CIRI_trainer(model=selected_model,\n","                            data_folders=data_folders,\n","                            data_prop=0.8)"],"metadata":{"id":"dOgai1p2y_JD","executionInfo":{"status":"ok","timestamp":1713123110453,"user_tz":-120,"elapsed":4,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["persistence_path = os.path.join(project_folder, 'checkpoints', f'CV_{selected_model}')\n","os.makedirs(persistence_path, exist_ok=True)"],"metadata":{"id":"y7O7zGNOzbaA","executionInfo":{"status":"ok","timestamp":1713123110454,"user_tz":-120,"elapsed":3,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["cv_whole = ciri_trainer.cross_validate(\n","    run_name=\"wide_resnet50_cv\",\n","    config={\n","        **best_params,\n","        \"additional_metrics\": ['precision', 'recall', 'f1', 'confusion_matrix']\n","    },\n","    outer_cv_k=5,\n","    inner_cv_k=0,\n","    tune_hyperparams=False,\n","    results_persist_dir=persistence_path,\n","    start_fold=(4,0)\n",")"],"metadata":{"id":"unhFuiEFzpkn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7dca0715-a281-419a-cfba-9e7ce6708443","executionInfo":{"status":"ok","timestamp":1713130895931,"user_tz":-120,"elapsed":7785480,"user":{"displayName":"Giulia Pais","userId":"14914739675973762893"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Outer fold 4 - number of samples: 9606\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = _posixsubprocess.fork_exec(\n","2024-04-14 19:32:14,130\tINFO worker.py:1752 -- Started a local Ray instance.\n","2024-04-14 19:32:15,849\tINFO tune.py:263 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `<FrameworkTrainer>(...)`.\n","2024-04-14 19:32:15,861\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"]},{"output_type":"stream","name":"stdout","text":["\n","View detailed results here: /root/ray_results/wide_resnet50_cv_outer_4\n","To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-04-14_19-32-11_529013_4082/artifacts/2024-04-14_19-32-15/wide_resnet50_cv_outer_4/driver_artifacts`\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(TrainTrainable pid=5548)\u001b[0m 2024-04-14 19:32:23.503976: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(TrainTrainable pid=5548)\u001b[0m 2024-04-14 19:32:23.504028: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(TrainTrainable pid=5548)\u001b[0m 2024-04-14 19:32:23.505430: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(TrainTrainable pid=5548)\u001b[0m 2024-04-14 19:32:24.822003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training started with configuration:\n","+---------------------------------------------------------------+\n","| Training config                                               |\n","+---------------------------------------------------------------+\n","| train_loop_config/additional_metrics     ...onfusion_matrix'] |\n","| train_loop_config/batch_size                               32 |\n","| train_loop_config/data_folders           ...ugmented_images'] |\n","| train_loop_config/data_prop                               0.8 |\n","| train_loop_config/epochs                                    5 |\n","| train_loop_config/lr                   0.00010777744580116128 |\n","| train_loop_config/model                       wide_resnet50_2 |\n","| train_loop_config/sample_indices                              |\n","| train_loop_config/train_test_idx         ...1, 12002, 12003]) |\n","+---------------------------------------------------------------+\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(TorchTrainer pid=5548)\u001b[0m Started distributed worker processes: \n","\u001b[36m(TorchTrainer pid=5548)\u001b[0m - (ip=172.28.0.12, pid=5624) world_rank=0, local_rank=0, node_rank=0\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m 2024-04-14 19:32:30.580535: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m 2024-04-14 19:32:30.580590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m 2024-04-14 19:32:30.581865: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m 2024-04-14 19:32:31.901882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m Moving model to device: cuda:0\n","Epoch (training) 1:   0%|          | 0/301 [00:00<?, ?it/s]\n","Epoch (training) 1:   0%|          | 1/301 [00:52<4:20:25, 52.08s/it]\n","Epoch (training) 1:   1%|          | 2/301 [01:06<2:29:56, 30.09s/it]\n","Epoch (training) 1:   1%|          | 3/301 [01:23<1:59:51, 24.13s/it]\n","Epoch (training) 1:   1%|▏         | 4/301 [01:40<1:45:42, 21.35s/it]\n","Epoch (training) 1:   2%|▏         | 5/301 [01:56<1:34:21, 19.13s/it]\n","Epoch (training) 1:   2%|▏         | 6/301 [02:10<1:25:48, 17.45s/it]\n","Epoch (training) 1:   2%|▏         | 7/301 [02:28<1:26:30, 17.65s/it]\n","Epoch (training) 1:   3%|▎         | 8/301 [02:42<1:21:26, 16.68s/it]\n","Epoch (training) 1:   3%|▎         | 9/301 [02:55<1:14:57, 15.40s/it]\n","Epoch (training) 1:   3%|▎         | 10/301 [03:09<1:12:59, 15.05s/it]\n","Epoch (training) 1:   4%|▎         | 11/301 [03:26<1:14:52, 15.49s/it]\n","Epoch (training) 1:   4%|▍         | 12/301 [03:40<1:12:14, 15.00s/it]\n","Epoch (training) 1:   4%|▍         | 13/301 [03:56<1:14:02, 15.43s/it]\n","Epoch (training) 1:   5%|▍         | 14/301 [04:10<1:12:10, 15.09s/it]\n","Epoch (training) 1:   5%|▍         | 15/301 [04:27<1:13:54, 15.51s/it]\n","Epoch (training) 1:   5%|▌         | 16/301 [04:44<1:15:29, 15.89s/it]\n","Epoch (training) 1:   6%|▌         | 17/301 [05:01<1:17:04, 16.28s/it]\n","Epoch (training) 1:   6%|▌         | 18/301 [05:18<1:17:27, 16.42s/it]\n","Epoch (training) 1:   6%|▋         | 19/301 [05:34<1:16:53, 16.36s/it]\n","Epoch (training) 1:   7%|▋         | 20/301 [05:49<1:15:20, 16.09s/it]\n","Epoch (training) 1:   7%|▋         | 21/301 [06:04<1:12:49, 15.60s/it]\n","Epoch (training) 1:   7%|▋         | 22/301 [06:18<1:11:17, 15.33s/it]\n","Epoch (training) 1:   8%|▊         | 23/301 [06:34<1:11:13, 15.37s/it]\n","Epoch (training) 1:   8%|▊         | 24/301 [06:49<1:10:51, 15.35s/it]\n","Epoch (training) 1:   8%|▊         | 25/301 [07:03<1:09:03, 15.01s/it]\n","Epoch (training) 1:   9%|▊         | 26/301 [07:19<1:10:07, 15.30s/it]\n","Epoch (training) 1:   9%|▉         | 27/301 [07:33<1:07:34, 14.80s/it]\n","Epoch (training) 1:   9%|▉         | 28/301 [07:50<1:09:51, 15.35s/it]\n","Epoch (training) 1:  10%|▉         | 29/301 [08:07<1:12:18, 15.95s/it]\n","Epoch (training) 1:  10%|▉         | 30/301 [08:22<1:10:24, 15.59s/it]\n","Epoch (training) 1:  10%|█         | 31/301 [08:36<1:07:48, 15.07s/it]\n","Epoch (training) 1:  11%|█         | 32/301 [08:51<1:07:23, 15.03s/it]\n","Epoch (training) 1:  11%|█         | 33/301 [09:05<1:06:29, 14.89s/it]\n","Epoch (training) 1:  11%|█▏        | 34/301 [09:20<1:05:39, 14.76s/it]\n","Epoch (training) 1:  12%|█▏        | 35/301 [09:36<1:07:12, 15.16s/it]\n","Epoch (training) 1:  12%|█▏        | 36/301 [09:52<1:08:29, 15.51s/it]\n","Epoch (training) 1:  12%|█▏        | 37/301 [10:09<1:09:51, 15.88s/it]\n","Epoch (training) 1:  13%|█▎        | 38/301 [10:26<1:11:52, 16.40s/it]\n","Epoch (training) 1:  13%|█▎        | 39/301 [10:42<1:10:41, 16.19s/it]\n","Epoch (training) 1:  13%|█▎        | 40/301 [10:57<1:08:13, 15.68s/it]\n","Epoch (training) 1:  14%|█▎        | 41/301 [11:12<1:07:30, 15.58s/it]\n","Epoch (training) 1:  14%|█▍        | 42/301 [11:26<1:05:23, 15.15s/it]\n","Epoch (training) 1:  14%|█▍        | 43/301 [11:42<1:06:47, 15.53s/it]\n","Epoch (training) 1:  15%|█▍        | 44/301 [11:58<1:06:52, 15.61s/it]\n","Epoch (training) 1:  15%|█▍        | 45/301 [12:13<1:04:56, 15.22s/it]\n","Epoch (training) 1:  15%|█▌        | 46/301 [12:29<1:06:14, 15.59s/it]\n","Epoch (training) 1:  16%|█▌        | 47/301 [12:44<1:04:57, 15.34s/it]\n","Epoch (training) 1:  16%|█▌        | 48/301 [12:58<1:03:05, 14.96s/it]\n","Epoch (training) 1:  16%|█▋        | 49/301 [13:13<1:02:40, 14.92s/it]\n","Epoch (training) 1:  17%|█▋        | 50/301 [13:28<1:03:06, 15.08s/it]\n","Epoch (training) 1:  17%|█▋        | 51/301 [13:44<1:03:54, 15.34s/it]\n","Epoch (training) 1:  17%|█▋        | 52/301 [13:58<1:01:18, 14.77s/it]\n","Epoch (training) 1:  18%|█▊        | 53/301 [14:17<1:07:21, 16.30s/it]\n","Epoch (training) 1:  18%|█▊        | 54/301 [14:31<1:03:54, 15.53s/it]\n","Epoch (training) 1:  18%|█▊        | 55/301 [14:45<1:01:39, 15.04s/it]\n","Epoch (training) 1:  19%|█▊        | 56/301 [15:00<1:01:29, 15.06s/it]\n","Epoch (training) 1:  19%|█▉        | 57/301 [15:15<1:01:03, 15.02s/it]\n","Epoch (training) 1:  19%|█▉        | 58/301 [15:31<1:02:07, 15.34s/it]\n","Epoch (training) 1:  20%|█▉        | 59/301 [15:46<1:00:59, 15.12s/it]\n","Epoch (training) 1:  20%|█▉        | 60/301 [16:01<1:00:32, 15.07s/it]\n","Epoch (training) 1:  20%|██        | 61/301 [16:17<1:01:29, 15.37s/it]\n","Epoch (training) 1:  21%|██        | 62/301 [16:31<59:30, 14.94s/it]  \n","Epoch (training) 1:  21%|██        | 63/301 [16:47<1:00:18, 15.20s/it]\n","Epoch (training) 1:  21%|██▏       | 64/301 [17:00<58:19, 14.77s/it]  \n","Epoch (training) 1:  22%|██▏       | 65/301 [17:15<58:21, 14.84s/it]\n","Epoch (training) 1:  22%|██▏       | 66/301 [17:31<58:52, 15.03s/it]\n","Epoch (training) 1:  22%|██▏       | 67/301 [17:45<57:11, 14.67s/it]\n","Epoch (training) 1:  23%|██▎       | 68/301 [18:01<58:26, 15.05s/it]\n","Epoch (training) 1:  23%|██▎       | 69/301 [18:15<57:44, 14.93s/it]\n","Epoch (training) 1:  23%|██▎       | 70/301 [18:29<55:46, 14.49s/it]\n","Epoch (training) 1:  24%|██▎       | 71/301 [18:46<59:25, 15.50s/it]\n","Epoch (training) 1:  24%|██▍       | 72/301 [19:02<58:50, 15.42s/it]\n","Epoch (training) 1:  24%|██▍       | 73/301 [19:18<59:06, 15.56s/it]\n","Epoch (training) 1:  25%|██▍       | 74/301 [19:32<58:05, 15.36s/it]\n","Epoch (training) 1:  25%|██▍       | 75/301 [19:48<58:11, 15.45s/it]\n","Epoch (training) 1:  25%|██▌       | 76/301 [20:02<55:35, 14.83s/it]\n","Epoch (training) 1:  26%|██▌       | 77/301 [20:17<56:23, 15.10s/it]\n","Epoch (training) 1:  26%|██▌       | 78/301 [20:35<59:36, 16.04s/it]\n","Epoch (training) 1:  26%|██▌       | 79/301 [20:50<58:12, 15.73s/it]\n","Epoch (training) 1:  27%|██▋       | 80/301 [21:07<58:21, 15.84s/it]\n","Epoch (training) 1:  27%|██▋       | 81/301 [21:21<56:55, 15.52s/it]\n","Epoch (training) 1:  27%|██▋       | 82/301 [21:35<54:33, 14.95s/it]\n","Epoch (training) 1:  28%|██▊       | 83/301 [21:52<56:02, 15.42s/it]\n","Epoch (training) 1:  28%|██▊       | 84/301 [22:08<57:27, 15.89s/it]\n","Epoch (training) 1:  28%|██▊       | 85/301 [22:24<56:18, 15.64s/it]\n","Epoch (training) 1:  29%|██▊       | 86/301 [22:39<56:13, 15.69s/it]\n","Epoch (training) 1:  29%|██▉       | 87/301 [22:55<55:41, 15.61s/it]\n","Epoch (training) 1:  29%|██▉       | 88/301 [23:11<55:39, 15.68s/it]\n","Epoch (training) 1:  30%|██▉       | 89/301 [23:29<58:18, 16.50s/it]\n","Epoch (training) 1:  30%|██▉       | 90/301 [23:44<56:15, 16.00s/it]\n","Epoch (training) 1:  30%|███       | 91/301 [23:57<52:56, 15.13s/it]\n","Epoch (training) 1:  31%|███       | 92/301 [24:14<54:23, 15.61s/it]\n","Epoch (training) 1:  31%|███       | 93/301 [24:30<54:36, 15.75s/it]\n","Epoch (training) 1:  31%|███       | 94/301 [24:44<52:30, 15.22s/it]\n","Epoch (training) 1:  32%|███▏      | 95/301 [25:02<55:03, 16.04s/it]\n","Epoch (training) 1:  32%|███▏      | 96/301 [25:16<53:18, 15.60s/it]\n","Epoch (training) 1:  32%|███▏      | 97/301 [25:32<52:43, 15.51s/it]\n","Epoch (training) 1:  33%|███▎      | 98/301 [25:47<52:28, 15.51s/it]\n","Epoch (training) 1:  33%|███▎      | 99/301 [26:04<53:59, 16.04s/it]\n","Epoch (training) 1:  33%|███▎      | 100/301 [26:18<51:08, 15.27s/it]\n","Epoch (training) 1:  34%|███▎      | 101/301 [26:34<51:41, 15.51s/it]\n","Epoch (training) 1:  34%|███▍      | 102/301 [26:50<51:52, 15.64s/it]\n","Epoch (training) 1:  34%|███▍      | 103/301 [27:04<49:41, 15.06s/it]\n","Epoch (training) 1:  35%|███▍      | 104/301 [27:19<50:15, 15.31s/it]\n","Epoch (training) 1:  35%|███▍      | 105/301 [27:36<51:35, 15.79s/it]\n","Epoch (training) 1:  35%|███▌      | 106/301 [27:52<51:00, 15.70s/it]\n","Epoch (training) 1:  36%|███▌      | 107/301 [28:07<50:19, 15.56s/it]\n","Epoch (training) 1:  36%|███▌      | 108/301 [28:23<50:10, 15.60s/it]\n","Epoch (training) 1:  36%|███▌      | 109/301 [28:38<49:44, 15.55s/it]\n","Epoch (training) 1:  37%|███▋      | 110/301 [28:53<48:28, 15.23s/it]\n","Epoch (training) 1:  37%|███▋      | 111/301 [29:06<46:50, 14.79s/it]\n","Epoch (training) 1:  37%|███▋      | 112/301 [29:21<45:58, 14.60s/it]\n","Epoch (training) 1:  38%|███▊      | 113/301 [29:36<46:56, 14.98s/it]\n","Epoch (training) 1:  38%|███▊      | 114/301 [29:50<45:20, 14.55s/it]\n","Epoch (training) 1:  38%|███▊      | 115/301 [30:08<48:07, 15.52s/it]\n","Epoch (training) 1:  39%|███▊      | 116/301 [30:23<47:42, 15.47s/it]\n","Epoch (training) 1:  39%|███▉      | 117/301 [30:40<48:47, 15.91s/it]\n","Epoch (training) 1:  39%|███▉      | 118/301 [30:55<47:12, 15.48s/it]\n","Epoch (training) 1:  40%|███▉      | 119/301 [31:09<45:46, 15.09s/it]\n","Epoch (training) 1:  40%|███▉      | 120/301 [31:24<45:16, 15.01s/it]\n","Epoch (training) 1:  40%|████      | 121/301 [31:38<44:11, 14.73s/it]\n","Epoch (training) 1:  41%|████      | 122/301 [31:52<43:20, 14.53s/it]\n","Epoch (training) 1:  41%|████      | 123/301 [32:06<42:47, 14.43s/it]\n","Epoch (training) 1:  41%|████      | 124/301 [32:19<41:33, 14.09s/it]\n","Epoch (training) 1:  42%|████▏     | 125/301 [32:38<45:46, 15.61s/it]\n","Epoch (training) 1:  42%|████▏     | 126/301 [32:54<45:20, 15.54s/it]\n","Epoch (training) 1:  42%|████▏     | 127/301 [33:09<44:35, 15.37s/it]\n","Epoch (training) 1:  43%|████▎     | 128/301 [33:27<46:33, 16.15s/it]\n","Epoch (training) 1:  43%|████▎     | 129/301 [33:41<45:05, 15.73s/it]\n","Epoch (training) 1:  43%|████▎     | 130/301 [33:56<44:14, 15.53s/it]\n","Epoch (training) 1:  44%|████▎     | 131/301 [34:12<43:46, 15.45s/it]\n","Epoch (training) 1:  44%|████▍     | 132/301 [34:27<42:56, 15.25s/it]\n","Epoch (training) 1:  44%|████▍     | 133/301 [34:42<42:42, 15.25s/it]\n","Epoch (training) 1:  45%|████▍     | 134/301 [34:58<42:54, 15.41s/it]\n","Epoch (training) 1:  45%|████▍     | 135/301 [35:12<41:38, 15.05s/it]\n","Epoch (training) 1:  45%|████▌     | 136/301 [35:27<41:20, 15.03s/it]\n","Epoch (training) 1:  46%|████▌     | 137/301 [35:44<42:43, 15.63s/it]\n","Epoch (training) 1:  46%|████▌     | 138/301 [36:00<42:47, 15.75s/it]\n","Epoch (training) 1:  46%|████▌     | 139/301 [36:14<41:14, 15.27s/it]\n","Epoch (training) 1:  47%|████▋     | 140/301 [36:30<41:44, 15.55s/it]\n","Epoch (training) 1:  47%|████▋     | 141/301 [36:47<42:33, 15.96s/it]\n","Epoch (training) 1:  47%|████▋     | 142/301 [37:02<41:39, 15.72s/it]\n","Epoch (training) 1:  48%|████▊     | 143/301 [37:18<41:02, 15.59s/it]\n","Epoch (training) 1:  48%|████▊     | 144/301 [37:32<40:17, 15.40s/it]\n","Epoch (training) 1:  48%|████▊     | 145/301 [37:48<40:06, 15.43s/it]\n","Epoch (training) 1:  49%|████▊     | 146/301 [38:05<40:52, 15.82s/it]\n","Epoch (training) 1:  49%|████▉     | 147/301 [38:22<41:58, 16.35s/it]\n","Epoch (training) 1:  49%|████▉     | 148/301 [38:35<38:57, 15.28s/it]\n","Epoch (training) 1:  50%|████▉     | 149/301 [38:51<39:21, 15.53s/it]\n","Epoch (training) 1:  50%|████▉     | 150/301 [39:07<39:25, 15.67s/it]\n","Epoch (training) 1:  50%|█████     | 151/301 [39:22<38:31, 15.41s/it]\n","Epoch (training) 1:  50%|█████     | 152/301 [39:36<37:26, 15.08s/it]\n","Epoch (training) 1:  51%|█████     | 153/301 [39:49<35:40, 14.46s/it]\n","Epoch (training) 1:  51%|█████     | 154/301 [40:04<35:22, 14.44s/it]\n","Epoch (training) 1:  51%|█████▏    | 155/301 [40:21<37:15, 15.31s/it]\n","Epoch (training) 1:  52%|█████▏    | 156/301 [40:39<39:02, 16.16s/it]\n","Epoch (training) 1:  52%|█████▏    | 157/301 [40:54<37:35, 15.66s/it]\n","Epoch (training) 1:  52%|█████▏    | 158/301 [41:10<37:36, 15.78s/it]\n","Epoch (training) 1:  53%|█████▎    | 159/301 [41:22<34:55, 14.76s/it]\n","Epoch (training) 1:  53%|█████▎    | 160/301 [41:39<35:51, 15.26s/it]\n","Epoch (training) 1:  53%|█████▎    | 161/301 [41:54<35:33, 15.24s/it]\n","Epoch (training) 1:  54%|█████▍    | 162/301 [42:11<36:21, 15.69s/it]\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m /usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m   warnings.warn(\n","Epoch (training) 1:  54%|█████▍    | 163/301 [42:27<36:42, 15.96s/it]\n","Epoch (training) 1:  54%|█████▍    | 164/301 [42:39<33:52, 14.84s/it]\n","Epoch (training) 1:  55%|█████▍    | 165/301 [42:55<33:59, 14.99s/it]\n","Epoch (training) 1:  55%|█████▌    | 166/301 [43:09<33:11, 14.75s/it]\n","Epoch (training) 1:  55%|█████▌    | 167/301 [43:23<32:42, 14.65s/it]\n","Epoch (training) 1:  56%|█████▌    | 168/301 [43:38<32:38, 14.72s/it]\n","Epoch (training) 1:  56%|█████▌    | 169/301 [43:53<32:43, 14.88s/it]\n","Epoch (training) 1:  56%|█████▋    | 170/301 [44:11<34:17, 15.71s/it]\n","Epoch (training) 1:  57%|█████▋    | 171/301 [44:27<34:26, 15.89s/it]\n","Epoch (training) 1:  57%|█████▋    | 172/301 [44:42<33:21, 15.51s/it]\n","Epoch (training) 1:  57%|█████▋    | 173/301 [45:00<34:48, 16.31s/it]\n","Epoch (training) 1:  58%|█████▊    | 174/301 [45:15<33:46, 15.96s/it]\n","Epoch (training) 1:  58%|█████▊    | 175/301 [45:32<33:41, 16.04s/it]\n","Epoch (training) 1:  58%|█████▊    | 176/301 [45:49<34:24, 16.52s/it]\n","Epoch (training) 1:  59%|█████▉    | 177/301 [46:05<33:42, 16.31s/it]\n","Epoch (training) 1:  59%|█████▉    | 178/301 [46:19<32:14, 15.73s/it]\n","Epoch (training) 1:  59%|█████▉    | 179/301 [46:34<31:31, 15.50s/it]\n","Epoch (training) 1:  60%|█████▉    | 180/301 [46:52<32:31, 16.13s/it]\n","Epoch (training) 1:  60%|██████    | 181/301 [47:05<30:21, 15.18s/it]\n","Epoch (training) 1:  60%|██████    | 182/301 [47:19<29:17, 14.77s/it]\n","Epoch (training) 1:  61%|██████    | 183/301 [47:33<28:50, 14.66s/it]\n","Epoch (training) 1:  61%|██████    | 184/301 [47:48<28:41, 14.71s/it]\n","Epoch (training) 1:  61%|██████▏   | 185/301 [48:03<28:33, 14.77s/it]\n","Epoch (training) 1:  62%|██████▏   | 186/301 [48:19<28:54, 15.08s/it]\n","Epoch (training) 1:  62%|██████▏   | 187/301 [48:37<30:28, 16.04s/it]\n","Epoch (training) 1:  62%|██████▏   | 188/301 [48:53<29:56, 15.90s/it]\n","Epoch (training) 1:  63%|██████▎   | 189/301 [49:09<29:56, 16.04s/it]\n","Epoch (training) 1:  63%|██████▎   | 190/301 [49:24<28:53, 15.62s/it]\n","Epoch (training) 1:  63%|██████▎   | 191/301 [49:40<29:13, 15.94s/it]\n","Epoch (training) 1:  64%|██████▍   | 192/301 [49:56<29:07, 16.03s/it]\n","Epoch (training) 1:  64%|██████▍   | 193/301 [50:10<27:23, 15.22s/it]\n","Epoch (training) 1:  64%|██████▍   | 194/301 [50:24<26:25, 14.81s/it]\n","Epoch (training) 1:  65%|██████▍   | 195/301 [50:40<26:46, 15.16s/it]\n","Epoch (training) 1:  65%|██████▌   | 196/301 [50:55<26:42, 15.26s/it]\n","Epoch (training) 1:  65%|██████▌   | 197/301 [51:10<26:14, 15.14s/it]\n","Epoch (training) 1:  66%|██████▌   | 198/301 [51:26<26:40, 15.54s/it]\n","Epoch (training) 1:  66%|██████▌   | 199/301 [51:44<27:40, 16.28s/it]\n","Epoch (training) 1:  66%|██████▋   | 200/301 [51:58<25:58, 15.43s/it]\n","Epoch (training) 1:  67%|██████▋   | 201/301 [52:13<25:39, 15.39s/it]\n","Epoch (training) 1:  67%|██████▋   | 202/301 [52:29<25:30, 15.46s/it]\n","Epoch (training) 1:  67%|██████▋   | 203/301 [52:46<26:02, 15.94s/it]\n","Epoch (training) 1:  68%|██████▊   | 204/301 [53:00<25:05, 15.52s/it]\n","Epoch (training) 1:  68%|██████▊   | 205/301 [53:18<25:48, 16.13s/it]\n","Epoch (training) 1:  68%|██████▊   | 206/301 [53:32<24:45, 15.63s/it]\n","Epoch (training) 1:  69%|██████▉   | 207/301 [53:47<23:58, 15.30s/it]\n","Epoch (training) 1:  69%|██████▉   | 208/301 [54:04<24:17, 15.67s/it]\n","Epoch (training) 1:  69%|██████▉   | 209/301 [54:22<25:21, 16.54s/it]\n","Epoch (training) 1:  70%|██████▉   | 210/301 [54:37<24:12, 15.96s/it]\n","Epoch (training) 1:  70%|███████   | 211/301 [54:51<23:25, 15.61s/it]\n","Epoch (training) 1:  70%|███████   | 212/301 [55:08<23:21, 15.74s/it]\n","Epoch (training) 1:  71%|███████   | 213/301 [55:20<21:43, 14.81s/it]\n","Epoch (training) 1:  71%|███████   | 214/301 [55:36<21:59, 15.16s/it]\n","Epoch (training) 1:  71%|███████▏  | 215/301 [55:52<22:11, 15.48s/it]\n","Epoch (training) 1:  72%|███████▏  | 216/301 [56:06<21:11, 14.96s/it]\n","Epoch (training) 1:  72%|███████▏  | 217/301 [56:20<20:32, 14.68s/it]\n","Epoch (training) 1:  72%|███████▏  | 218/301 [56:36<20:36, 14.89s/it]\n","Epoch (training) 1:  73%|███████▎  | 219/301 [56:50<20:13, 14.80s/it]\n","Epoch (training) 1:  73%|███████▎  | 220/301 [57:06<20:18, 15.04s/it]\n","Epoch (training) 1:  73%|███████▎  | 221/301 [57:19<19:12, 14.40s/it]\n","Epoch (training) 1:  74%|███████▍  | 222/301 [57:36<20:06, 15.28s/it]\n","Epoch (training) 1:  74%|███████▍  | 223/301 [57:52<20:04, 15.45s/it]\n","Epoch (training) 1:  74%|███████▍  | 224/301 [58:05<19:07, 14.90s/it]\n","Epoch (training) 1:  75%|███████▍  | 225/301 [58:20<18:54, 14.92s/it]\n","Epoch (training) 1:  75%|███████▌  | 226/301 [58:34<18:16, 14.61s/it]\n","Epoch (training) 1:  75%|███████▌  | 227/301 [58:49<18:00, 14.60s/it]\n","Epoch (training) 1:  76%|███████▌  | 228/301 [59:03<17:45, 14.59s/it]\n","Epoch (training) 1:  76%|███████▌  | 229/301 [59:19<17:48, 14.84s/it]\n","Epoch (training) 1:  76%|███████▋  | 230/301 [59:35<18:00, 15.22s/it]\n","Epoch (training) 1:  77%|███████▋  | 231/301 [59:52<18:12, 15.61s/it]\n","Epoch (training) 1:  77%|███████▋  | 232/301 [1:00:08<18:17, 15.90s/it]\n","Epoch (training) 1:  77%|███████▋  | 233/301 [1:00:23<17:42, 15.63s/it]\n","Epoch (training) 1:  78%|███████▊  | 234/301 [1:00:37<16:55, 15.16s/it]\n","Epoch (training) 1:  78%|███████▊  | 235/301 [1:00:52<16:37, 15.11s/it]\n","Epoch (training) 1:  78%|███████▊  | 236/301 [1:01:09<16:52, 15.58s/it]\n","Epoch (training) 1:  79%|███████▊  | 237/301 [1:01:24<16:36, 15.57s/it]\n","Epoch (training) 1:  79%|███████▉  | 238/301 [1:01:41<16:47, 15.99s/it]\n","Epoch (training) 1:  79%|███████▉  | 239/301 [1:02:00<17:20, 16.78s/it]\n","Epoch (training) 1:  80%|███████▉  | 240/301 [1:02:16<16:44, 16.48s/it]\n","Epoch (training) 1:  80%|████████  | 241/301 [1:02:29<15:31, 15.52s/it]\n","Epoch (training) 1:  80%|████████  | 242/301 [1:02:44<15:12, 15.47s/it]\n","Epoch (training) 1:  81%|████████  | 243/301 [1:03:00<14:52, 15.38s/it]\n","Epoch (training) 1:  81%|████████  | 244/301 [1:03:14<14:19, 15.08s/it]\n","Epoch (training) 1:  81%|████████▏ | 245/301 [1:03:29<14:08, 15.15s/it]\n","Epoch (training) 1:  82%|████████▏ | 246/301 [1:03:44<13:40, 14.91s/it]\n","Epoch (training) 1:  82%|████████▏ | 247/301 [1:03:59<13:32, 15.04s/it]\n","Epoch (training) 1:  82%|████████▏ | 248/301 [1:04:17<14:04, 15.94s/it]\n","Epoch (training) 1:  83%|████████▎ | 249/301 [1:04:31<13:25, 15.50s/it]\n","Epoch (training) 1:  83%|████████▎ | 250/301 [1:04:45<12:43, 14.97s/it]\n","Epoch (training) 1:  83%|████████▎ | 251/301 [1:05:00<12:32, 15.05s/it]\n","Epoch (training) 1:  84%|████████▎ | 252/301 [1:05:18<12:48, 15.68s/it]\n","Epoch (training) 1:  84%|████████▍ | 253/301 [1:05:34<12:47, 15.99s/it]\n","Epoch (training) 1:  84%|████████▍ | 254/301 [1:05:48<12:01, 15.34s/it]\n","Epoch (training) 1:  85%|████████▍ | 255/301 [1:06:02<11:30, 15.01s/it]\n","Epoch (training) 1:  85%|████████▌ | 256/301 [1:06:17<11:13, 14.96s/it]\n","Epoch (training) 1:  85%|████████▌ | 257/301 [1:06:31<10:45, 14.67s/it]\n","Epoch (training) 1:  86%|████████▌ | 258/301 [1:06:46<10:28, 14.63s/it]\n","Epoch (training) 1:  86%|████████▌ | 259/301 [1:07:02<10:33, 15.07s/it]\n","Epoch (training) 1:  86%|████████▋ | 260/301 [1:07:15<09:52, 14.45s/it]\n","Epoch (training) 1:  87%|████████▋ | 261/301 [1:07:32<10:06, 15.16s/it]\n","Epoch (training) 1:  87%|████████▋ | 262/301 [1:07:45<09:24, 14.48s/it]\n","Epoch (training) 1:  87%|████████▋ | 263/301 [1:07:59<09:06, 14.38s/it]\n","Epoch (training) 1:  88%|████████▊ | 264/301 [1:08:15<09:13, 14.96s/it]\n","Epoch (training) 1:  88%|████████▊ | 265/301 [1:08:30<09:03, 15.09s/it]\n","Epoch (training) 1:  88%|████████▊ | 266/301 [1:08:48<09:10, 15.73s/it]\n","Epoch (training) 1:  89%|████████▊ | 267/301 [1:09:03<08:53, 15.70s/it]\n","Epoch (training) 1:  89%|████████▉ | 268/301 [1:09:18<08:25, 15.33s/it]\n","Epoch (training) 1:  89%|████████▉ | 269/301 [1:09:34<08:21, 15.66s/it]\n","Epoch (training) 1:  90%|████████▉ | 270/301 [1:09:51<08:18, 16.09s/it]\n","Epoch (training) 1:  90%|█████████ | 271/301 [1:10:07<08:02, 16.08s/it]\n","Epoch (training) 1:  90%|█████████ | 272/301 [1:10:21<07:28, 15.46s/it]\n","Epoch (training) 1:  91%|█████████ | 273/301 [1:10:37<07:12, 15.44s/it]\n","Epoch (training) 1:  91%|█████████ | 274/301 [1:10:52<06:53, 15.30s/it]\n","Epoch (training) 1:  91%|█████████▏| 275/301 [1:11:06<06:31, 15.06s/it]\n","Epoch (training) 1:  92%|█████████▏| 276/301 [1:11:21<06:17, 15.11s/it]\n","Epoch (training) 1:  92%|█████████▏| 277/301 [1:11:35<05:54, 14.76s/it]\n","Epoch (training) 1:  92%|█████████▏| 278/301 [1:11:50<05:40, 14.82s/it]\n","Epoch (training) 1:  93%|█████████▎| 279/301 [1:12:05<05:27, 14.90s/it]\n","Epoch (training) 1:  93%|█████████▎| 280/301 [1:12:20<05:08, 14.70s/it]\n","Epoch (training) 1:  93%|█████████▎| 281/301 [1:12:36<05:03, 15.19s/it]\n","Epoch (training) 1:  94%|█████████▎| 282/301 [1:12:53<05:00, 15.81s/it]\n","Epoch (training) 1:  94%|█████████▍| 283/301 [1:13:09<04:42, 15.71s/it]\n","Epoch (training) 1:  94%|█████████▍| 284/301 [1:13:24<04:24, 15.58s/it]\n","Epoch (training) 1:  95%|█████████▍| 285/301 [1:13:38<03:59, 14.99s/it]\n","Epoch (training) 1:  95%|█████████▌| 286/301 [1:13:52<03:43, 14.90s/it]\n","Epoch (training) 1:  95%|█████████▌| 287/301 [1:14:07<03:29, 14.95s/it]\n","Epoch (training) 1:  96%|█████████▌| 288/301 [1:14:22<03:12, 14.80s/it]\n","Epoch (training) 1:  96%|█████████▌| 289/301 [1:14:38<03:02, 15.22s/it]\n","Epoch (training) 1:  96%|█████████▋| 290/301 [1:14:51<02:41, 14.70s/it]\n","Epoch (training) 1:  97%|█████████▋| 291/301 [1:15:08<02:31, 15.16s/it]\n","Epoch (training) 1:  97%|█████████▋| 292/301 [1:15:25<02:22, 15.78s/it]\n","Epoch (training) 1:  97%|█████████▋| 293/301 [1:15:39<02:02, 15.34s/it]\n","Epoch (training) 1:  98%|█████████▊| 294/301 [1:15:55<01:47, 15.42s/it]\n","Epoch (training) 1:  98%|█████████▊| 295/301 [1:16:09<01:30, 15.06s/it]\n","Epoch (training) 1:  98%|█████████▊| 296/301 [1:16:23<01:13, 14.76s/it]\n","Epoch (training) 1:  99%|█████████▊| 297/301 [1:16:40<01:02, 15.55s/it]\n","Epoch (training) 1:  99%|█████████▉| 298/301 [1:16:54<00:45, 15.08s/it]\n","Epoch (training) 1:  99%|█████████▉| 299/301 [1:17:10<00:30, 15.20s/it]\n","Epoch (training) 1: 100%|█████████▉| 300/301 [1:17:13<00:11, 11.45s/it]\n","Epoch (training) 1: 100%|██████████| 301/301 [1:17:13<00:00, 15.39s/it]\n","Epoch (test) 1:   0%|          | 0/76 [00:00<?, ?it/s]\n","Epoch (test) 1:   1%|▏         | 1/76 [00:27<34:33, 27.64s/it]\n","Epoch (test) 1:   3%|▎         | 2/76 [00:41<24:08, 19.57s/it]\n","Epoch (test) 1:   4%|▍         | 3/76 [00:57<21:35, 17.75s/it]\n","Epoch (test) 1:   5%|▌         | 4/76 [01:11<19:45, 16.46s/it]\n","Epoch (test) 1:   7%|▋         | 5/76 [01:26<18:52, 15.96s/it]\n","Epoch (test) 1:   8%|▊         | 6/76 [01:40<17:47, 15.25s/it]\n","Epoch (test) 1:   9%|▉         | 7/76 [01:56<17:43, 15.42s/it]\n","Epoch (test) 1:  11%|█         | 8/76 [02:09<16:39, 14.69s/it]\n","Epoch (test) 1:  12%|█▏        | 9/76 [02:26<17:02, 15.27s/it]\n","Epoch (test) 1:  13%|█▎        | 10/76 [02:41<16:44, 15.22s/it]\n","Epoch (test) 1:  14%|█▍        | 11/76 [02:55<16:08, 14.90s/it]\n","Epoch (test) 1:  16%|█▌        | 12/76 [03:10<15:53, 14.90s/it]\n","Epoch (test) 1:  17%|█▋        | 13/76 [03:24<15:36, 14.87s/it]\n","Epoch (test) 1:  18%|█▊        | 14/76 [03:39<15:11, 14.71s/it]\n","Epoch (test) 1:  20%|█▉        | 15/76 [03:52<14:24, 14.18s/it]\n","Epoch (test) 1:  21%|██        | 16/76 [04:06<14:16, 14.27s/it]\n","Epoch (test) 1:  22%|██▏       | 17/76 [04:20<13:48, 14.05s/it]\n","Epoch (test) 1:  24%|██▎       | 18/76 [04:34<13:36, 14.07s/it]\n","Epoch (test) 1:  25%|██▌       | 19/76 [04:47<13:09, 13.85s/it]\n","Epoch (test) 1:  26%|██▋       | 20/76 [05:02<13:13, 14.18s/it]\n","Epoch (test) 1:  28%|██▊       | 21/76 [05:19<13:37, 14.87s/it]\n","Epoch (test) 1:  29%|██▉       | 22/76 [05:33<13:17, 14.77s/it]\n","Epoch (test) 1:  30%|███       | 23/76 [05:47<12:52, 14.58s/it]\n","Epoch (test) 1:  32%|███▏      | 24/76 [06:01<12:28, 14.40s/it]\n","Epoch (test) 1:  33%|███▎      | 25/76 [06:17<12:31, 14.73s/it]\n","Epoch (test) 1:  34%|███▍      | 26/76 [06:31<12:03, 14.47s/it]\n","Epoch (test) 1:  36%|███▌      | 27/76 [06:45<11:52, 14.55s/it]\n","Epoch (test) 1:  37%|███▋      | 28/76 [07:00<11:37, 14.53s/it]\n","Epoch (test) 1:  38%|███▊      | 29/76 [07:15<11:35, 14.80s/it]\n","Epoch (test) 1:  39%|███▉      | 30/76 [07:29<11:10, 14.59s/it]\n","Epoch (test) 1:  41%|████      | 31/76 [07:43<10:44, 14.33s/it]\n","Epoch (test) 1:  42%|████▏     | 32/76 [08:00<10:57, 14.94s/it]\n","Epoch (test) 1:  43%|████▎     | 33/76 [08:13<10:25, 14.55s/it]\n","Epoch (test) 1:  45%|████▍     | 34/76 [08:29<10:24, 14.86s/it]\n","Epoch (test) 1:  46%|████▌     | 35/76 [08:45<10:30, 15.38s/it]\n","Epoch (test) 1:  47%|████▋     | 36/76 [09:00<10:03, 15.10s/it]\n","Epoch (test) 1:  49%|████▊     | 37/76 [09:14<09:39, 14.87s/it]\n","Epoch (test) 1:  50%|█████     | 38/76 [09:29<09:22, 14.80s/it]\n","Epoch (test) 1:  51%|█████▏    | 39/76 [09:44<09:09, 14.85s/it]\n","Epoch (test) 1:  53%|█████▎    | 40/76 [09:58<08:49, 14.70s/it]\n","Epoch (test) 1:  54%|█████▍    | 41/76 [10:11<08:19, 14.26s/it]\n","Epoch (test) 1:  55%|█████▌    | 42/76 [10:27<08:19, 14.69s/it]\n","Epoch (test) 1:  57%|█████▋    | 43/76 [10:42<08:12, 14.92s/it]\n","Epoch (test) 1:  58%|█████▊    | 44/76 [10:58<08:04, 15.14s/it]\n","Epoch (test) 1:  59%|█████▉    | 45/76 [11:13<07:48, 15.11s/it]\n","Epoch (test) 1:  61%|██████    | 46/76 [11:35<08:32, 17.08s/it]\n","Epoch (test) 1:  62%|██████▏   | 47/76 [11:54<08:32, 17.68s/it]\n","Epoch (test) 1:  63%|██████▎   | 48/76 [12:12<08:21, 17.92s/it]\n","Epoch (test) 1:  64%|██████▍   | 49/76 [12:31<08:08, 18.08s/it]\n","Epoch (test) 1:  66%|██████▌   | 50/76 [12:51<08:02, 18.56s/it]\n","Epoch (test) 1:  67%|██████▋   | 51/76 [13:09<07:40, 18.42s/it]\n","Epoch (test) 1:  68%|██████▊   | 52/76 [13:28<07:31, 18.81s/it]\n","Epoch (test) 1:  70%|██████▉   | 53/76 [13:47<07:10, 18.70s/it]\n","Epoch (test) 1:  71%|███████   | 54/76 [14:08<07:05, 19.36s/it]\n","Epoch (test) 1:  72%|███████▏  | 55/76 [14:28<06:49, 19.50s/it]\n","Epoch (test) 1:  74%|███████▎  | 56/76 [14:42<05:59, 17.95s/it]\n","Epoch (test) 1:  75%|███████▌  | 57/76 [14:44<04:09, 13.15s/it]\n","Epoch (test) 1:  76%|███████▋  | 58/76 [14:46<02:55,  9.74s/it]\n","Epoch (test) 1:  78%|███████▊  | 59/76 [14:47<02:02,  7.23s/it]\n","Epoch (test) 1:  79%|███████▉  | 60/76 [14:49<01:30,  5.68s/it]\n","Epoch (test) 1:  80%|████████  | 61/76 [14:58<01:40,  6.70s/it]\n","Epoch (test) 1:  82%|████████▏ | 62/76 [15:16<02:19,  9.99s/it]\n","Epoch (test) 1:  83%|████████▎ | 63/76 [15:35<02:45, 12.77s/it]\n","Epoch (test) 1:  84%|████████▍ | 64/76 [15:56<03:03, 15.32s/it]\n","Epoch (test) 1:  86%|████████▌ | 65/76 [16:15<03:00, 16.42s/it]\n","Epoch (test) 1:  87%|████████▋ | 66/76 [16:32<02:45, 16.58s/it]\n","Epoch (test) 1:  88%|████████▊ | 67/76 [16:50<02:31, 16.82s/it]\n","Epoch (test) 1:  89%|████████▉ | 68/76 [17:07<02:16, 17.04s/it]\n","Epoch (test) 1:  91%|█████████ | 69/76 [17:27<02:04, 17.80s/it]\n","Epoch (test) 1:  92%|█████████▏| 70/76 [17:48<01:52, 18.73s/it]\n","Epoch (test) 1:  93%|█████████▎| 71/76 [18:07<01:34, 18.92s/it]\n","Epoch (test) 1:  95%|█████████▍| 72/76 [18:27<01:16, 19.14s/it]\n","Epoch (test) 1:  96%|█████████▌| 73/76 [18:46<00:57, 19.15s/it]\n","Epoch (test) 1:  97%|█████████▋| 74/76 [19:07<00:39, 19.71s/it]\n","Epoch (test) 1:  99%|█████████▊| 75/76 [19:07<00:13, 13.95s/it]\n","Epoch (test) 1: 100%|██████████| 76/76 [19:08<00:00, 15.11s/it]\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_cv_outer_4/TorchTrainer_b33ac_00000_0_2024-04-14_19-32-16/checkpoint_000000)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training finished iteration 1 at 2024-04-14 21:09:00. Total running time: 1hr 36min 43s\n","+---------------------------------------------+\n","| Training result                             |\n","+---------------------------------------------+\n","| checkpoint_dir_name       checkpoint_000000 |\n","| time_this_iter_s                 5794.63631 |\n","| time_total_s                     5794.63631 |\n","| training_iteration                        1 |\n","| accuracy                            0.37833 |\n","| confusion_matrix       ... 10, 11, 11, 11]) |\n","| f1                                  0.35646 |\n","| loss                                1.88437 |\n","| precision                           0.40003 |\n","| recall                              0.37833 |\n","| summary/epoch/0                         1.0 |\n","| summary/train_acc/0     0.28052083333333333 |\n","| summary/train_loss/0     2.0832002725316046 |\n","| summary/val_acc/0       0.37833333333333335 |\n","| summary/val_loss/0       1.8843663452487243 |\n","+---------------------------------------------+\n","Training saved a checkpoint for iteration 1 at: (local)/root/ray_results/wide_resnet50_cv_outer_4/TorchTrainer_b33ac_00000_0_2024-04-14_19-32-16/checkpoint_000000\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 2:   0%|          | 0/301 [00:00<?, ?it/s]\n","Epoch (training) 2:   0%|          | 1/301 [00:02<11:56,  2.39s/it]\n","Epoch (training) 2:   1%|          | 2/301 [00:03<07:35,  1.52s/it]\n","Epoch (training) 2:   1%|          | 3/301 [00:04<06:20,  1.28s/it]\n","Epoch (training) 2:   1%|▏         | 4/301 [00:05<06:23,  1.29s/it]\n","Epoch (training) 2:   2%|▏         | 5/301 [00:06<06:08,  1.24s/it]\n","Epoch (training) 2:   2%|▏         | 6/301 [00:08<06:31,  1.33s/it]\n","Epoch (training) 2:   2%|▏         | 7/301 [00:10<07:27,  1.52s/it]\n","Epoch (training) 2:   3%|▎         | 8/301 [00:11<07:31,  1.54s/it]\n","Epoch (training) 2:   3%|▎         | 9/301 [00:12<06:37,  1.36s/it]\n","Epoch (training) 2:   3%|▎         | 10/301 [00:14<07:03,  1.45s/it]\n","Epoch (training) 2:   4%|▎         | 11/301 [00:15<06:19,  1.31s/it]\n","Epoch (training) 2:   4%|▍         | 12/301 [00:16<06:29,  1.35s/it]\n","Epoch (training) 2:   4%|▍         | 13/301 [00:17<05:57,  1.24s/it]\n","Epoch (training) 2:   5%|▍         | 14/301 [00:18<05:27,  1.14s/it]\n","Epoch (training) 2:   5%|▍         | 15/301 [00:19<04:51,  1.02s/it]\n","Epoch (training) 2:   5%|▌         | 16/301 [00:20<04:17,  1.11it/s]\n","Epoch (training) 2:   6%|▌         | 17/301 [00:21<04:41,  1.01it/s]\n","Epoch (training) 2:   6%|▌         | 18/301 [00:22<04:55,  1.04s/it]\n","Epoch (training) 2:   6%|▋         | 19/301 [00:24<06:22,  1.36s/it]\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m /usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m   warnings.warn(\n","Epoch (training) 2:   7%|▋         | 20/301 [00:25<06:18,  1.35s/it]\n","Epoch (training) 2:   7%|▋         | 21/301 [00:26<05:35,  1.20s/it]\n","Epoch (training) 2:   7%|▋         | 22/301 [00:27<05:29,  1.18s/it]\n","Epoch (training) 2:   8%|▊         | 23/301 [00:29<06:14,  1.35s/it]\n","Epoch (training) 2:   8%|▊         | 24/301 [00:30<05:20,  1.16s/it]\n","Epoch (training) 2:   8%|▊         | 25/301 [00:31<05:13,  1.14s/it]\n","Epoch (training) 2:   9%|▊         | 26/301 [00:32<05:48,  1.27s/it]\n","Epoch (training) 2:   9%|▉         | 27/301 [00:34<05:33,  1.22s/it]\n","Epoch (training) 2:   9%|▉         | 28/301 [00:35<05:14,  1.15s/it]\n","Epoch (training) 2:  10%|▉         | 29/301 [00:36<05:18,  1.17s/it]\n","Epoch (training) 2:  10%|▉         | 30/301 [00:37<05:04,  1.12s/it]\n","Epoch (training) 2:  10%|█         | 31/301 [00:39<06:35,  1.46s/it]\n","Epoch (training) 2:  11%|█         | 32/301 [00:40<06:23,  1.42s/it]\n","Epoch (training) 2:  11%|█         | 33/301 [00:41<05:33,  1.25s/it]\n","Epoch (training) 2:  11%|█▏        | 34/301 [00:43<06:41,  1.50s/it]\n","Epoch (training) 2:  12%|█▏        | 35/301 [00:44<05:57,  1.34s/it]\n","Epoch (training) 2:  12%|█▏        | 36/301 [00:45<05:16,  1.19s/it]\n","Epoch (training) 2:  12%|█▏        | 37/301 [00:47<06:04,  1.38s/it]\n","Epoch (training) 2:  13%|█▎        | 38/301 [00:49<06:30,  1.48s/it]\n","Epoch (training) 2:  13%|█▎        | 39/301 [00:50<05:42,  1.31s/it]\n","Epoch (training) 2:  13%|█▎        | 40/301 [00:51<06:00,  1.38s/it]\n","Epoch (training) 2:  14%|█▎        | 41/301 [00:53<06:44,  1.56s/it]\n","Epoch (training) 2:  14%|█▍        | 42/301 [00:55<06:39,  1.54s/it]\n","Epoch (training) 2:  14%|█▍        | 43/301 [00:56<06:00,  1.40s/it]\n","Epoch (training) 2:  15%|█▍        | 44/301 [00:57<05:27,  1.27s/it]\n","Epoch (training) 2:  15%|█▍        | 45/301 [00:58<04:58,  1.17s/it]\n","Epoch (training) 2:  15%|█▌        | 46/301 [01:00<06:04,  1.43s/it]\n","Epoch (training) 2:  16%|█▌        | 47/301 [01:01<05:36,  1.32s/it]\n","Epoch (training) 2:  16%|█▌        | 48/301 [01:02<05:05,  1.21s/it]\n","Epoch (training) 2:  16%|█▋        | 49/301 [01:02<04:38,  1.10s/it]\n","Epoch (training) 2:  17%|█▋        | 50/301 [01:04<04:33,  1.09s/it]\n","Epoch (training) 2:  17%|█▋        | 51/301 [01:05<04:45,  1.14s/it]\n","Epoch (training) 2:  17%|█▋        | 52/301 [01:07<05:31,  1.33s/it]\n","Epoch (training) 2:  18%|█▊        | 53/301 [01:08<06:14,  1.51s/it]\n","Epoch (training) 2:  18%|█▊        | 54/301 [01:10<05:38,  1.37s/it]\n","Epoch (training) 2:  18%|█▊        | 55/301 [01:10<04:55,  1.20s/it]\n","Epoch (training) 2:  19%|█▊        | 56/301 [01:11<04:28,  1.10s/it]\n","Epoch (training) 2:  19%|█▉        | 57/301 [01:13<04:43,  1.16s/it]\n","Epoch (training) 2:  19%|█▉        | 58/301 [01:13<04:29,  1.11s/it]\n","Epoch (training) 2:  20%|█▉        | 59/301 [01:14<04:17,  1.06s/it]\n","Epoch (training) 2:  20%|█▉        | 60/301 [01:16<04:20,  1.08s/it]\n","Epoch (training) 2:  20%|██        | 61/301 [01:17<04:36,  1.15s/it]\n","Epoch (training) 2:  21%|██        | 62/301 [01:18<04:41,  1.18s/it]\n","Epoch (training) 2:  21%|██        | 63/301 [01:19<04:31,  1.14s/it]\n","Epoch (training) 2:  21%|██▏       | 64/301 [01:21<04:56,  1.25s/it]\n","Epoch (training) 2:  22%|██▏       | 65/301 [01:22<05:11,  1.32s/it]\n","Epoch (training) 2:  22%|██▏       | 66/301 [01:24<06:13,  1.59s/it]\n","Epoch (training) 2:  22%|██▏       | 67/301 [01:25<05:19,  1.36s/it]\n","Epoch (training) 2:  23%|██▎       | 68/301 [01:26<04:47,  1.23s/it]\n","Epoch (training) 2:  23%|██▎       | 69/301 [01:27<04:15,  1.10s/it]\n","Epoch (training) 2:  23%|██▎       | 70/301 [01:28<03:50,  1.00it/s]\n","Epoch (training) 2:  24%|██▎       | 71/301 [01:29<04:12,  1.10s/it]\n","Epoch (training) 2:  24%|██▍       | 72/301 [01:31<04:55,  1.29s/it]\n","Epoch (training) 2:  24%|██▍       | 73/301 [01:31<04:12,  1.11s/it]\n","Epoch (training) 2:  25%|██▍       | 74/301 [01:33<04:47,  1.27s/it]\n","Epoch (training) 2:  25%|██▍       | 75/301 [01:34<04:25,  1.18s/it]\n","Epoch (training) 2:  25%|██▌       | 76/301 [01:36<05:05,  1.36s/it]\n","Epoch (training) 2:  26%|██▌       | 77/301 [01:38<05:28,  1.47s/it]\n","Epoch (training) 2:  26%|██▌       | 78/301 [01:38<04:51,  1.31s/it]\n","Epoch (training) 2:  26%|██▌       | 79/301 [01:40<05:13,  1.41s/it]\n","Epoch (training) 2:  27%|██▋       | 80/301 [01:41<04:49,  1.31s/it]\n","Epoch (training) 2:  27%|██▋       | 81/301 [01:43<04:59,  1.36s/it]\n","Epoch (training) 2:  27%|██▋       | 82/301 [01:44<05:04,  1.39s/it]\n","Epoch (training) 2:  28%|██▊       | 83/301 [01:45<04:28,  1.23s/it]\n","Epoch (training) 2:  28%|██▊       | 84/301 [01:46<04:29,  1.24s/it]\n","Epoch (training) 2:  28%|██▊       | 85/301 [01:48<04:26,  1.23s/it]\n","Epoch (training) 2:  29%|██▊       | 86/301 [01:48<04:06,  1.15s/it]\n","Epoch (training) 2:  29%|██▉       | 87/301 [01:50<04:16,  1.20s/it]\n","Epoch (training) 2:  29%|██▉       | 88/301 [01:52<05:17,  1.49s/it]\n","Epoch (training) 2:  30%|██▉       | 89/301 [01:54<05:35,  1.58s/it]\n","Epoch (training) 2:  30%|██▉       | 90/301 [01:56<05:52,  1.67s/it]\n","Epoch (training) 2:  30%|███       | 91/301 [01:57<05:13,  1.49s/it]\n","Epoch (training) 2:  31%|███       | 92/301 [01:58<04:39,  1.34s/it]\n","Epoch (training) 2:  31%|███       | 93/301 [01:59<04:43,  1.36s/it]\n","Epoch (training) 2:  31%|███       | 94/301 [02:00<04:21,  1.26s/it]\n","Epoch (training) 2:  32%|███▏      | 95/301 [02:01<03:54,  1.14s/it]\n","Epoch (training) 2:  32%|███▏      | 96/301 [02:02<03:54,  1.15s/it]\n","Epoch (training) 2:  32%|███▏      | 97/301 [02:04<04:13,  1.24s/it]\n","Epoch (training) 2:  33%|███▎      | 98/301 [02:05<04:12,  1.24s/it]\n","Epoch (training) 2:  33%|███▎      | 99/301 [02:06<04:15,  1.26s/it]\n","Epoch (training) 2:  33%|███▎      | 100/301 [02:07<03:52,  1.16s/it]\n","Epoch (training) 2:  34%|███▎      | 101/301 [02:08<04:03,  1.22s/it]\n","Epoch (training) 2:  34%|███▍      | 102/301 [02:09<03:48,  1.15s/it]\n","Epoch (training) 2:  34%|███▍      | 103/301 [02:11<03:46,  1.14s/it]\n","Epoch (training) 2:  35%|███▍      | 104/301 [02:12<03:34,  1.09s/it]\n","Epoch (training) 2:  35%|███▍      | 105/301 [02:13<03:45,  1.15s/it]\n","Epoch (training) 2:  35%|███▌      | 106/301 [02:14<03:38,  1.12s/it]\n","Epoch (training) 2:  36%|███▌      | 107/301 [02:15<03:14,  1.00s/it]\n","Epoch (training) 2:  36%|███▌      | 108/301 [02:15<03:08,  1.02it/s]\n","Epoch (training) 2:  36%|███▌      | 109/301 [02:16<02:58,  1.07it/s]\n","Epoch (training) 2:  37%|███▋      | 110/301 [02:17<02:54,  1.09it/s]\n","Epoch (training) 2:  37%|███▋      | 111/301 [02:20<04:17,  1.35s/it]\n","Epoch (training) 2:  37%|███▋      | 112/301 [02:21<04:16,  1.36s/it]\n","Epoch (training) 2:  38%|███▊      | 113/301 [02:23<04:34,  1.46s/it]\n","Epoch (training) 2:  38%|███▊      | 114/301 [02:24<04:29,  1.44s/it]\n","Epoch (training) 2:  38%|███▊      | 115/301 [02:25<04:04,  1.31s/it]\n","Epoch (training) 2:  39%|███▊      | 116/301 [02:26<03:43,  1.21s/it]\n","Epoch (training) 2:  39%|███▉      | 117/301 [02:27<03:25,  1.12s/it]\n","Epoch (training) 2:  39%|███▉      | 118/301 [02:30<04:50,  1.59s/it]\n","Epoch (training) 2:  40%|███▉      | 119/301 [02:31<04:24,  1.45s/it]\n","Epoch (training) 2:  40%|███▉      | 120/301 [02:33<05:14,  1.74s/it]\n","Epoch (training) 2:  40%|████      | 121/301 [02:37<06:56,  2.31s/it]\n","Epoch (training) 2:  41%|████      | 122/301 [02:38<05:30,  1.85s/it]\n","Epoch (training) 2:  41%|████      | 123/301 [02:38<04:32,  1.53s/it]\n","Epoch (training) 2:  41%|████      | 124/301 [02:39<04:01,  1.36s/it]\n","Epoch (training) 2:  42%|████▏     | 125/301 [02:40<03:36,  1.23s/it]\n","Epoch (training) 2:  42%|████▏     | 126/301 [02:41<03:35,  1.23s/it]\n","Epoch (training) 2:  42%|████▏     | 127/301 [02:43<04:14,  1.46s/it]\n","Epoch (training) 2:  43%|████▎     | 128/301 [02:44<03:39,  1.27s/it]\n","Epoch (training) 2:  43%|████▎     | 129/301 [02:46<03:46,  1.32s/it]\n","Epoch (training) 2:  43%|████▎     | 130/301 [02:50<06:02,  2.12s/it]\n","Epoch (training) 2:  44%|████▎     | 131/301 [02:51<05:08,  1.81s/it]\n","Epoch (training) 2:  44%|████▍     | 132/301 [02:52<04:18,  1.53s/it]\n","Epoch (training) 2:  44%|████▍     | 133/301 [02:53<04:15,  1.52s/it]\n","Epoch (training) 2:  45%|████▍     | 134/301 [02:55<04:26,  1.59s/it]\n","Epoch (training) 2:  45%|████▍     | 135/301 [02:56<03:54,  1.41s/it]\n","Epoch (training) 2:  45%|████▌     | 136/301 [02:57<03:32,  1.29s/it]\n","Epoch (training) 2:  46%|████▌     | 137/301 [02:58<03:11,  1.17s/it]\n","Epoch (training) 2:  46%|████▌     | 138/301 [03:00<03:39,  1.34s/it]\n","Epoch (training) 2:  46%|████▌     | 139/301 [03:02<04:10,  1.54s/it]\n","Epoch (training) 2:  47%|████▋     | 140/301 [03:03<03:47,  1.41s/it]\n","Epoch (training) 2:  47%|████▋     | 141/301 [03:04<03:57,  1.49s/it]\n","Epoch (training) 2:  47%|████▋     | 142/301 [03:05<03:32,  1.34s/it]\n","Epoch (training) 2:  48%|████▊     | 143/301 [03:06<03:18,  1.25s/it]\n","Epoch (training) 2:  48%|████▊     | 144/301 [03:07<02:59,  1.14s/it]\n","Epoch (training) 2:  48%|████▊     | 145/301 [03:09<03:09,  1.21s/it]\n","Epoch (training) 2:  49%|████▊     | 146/301 [03:09<02:46,  1.07s/it]\n","Epoch (training) 2:  49%|████▉     | 147/301 [03:10<02:35,  1.01s/it]\n","Epoch (training) 2:  49%|████▉     | 148/301 [03:12<03:20,  1.31s/it]\n","Epoch (training) 2:  50%|████▉     | 149/301 [03:14<03:19,  1.31s/it]\n","Epoch (training) 2:  50%|████▉     | 150/301 [03:15<03:08,  1.25s/it]\n","Epoch (training) 2:  50%|█████     | 151/301 [03:15<02:40,  1.07s/it]\n","Epoch (training) 2:  50%|█████     | 152/301 [03:16<02:42,  1.09s/it]\n","Epoch (training) 2:  51%|█████     | 153/301 [03:19<03:44,  1.52s/it]\n","Epoch (training) 2:  51%|█████     | 154/301 [03:20<03:30,  1.43s/it]\n","Epoch (training) 2:  51%|█████▏    | 155/301 [03:22<03:33,  1.46s/it]\n","Epoch (training) 2:  52%|█████▏    | 156/301 [03:23<03:40,  1.52s/it]\n","Epoch (training) 2:  52%|█████▏    | 157/301 [03:24<03:16,  1.36s/it]\n","Epoch (training) 2:  52%|█████▏    | 158/301 [03:25<03:00,  1.26s/it]\n","Epoch (training) 2:  53%|█████▎    | 159/301 [03:27<03:24,  1.44s/it]\n","Epoch (training) 2:  53%|█████▎    | 160/301 [03:29<03:45,  1.60s/it]\n","Epoch (training) 2:  53%|█████▎    | 161/301 [03:31<03:45,  1.61s/it]\n","Epoch (training) 2:  54%|█████▍    | 162/301 [03:32<03:29,  1.51s/it]\n","Epoch (training) 2:  54%|█████▍    | 163/301 [03:34<03:33,  1.55s/it]\n","Epoch (training) 2:  54%|█████▍    | 164/301 [03:35<03:22,  1.48s/it]\n","Epoch (training) 2:  55%|█████▍    | 165/301 [03:37<03:51,  1.70s/it]\n","Epoch (training) 2:  55%|█████▌    | 166/301 [03:39<04:03,  1.80s/it]\n","Epoch (training) 2:  55%|█████▌    | 167/301 [03:40<03:32,  1.59s/it]\n","Epoch (training) 2:  56%|█████▌    | 168/301 [03:42<03:18,  1.50s/it]\n","Epoch (training) 2:  56%|█████▌    | 169/301 [03:43<02:55,  1.33s/it]\n","Epoch (training) 2:  56%|█████▋    | 170/301 [03:44<02:48,  1.29s/it]\n","Epoch (training) 2:  57%|█████▋    | 171/301 [03:46<03:04,  1.42s/it]\n","Epoch (training) 2:  57%|█████▋    | 172/301 [03:47<03:05,  1.43s/it]\n","Epoch (training) 2:  57%|█████▋    | 173/301 [03:49<03:12,  1.50s/it]\n","Epoch (training) 2:  58%|█████▊    | 174/301 [03:50<02:54,  1.37s/it]\n","Epoch (training) 2:  58%|█████▊    | 175/301 [03:51<02:34,  1.23s/it]\n","Epoch (training) 2:  58%|█████▊    | 176/301 [03:52<02:27,  1.18s/it]\n","Epoch (training) 2:  59%|█████▉    | 177/301 [03:53<02:20,  1.14s/it]\n","Epoch (training) 2:  59%|█████▉    | 178/301 [03:54<02:20,  1.14s/it]\n","Epoch (training) 2:  59%|█████▉    | 179/301 [03:55<02:26,  1.20s/it]\n","Epoch (training) 2:  60%|█████▉    | 180/301 [03:57<02:54,  1.44s/it]\n","Epoch (training) 2:  60%|██████    | 181/301 [03:58<02:31,  1.26s/it]\n","Epoch (training) 2:  60%|██████    | 182/301 [03:59<02:11,  1.11s/it]\n","Epoch (training) 2:  61%|██████    | 183/301 [04:00<02:25,  1.23s/it]\n","Epoch (training) 2:  61%|██████    | 184/301 [04:02<02:22,  1.22s/it]\n","Epoch (training) 2:  61%|██████▏   | 185/301 [04:03<02:36,  1.35s/it]\n","Epoch (training) 2:  62%|██████▏   | 186/301 [04:04<02:31,  1.32s/it]\n","Epoch (training) 2:  62%|██████▏   | 187/301 [04:05<02:13,  1.17s/it]\n","Epoch (training) 2:  62%|██████▏   | 188/301 [04:07<02:14,  1.19s/it]\n","Epoch (training) 2:  63%|██████▎   | 189/301 [04:09<02:48,  1.51s/it]\n","Epoch (training) 2:  63%|██████▎   | 190/301 [04:11<02:55,  1.58s/it]\n","Epoch (training) 2:  63%|██████▎   | 191/301 [04:11<02:22,  1.30s/it]\n","Epoch (training) 2:  64%|██████▍   | 192/301 [04:12<02:06,  1.16s/it]\n","Epoch (training) 2:  64%|██████▍   | 193/301 [04:13<01:57,  1.09s/it]\n","Epoch (training) 2:  64%|██████▍   | 194/301 [04:14<01:43,  1.04it/s]\n","Epoch (training) 2:  65%|██████▍   | 195/301 [04:15<01:43,  1.02it/s]\n","Epoch (training) 2:  65%|██████▌   | 196/301 [04:16<01:53,  1.08s/it]\n","Epoch (training) 2:  65%|██████▌   | 197/301 [04:17<01:55,  1.11s/it]\n","Epoch (training) 2:  66%|██████▌   | 198/301 [04:19<02:06,  1.23s/it]\n","Epoch (training) 2:  66%|██████▌   | 199/301 [04:20<02:14,  1.32s/it]\n","Epoch (training) 2:  66%|██████▋   | 200/301 [04:21<02:00,  1.19s/it]\n","Epoch (training) 2:  67%|██████▋   | 201/301 [04:22<01:49,  1.10s/it]\n","Epoch (training) 2:  67%|██████▋   | 202/301 [04:23<01:39,  1.00s/it]\n","Epoch (training) 2:  67%|██████▋   | 203/301 [04:24<01:35,  1.03it/s]\n","Epoch (training) 2:  68%|██████▊   | 204/301 [04:24<01:28,  1.09it/s]\n","Epoch (training) 2:  68%|██████▊   | 205/301 [04:25<01:21,  1.18it/s]\n","Epoch (training) 2:  68%|██████▊   | 206/301 [04:26<01:24,  1.13it/s]\n","Epoch (training) 2:  69%|██████▉   | 207/301 [04:27<01:34,  1.01s/it]\n","Epoch (training) 2:  69%|██████▉   | 208/301 [04:29<01:40,  1.08s/it]\n","Epoch (training) 2:  69%|██████▉   | 209/301 [04:30<01:37,  1.06s/it]\n","Epoch (training) 2:  70%|██████▉   | 210/301 [04:31<01:55,  1.27s/it]\n","Epoch (training) 2:  70%|███████   | 211/301 [04:33<01:50,  1.23s/it]\n","Epoch (training) 2:  70%|███████   | 212/301 [04:34<01:54,  1.29s/it]\n","Epoch (training) 2:  71%|███████   | 213/301 [04:36<02:03,  1.41s/it]\n","Epoch (training) 2:  71%|███████   | 214/301 [04:37<01:50,  1.27s/it]\n","Epoch (training) 2:  71%|███████▏  | 215/301 [04:38<01:41,  1.18s/it]\n","Epoch (training) 2:  72%|███████▏  | 216/301 [04:38<01:28,  1.04s/it]\n","Epoch (training) 2:  72%|███████▏  | 217/301 [04:39<01:24,  1.00s/it]\n","Epoch (training) 2:  72%|███████▏  | 218/301 [04:41<01:36,  1.16s/it]\n","Epoch (training) 2:  73%|███████▎  | 219/301 [04:42<01:27,  1.07s/it]\n","Epoch (training) 2:  73%|███████▎  | 220/301 [04:42<01:22,  1.01s/it]\n","Epoch (training) 2:  73%|███████▎  | 221/301 [04:44<01:34,  1.18s/it]\n","Epoch (training) 2:  74%|███████▍  | 222/301 [04:46<01:49,  1.39s/it]\n","Epoch (training) 2:  74%|███████▍  | 223/301 [04:47<01:46,  1.36s/it]\n","Epoch (training) 2:  74%|███████▍  | 224/301 [04:49<01:44,  1.36s/it]\n","Epoch (training) 2:  75%|███████▍  | 225/301 [04:50<01:38,  1.29s/it]\n","Epoch (training) 2:  75%|███████▌  | 226/301 [04:51<01:36,  1.29s/it]\n","Epoch (training) 2:  75%|███████▌  | 227/301 [04:52<01:29,  1.21s/it]\n","Epoch (training) 2:  76%|███████▌  | 228/301 [04:53<01:29,  1.23s/it]\n","Epoch (training) 2:  76%|███████▌  | 229/301 [04:54<01:24,  1.17s/it]\n","Epoch (training) 2:  76%|███████▋  | 230/301 [04:56<01:24,  1.19s/it]\n","Epoch (training) 2:  77%|███████▋  | 231/301 [04:56<01:13,  1.05s/it]\n","Epoch (training) 2:  77%|███████▋  | 232/301 [04:57<01:10,  1.03s/it]\n","Epoch (training) 2:  77%|███████▋  | 233/301 [04:58<01:13,  1.07s/it]\n","Epoch (training) 2:  78%|███████▊  | 234/301 [05:00<01:26,  1.29s/it]\n","Epoch (training) 2:  78%|███████▊  | 235/301 [05:02<01:29,  1.36s/it]\n","Epoch (training) 2:  78%|███████▊  | 236/301 [05:03<01:21,  1.25s/it]\n","Epoch (training) 2:  79%|███████▊  | 237/301 [05:04<01:20,  1.26s/it]\n","Epoch (training) 2:  79%|███████▉  | 238/301 [05:05<01:11,  1.14s/it]\n","Epoch (training) 2:  79%|███████▉  | 239/301 [05:06<01:09,  1.11s/it]\n","Epoch (training) 2:  80%|███████▉  | 240/301 [05:07<01:13,  1.20s/it]\n","Epoch (training) 2:  80%|████████  | 241/301 [05:08<01:10,  1.17s/it]\n","Epoch (training) 2:  80%|████████  | 242/301 [05:09<01:05,  1.12s/it]\n","Epoch (training) 2:  81%|████████  | 243/301 [05:11<01:10,  1.22s/it]\n","Epoch (training) 2:  81%|████████  | 244/301 [05:12<01:06,  1.16s/it]\n","Epoch (training) 2:  81%|████████▏ | 245/301 [05:13<01:03,  1.13s/it]\n","Epoch (training) 2:  82%|████████▏ | 246/301 [05:14<01:07,  1.24s/it]\n","Epoch (training) 2:  82%|████████▏ | 247/301 [05:16<01:15,  1.39s/it]\n","Epoch (training) 2:  82%|████████▏ | 248/301 [05:17<01:10,  1.32s/it]\n","Epoch (training) 2:  83%|████████▎ | 249/301 [05:18<01:01,  1.18s/it]\n","Epoch (training) 2:  83%|████████▎ | 250/301 [05:19<00:58,  1.15s/it]\n","Epoch (training) 2:  83%|████████▎ | 251/301 [05:20<00:51,  1.04s/it]\n","Epoch (training) 2:  84%|████████▎ | 252/301 [05:21<00:56,  1.15s/it]\n","Epoch (training) 2:  84%|████████▍ | 253/301 [05:23<00:54,  1.13s/it]\n","Epoch (training) 2:  84%|████████▍ | 254/301 [05:24<01:00,  1.28s/it]\n","Epoch (training) 2:  85%|████████▍ | 255/301 [05:25<00:58,  1.26s/it]\n","Epoch (training) 2:  85%|████████▌ | 256/301 [05:26<00:53,  1.20s/it]\n","Epoch (training) 2:  85%|████████▌ | 257/301 [05:28<00:55,  1.27s/it]\n","Epoch (training) 2:  86%|████████▌ | 258/301 [05:30<01:00,  1.40s/it]\n","Epoch (training) 2:  86%|████████▌ | 259/301 [05:31<01:01,  1.46s/it]\n","Epoch (training) 2:  86%|████████▋ | 260/301 [05:33<00:59,  1.44s/it]\n","Epoch (training) 2:  87%|████████▋ | 261/301 [05:33<00:50,  1.26s/it]\n","Epoch (training) 2:  87%|████████▋ | 262/301 [05:35<00:52,  1.34s/it]\n","Epoch (training) 2:  87%|████████▋ | 263/301 [05:36<00:45,  1.21s/it]\n","Epoch (training) 2:  88%|████████▊ | 264/301 [05:38<00:55,  1.51s/it]\n","Epoch (training) 2:  88%|████████▊ | 265/301 [05:39<00:51,  1.44s/it]\n","Epoch (training) 2:  88%|████████▊ | 266/301 [05:40<00:46,  1.32s/it]\n","Epoch (training) 2:  89%|████████▊ | 267/301 [05:41<00:38,  1.12s/it]\n","Epoch (training) 2:  89%|████████▉ | 268/301 [05:42<00:40,  1.22s/it]\n","Epoch (training) 2:  89%|████████▉ | 269/301 [05:44<00:43,  1.37s/it]\n","Epoch (training) 2:  90%|████████▉ | 270/301 [05:45<00:40,  1.30s/it]\n","Epoch (training) 2:  90%|█████████ | 271/301 [05:46<00:34,  1.15s/it]\n","Epoch (training) 2:  90%|█████████ | 272/301 [05:47<00:32,  1.12s/it]\n","Epoch (training) 2:  91%|█████████ | 273/301 [05:48<00:31,  1.11s/it]\n","Epoch (training) 2:  91%|█████████ | 274/301 [05:49<00:27,  1.00s/it]\n","Epoch (training) 2:  91%|█████████▏| 275/301 [05:50<00:25,  1.00it/s]\n","Epoch (training) 2:  92%|█████████▏| 276/301 [05:51<00:27,  1.10s/it]\n","Epoch (training) 2:  92%|█████████▏| 277/301 [05:53<00:27,  1.14s/it]\n","Epoch (training) 2:  92%|█████████▏| 278/301 [05:53<00:24,  1.06s/it]\n","Epoch (training) 2:  93%|█████████▎| 279/301 [05:55<00:23,  1.05s/it]\n","Epoch (training) 2:  93%|█████████▎| 280/301 [05:56<00:21,  1.04s/it]\n","Epoch (training) 2:  93%|█████████▎| 281/301 [05:57<00:20,  1.03s/it]\n","Epoch (training) 2:  94%|█████████▎| 282/301 [05:58<00:19,  1.04s/it]\n","Epoch (training) 2:  94%|█████████▍| 283/301 [05:59<00:19,  1.09s/it]\n","Epoch (training) 2:  94%|█████████▍| 284/301 [06:00<00:19,  1.15s/it]\n","Epoch (training) 2:  95%|█████████▍| 285/301 [06:01<00:17,  1.12s/it]\n","Epoch (training) 2:  95%|█████████▌| 286/301 [06:03<00:21,  1.44s/it]\n","Epoch (training) 2:  95%|█████████▌| 287/301 [06:04<00:18,  1.32s/it]\n","Epoch (training) 2:  96%|█████████▌| 288/301 [06:05<00:15,  1.17s/it]\n","Epoch (training) 2:  96%|█████████▌| 289/301 [06:06<00:12,  1.03s/it]\n","Epoch (training) 2:  96%|█████████▋| 290/301 [06:08<00:13,  1.26s/it]\n","Epoch (training) 2:  97%|█████████▋| 291/301 [06:09<00:13,  1.32s/it]\n","Epoch (training) 2:  97%|█████████▋| 292/301 [06:11<00:14,  1.60s/it]\n","Epoch (training) 2:  97%|█████████▋| 293/301 [06:14<00:14,  1.80s/it]\n","Epoch (training) 2:  98%|█████████▊| 294/301 [06:15<00:11,  1.64s/it]\n","Epoch (training) 2:  98%|█████████▊| 295/301 [06:16<00:08,  1.39s/it]\n","Epoch (training) 2:  98%|█████████▊| 296/301 [06:18<00:07,  1.50s/it]\n","Epoch (training) 2:  99%|█████████▊| 297/301 [06:19<00:05,  1.37s/it]\n","Epoch (training) 2:  99%|█████████▉| 298/301 [06:20<00:04,  1.41s/it]\n","Epoch (training) 2:  99%|█████████▉| 299/301 [06:22<00:02,  1.44s/it]\n","Epoch (training) 2: 100%|█████████▉| 300/301 [06:22<00:01,  1.08s/it]\n","Epoch (training) 2: 100%|██████████| 301/301 [06:22<00:00,  1.27s/it]\n","Epoch (test) 2:   0%|          | 0/76 [00:00<?, ?it/s]\n","Epoch (test) 2:   1%|▏         | 1/76 [00:01<01:55,  1.54s/it]\n","Epoch (test) 2:   3%|▎         | 2/76 [00:02<01:30,  1.23s/it]\n","Epoch (test) 2:   4%|▍         | 3/76 [00:03<01:26,  1.19s/it]\n","Epoch (test) 2:   5%|▌         | 4/76 [00:04<01:25,  1.18s/it]\n","Epoch (test) 2:   7%|▋         | 5/76 [00:06<01:31,  1.29s/it]\n","Epoch (test) 2:   8%|▊         | 6/76 [00:07<01:19,  1.14s/it]\n","Epoch (test) 2:   9%|▉         | 7/76 [00:08<01:21,  1.18s/it]\n","Epoch (test) 2:  11%|█         | 8/76 [00:09<01:09,  1.02s/it]\n","Epoch (test) 2:  12%|█▏        | 9/76 [00:10<01:05,  1.02it/s]\n","Epoch (test) 2:  13%|█▎        | 10/76 [00:10<01:03,  1.04it/s]\n","Epoch (test) 2:  14%|█▍        | 11/76 [00:11<00:55,  1.17it/s]\n","Epoch (test) 2:  16%|█▌        | 12/76 [00:12<00:53,  1.20it/s]\n","Epoch (test) 2:  17%|█▋        | 13/76 [00:13<00:54,  1.15it/s]\n","Epoch (test) 2:  18%|█▊        | 14/76 [00:14<00:51,  1.21it/s]\n","Epoch (test) 2:  20%|█▉        | 15/76 [00:14<00:44,  1.37it/s]\n","Epoch (test) 2:  21%|██        | 16/76 [00:15<00:42,  1.43it/s]\n","Epoch (test) 2:  22%|██▏       | 17/76 [00:15<00:37,  1.57it/s]\n","Epoch (test) 2:  24%|██▎       | 18/76 [00:16<00:41,  1.40it/s]\n","Epoch (test) 2:  25%|██▌       | 19/76 [00:17<00:37,  1.51it/s]\n","Epoch (test) 2:  26%|██▋       | 20/76 [00:17<00:39,  1.41it/s]\n","Epoch (test) 2:  28%|██▊       | 21/76 [00:19<00:48,  1.14it/s]\n","Epoch (test) 2:  29%|██▉       | 22/76 [00:20<00:53,  1.02it/s]\n","Epoch (test) 2:  30%|███       | 23/76 [00:21<00:56,  1.06s/it]\n","Epoch (test) 2:  32%|███▏      | 24/76 [00:22<00:53,  1.03s/it]\n","Epoch (test) 2:  33%|███▎      | 25/76 [00:23<00:56,  1.11s/it]\n","Epoch (test) 2:  34%|███▍      | 26/76 [00:25<00:57,  1.15s/it]\n","Epoch (test) 2:  36%|███▌      | 27/76 [00:25<00:50,  1.03s/it]\n","Epoch (test) 2:  37%|███▋      | 28/76 [00:27<00:50,  1.06s/it]\n","Epoch (test) 2:  38%|███▊      | 29/76 [00:28<00:50,  1.06s/it]\n","Epoch (test) 2:  39%|███▉      | 30/76 [00:28<00:43,  1.06it/s]\n","Epoch (test) 2:  41%|████      | 31/76 [00:29<00:40,  1.10it/s]\n","Epoch (test) 2:  42%|████▏     | 32/76 [00:30<00:44,  1.01s/it]\n","Epoch (test) 2:  43%|████▎     | 33/76 [00:31<00:38,  1.12it/s]\n","Epoch (test) 2:  45%|████▍     | 34/76 [00:32<00:35,  1.20it/s]\n","Epoch (test) 2:  46%|████▌     | 35/76 [00:33<00:36,  1.13it/s]\n","Epoch (test) 2:  47%|████▋     | 36/76 [00:33<00:33,  1.21it/s]\n","Epoch (test) 2:  49%|████▊     | 37/76 [00:34<00:32,  1.19it/s]\n","Epoch (test) 2:  50%|█████     | 38/76 [00:35<00:31,  1.20it/s]\n","Epoch (test) 2:  51%|█████▏    | 39/76 [00:37<00:39,  1.07s/it]\n","Epoch (test) 2:  53%|█████▎    | 40/76 [00:37<00:35,  1.03it/s]\n","Epoch (test) 2:  54%|█████▍    | 41/76 [00:38<00:29,  1.20it/s]\n","Epoch (test) 2:  55%|█████▌    | 42/76 [00:39<00:29,  1.14it/s]\n","Epoch (test) 2:  57%|█████▋    | 43/76 [00:40<00:30,  1.07it/s]\n","Epoch (test) 2:  58%|█████▊    | 44/76 [00:41<00:30,  1.06it/s]\n","Epoch (test) 2:  59%|█████▉    | 45/76 [00:42<00:27,  1.12it/s]\n","Epoch (test) 2:  61%|██████    | 46/76 [00:44<00:37,  1.24s/it]\n","Epoch (test) 2:  62%|██████▏   | 47/76 [00:45<00:35,  1.23s/it]\n","Epoch (test) 2:  63%|██████▎   | 48/76 [00:46<00:33,  1.21s/it]\n","Epoch (test) 2:  64%|██████▍   | 49/76 [00:48<00:36,  1.34s/it]\n","Epoch (test) 2:  66%|██████▌   | 50/76 [00:51<00:47,  1.81s/it]\n","Epoch (test) 2:  67%|██████▋   | 51/76 [00:52<00:42,  1.69s/it]\n","Epoch (test) 2:  68%|██████▊   | 52/76 [00:54<00:40,  1.69s/it]\n","Epoch (test) 2:  70%|██████▉   | 53/76 [00:55<00:37,  1.61s/it]\n","Epoch (test) 2:  71%|███████   | 54/76 [00:58<00:43,  1.97s/it]\n","Epoch (test) 2:  72%|███████▏  | 55/76 [01:00<00:42,  2.01s/it]\n","Epoch (test) 2:  74%|███████▎  | 56/76 [01:02<00:39,  1.99s/it]\n","Epoch (test) 2:  75%|███████▌  | 57/76 [01:05<00:40,  2.15s/it]\n","Epoch (test) 2:  76%|███████▋  | 58/76 [01:06<00:36,  2.01s/it]\n","Epoch (test) 2:  78%|███████▊  | 59/76 [01:07<00:29,  1.72s/it]\n","Epoch (test) 2:  79%|███████▉  | 60/76 [01:09<00:25,  1.62s/it]\n","Epoch (test) 2:  80%|████████  | 61/76 [01:10<00:23,  1.55s/it]\n","Epoch (test) 2:  82%|████████▏ | 62/76 [01:11<00:20,  1.43s/it]\n","Epoch (test) 2:  83%|████████▎ | 63/76 [01:13<00:18,  1.45s/it]\n","Epoch (test) 2:  84%|████████▍ | 64/76 [01:15<00:21,  1.76s/it]\n","Epoch (test) 2:  86%|████████▌ | 65/76 [01:17<00:18,  1.71s/it]\n","Epoch (test) 2:  87%|████████▋ | 66/76 [01:18<00:16,  1.61s/it]\n","Epoch (test) 2:  88%|████████▊ | 67/76 [01:20<00:14,  1.62s/it]\n","Epoch (test) 2:  89%|████████▉ | 68/76 [01:21<00:12,  1.56s/it]\n","Epoch (test) 2:  91%|█████████ | 69/76 [01:23<00:11,  1.63s/it]\n","Epoch (test) 2:  92%|█████████▏| 70/76 [01:26<00:11,  1.90s/it]\n","Epoch (test) 2:  93%|█████████▎| 71/76 [01:28<00:09,  1.98s/it]\n","Epoch (test) 2:  95%|█████████▍| 72/76 [01:29<00:07,  1.81s/it]\n","Epoch (test) 2:  96%|█████████▌| 73/76 [01:31<00:05,  1.73s/it]\n","Epoch (test) 2:  97%|█████████▋| 74/76 [01:36<00:05,  2.72s/it]\n","Epoch (test) 2:  99%|█████████▊| 75/76 [01:36<00:01,  1.94s/it]\n","Epoch (test) 2: 100%|██████████| 76/76 [01:36<00:00,  1.27s/it]\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_cv_outer_4/TorchTrainer_b33ac_00000_0_2024-04-14_19-32-16/checkpoint_000001)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training finished iteration 2 at 2024-04-14 21:17:05. Total running time: 1hr 44min 49s\n","+---------------------------------------------+\n","| Training result                             |\n","+---------------------------------------------+\n","| checkpoint_dir_name       checkpoint_000001 |\n","| time_this_iter_s                  485.51512 |\n","| time_total_s                     6280.15144 |\n","| training_iteration                        2 |\n","| accuracy                            0.40292 |\n","| confusion_matrix       ..., 8, 11, 10, 11]) |\n","| f1                                  0.39339 |\n","| loss                                1.75712 |\n","| precision                           0.43497 |\n","| recall                              0.40292 |\n","| summary/epoch/0                         1.0 |\n","| summary/epoch/1                         2.0 |\n","| summary/train_acc/0     0.28052083333333333 |\n","| summary/train_acc/1     0.40020833333333333 |\n","| summary/train_loss/0     2.0832002725316046 |\n","| summary/train_loss/1      1.756782130545556 |\n","| summary/val_acc/0       0.37833333333333335 |\n","| summary/val_acc/1       0.40291666666666665 |\n","| summary/val_loss/0       1.8843663452487243 |\n","| summary/val_loss/1        1.757122580158083 |\n","+---------------------------------------------+\n","Training saved a checkpoint for iteration 2 at: (local)/root/ray_results/wide_resnet50_cv_outer_4/TorchTrainer_b33ac_00000_0_2024-04-14_19-32-16/checkpoint_000001\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 3:   0%|          | 0/301 [00:00<?, ?it/s]\n","Epoch (training) 3:   0%|          | 1/301 [00:02<14:33,  2.91s/it]\n","Epoch (training) 3:   1%|          | 2/301 [00:04<11:48,  2.37s/it]\n","Epoch (training) 3:   1%|          | 3/301 [00:06<09:39,  1.94s/it]\n","Epoch (training) 3:   1%|▏         | 4/301 [00:07<08:39,  1.75s/it]\n","Epoch (training) 3:   2%|▏         | 5/301 [00:08<07:11,  1.46s/it]\n","Epoch (training) 3:   2%|▏         | 6/301 [00:09<05:57,  1.21s/it]\n","Epoch (training) 3:   2%|▏         | 7/301 [00:10<05:36,  1.14s/it]\n","Epoch (training) 3:   3%|▎         | 8/301 [00:11<05:53,  1.21s/it]\n","Epoch (training) 3:   3%|▎         | 9/301 [00:12<05:41,  1.17s/it]\n","Epoch (training) 3:   3%|▎         | 10/301 [00:13<05:22,  1.11s/it]\n","Epoch (training) 3:   4%|▎         | 11/301 [00:15<06:15,  1.29s/it]\n","Epoch (training) 3:   4%|▍         | 12/301 [00:16<06:00,  1.25s/it]\n","Epoch (training) 3:   4%|▍         | 13/301 [00:17<05:51,  1.22s/it]\n","Epoch (training) 3:   5%|▍         | 14/301 [00:20<07:57,  1.66s/it]\n","Epoch (training) 3:   5%|▍         | 15/301 [00:21<07:06,  1.49s/it]\n","Epoch (training) 3:   5%|▌         | 16/301 [00:22<06:23,  1.35s/it]\n","Epoch (training) 3:   6%|▌         | 17/301 [00:23<05:50,  1.24s/it]\n","Epoch (training) 3:   6%|▌         | 18/301 [00:24<05:12,  1.10s/it]\n","Epoch (training) 3:   6%|▋         | 19/301 [00:26<06:02,  1.29s/it]\n","Epoch (training) 3:   7%|▋         | 20/301 [00:27<05:53,  1.26s/it]\n","Epoch (training) 3:   7%|▋         | 21/301 [00:28<05:50,  1.25s/it]\n","Epoch (training) 3:   7%|▋         | 22/301 [00:29<05:30,  1.19s/it]\n","Epoch (training) 3:   8%|▊         | 23/301 [00:30<05:13,  1.13s/it]\n","Epoch (training) 3:   8%|▊         | 24/301 [00:32<06:02,  1.31s/it]\n","Epoch (training) 3:   8%|▊         | 25/301 [00:33<06:23,  1.39s/it]\n","Epoch (training) 3:   9%|▊         | 26/301 [00:35<06:35,  1.44s/it]\n","Epoch (training) 3:   9%|▉         | 27/301 [00:36<06:08,  1.34s/it]\n","Epoch (training) 3:   9%|▉         | 28/301 [00:37<05:33,  1.22s/it]\n","Epoch (training) 3:  10%|▉         | 29/301 [00:38<05:36,  1.24s/it]\n","Epoch (training) 3:  10%|▉         | 30/301 [00:39<05:15,  1.16s/it]\n","Epoch (training) 3:  10%|█         | 31/301 [00:40<04:46,  1.06s/it]\n","Epoch (training) 3:  11%|█         | 32/301 [00:41<05:01,  1.12s/it]\n","Epoch (training) 3:  11%|█         | 33/301 [00:43<05:43,  1.28s/it]\n","Epoch (training) 3:  11%|█▏        | 34/301 [00:44<05:09,  1.16s/it]\n","Epoch (training) 3:  12%|█▏        | 35/301 [00:45<04:43,  1.06s/it]\n","Epoch (training) 3:  12%|█▏        | 36/301 [00:47<05:41,  1.29s/it]\n","Epoch (training) 3:  12%|█▏        | 37/301 [00:48<06:25,  1.46s/it]\n","Epoch (training) 3:  13%|█▎        | 38/301 [00:50<06:59,  1.59s/it]\n","Epoch (training) 3:  13%|█▎        | 39/301 [00:51<05:58,  1.37s/it]\n","Epoch (training) 3:  13%|█▎        | 40/301 [00:52<05:08,  1.18s/it]\n","Epoch (training) 3:  14%|█▎        | 41/301 [00:53<05:05,  1.17s/it]\n","Epoch (training) 3:  14%|█▍        | 42/301 [00:54<04:31,  1.05s/it]\n","Epoch (training) 3:  14%|█▍        | 43/301 [00:55<04:54,  1.14s/it]\n","Epoch (training) 3:  15%|█▍        | 44/301 [00:56<04:44,  1.11s/it]\n","Epoch (training) 3:  15%|█▍        | 45/301 [00:58<05:10,  1.21s/it]\n","Epoch (training) 3:  15%|█▌        | 46/301 [00:59<04:55,  1.16s/it]\n","Epoch (training) 3:  16%|█▌        | 47/301 [01:00<04:49,  1.14s/it]\n","Epoch (training) 3:  16%|█▌        | 48/301 [01:01<04:59,  1.18s/it]\n","Epoch (training) 3:  16%|█▋        | 49/301 [01:03<06:29,  1.54s/it]\n","Epoch (training) 3:  17%|█▋        | 50/301 [01:05<06:26,  1.54s/it]\n","Epoch (training) 3:  17%|█▋        | 51/301 [01:06<05:39,  1.36s/it]\n","Epoch (training) 3:  17%|█▋        | 52/301 [01:07<05:16,  1.27s/it]\n","Epoch (training) 3:  18%|█▊        | 53/301 [01:08<05:01,  1.22s/it]\n","Epoch (training) 3:  18%|█▊        | 54/301 [01:09<05:11,  1.26s/it]\n","Epoch (training) 3:  18%|█▊        | 55/301 [01:12<06:08,  1.50s/it]\n","Epoch (training) 3:  19%|█▊        | 56/301 [01:12<05:22,  1.32s/it]\n","Epoch (training) 3:  19%|█▉        | 57/301 [01:13<04:59,  1.23s/it]\n","Epoch (training) 3:  19%|█▉        | 58/301 [01:15<05:09,  1.27s/it]\n","Epoch (training) 3:  20%|█▉        | 59/301 [01:16<04:48,  1.19s/it]\n","Epoch (training) 3:  20%|█▉        | 60/301 [01:17<04:39,  1.16s/it]\n","Epoch (training) 3:  20%|██        | 61/301 [01:18<05:02,  1.26s/it]\n","Epoch (training) 3:  21%|██        | 62/301 [01:19<04:38,  1.16s/it]\n","Epoch (training) 3:  21%|██        | 63/301 [01:22<06:05,  1.53s/it]\n","Epoch (training) 3:  21%|██▏       | 64/301 [01:23<05:34,  1.41s/it]\n","Epoch (training) 3:  22%|██▏       | 65/301 [01:25<05:54,  1.50s/it]\n","Epoch (training) 3:  22%|██▏       | 66/301 [01:26<05:19,  1.36s/it]\n","Epoch (training) 3:  22%|██▏       | 67/301 [01:26<04:41,  1.20s/it]\n","Epoch (training) 3:  23%|██▎       | 68/301 [01:28<04:55,  1.27s/it]\n","Epoch (training) 3:  23%|██▎       | 69/301 [01:29<04:28,  1.16s/it]\n","Epoch (training) 3:  23%|██▎       | 70/301 [01:29<03:47,  1.02it/s]\n","Epoch (training) 3:  24%|██▎       | 71/301 [01:31<04:46,  1.25s/it]\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m /usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m   warnings.warn(\n","Epoch (training) 3:  24%|██▍       | 72/301 [01:32<04:46,  1.25s/it]\n","Epoch (training) 3:  24%|██▍       | 73/301 [01:34<04:44,  1.25s/it]\n","Epoch (training) 3:  25%|██▍       | 74/301 [01:35<05:04,  1.34s/it]\n","Epoch (training) 3:  25%|██▍       | 75/301 [01:36<04:54,  1.31s/it]\n","Epoch (training) 3:  25%|██▌       | 76/301 [01:38<05:22,  1.43s/it]\n","Epoch (training) 3:  26%|██▌       | 77/301 [01:39<04:58,  1.33s/it]\n","Epoch (training) 3:  26%|██▌       | 78/301 [01:41<05:20,  1.44s/it]\n","Epoch (training) 3:  26%|██▌       | 79/301 [01:42<04:46,  1.29s/it]\n","Epoch (training) 3:  27%|██▋       | 80/301 [01:43<04:56,  1.34s/it]\n","Epoch (training) 3:  27%|██▋       | 81/301 [01:44<04:27,  1.22s/it]\n","Epoch (training) 3:  27%|██▋       | 82/301 [01:45<04:12,  1.15s/it]\n","Epoch (training) 3:  28%|██▊       | 83/301 [01:48<06:11,  1.71s/it]\n","Epoch (training) 3:  28%|██▊       | 84/301 [01:50<06:05,  1.68s/it]\n","Epoch (training) 3:  28%|██▊       | 85/301 [01:51<05:15,  1.46s/it]\n","Epoch (training) 3:  29%|██▊       | 86/301 [01:52<04:50,  1.35s/it]\n","Epoch (training) 3:  29%|██▉       | 87/301 [01:53<04:19,  1.21s/it]\n","Epoch (training) 3:  29%|██▉       | 88/301 [01:54<03:53,  1.10s/it]\n","Epoch (training) 3:  30%|██▉       | 89/301 [01:56<04:42,  1.33s/it]\n","Epoch (training) 3:  30%|██▉       | 90/301 [01:57<04:29,  1.28s/it]\n","Epoch (training) 3:  30%|███       | 91/301 [01:58<04:01,  1.15s/it]\n","Epoch (training) 3:  31%|███       | 92/301 [01:59<04:13,  1.21s/it]\n","Epoch (training) 3:  31%|███       | 93/301 [02:00<04:10,  1.20s/it]\n","Epoch (training) 3:  31%|███       | 94/301 [02:01<04:17,  1.24s/it]\n","Epoch (training) 3:  32%|███▏      | 95/301 [02:03<04:33,  1.33s/it]\n","Epoch (training) 3:  32%|███▏      | 96/301 [02:04<04:34,  1.34s/it]\n","Epoch (training) 3:  32%|███▏      | 97/301 [02:05<03:56,  1.16s/it]\n","Epoch (training) 3:  33%|███▎      | 98/301 [02:07<04:14,  1.26s/it]\n","Epoch (training) 3:  33%|███▎      | 99/301 [02:08<04:05,  1.22s/it]\n","Epoch (training) 3:  33%|███▎      | 100/301 [02:09<04:24,  1.32s/it]\n","Epoch (training) 3:  34%|███▎      | 101/301 [02:11<04:28,  1.34s/it]\n","Epoch (training) 3:  34%|███▍      | 102/301 [02:13<05:03,  1.53s/it]\n","Epoch (training) 3:  34%|███▍      | 103/301 [02:14<05:13,  1.59s/it]\n","Epoch (training) 3:  35%|███▍      | 104/301 [02:16<05:17,  1.61s/it]\n","Epoch (training) 3:  35%|███▍      | 105/301 [02:17<05:00,  1.53s/it]\n","Epoch (training) 3:  35%|███▌      | 106/301 [02:19<04:55,  1.51s/it]\n","Epoch (training) 3:  36%|███▌      | 107/301 [02:20<04:39,  1.44s/it]\n","Epoch (training) 3:  36%|███▌      | 108/301 [02:21<04:03,  1.26s/it]\n","Epoch (training) 3:  36%|███▌      | 109/301 [02:22<04:08,  1.29s/it]\n","Epoch (training) 3:  37%|███▋      | 110/301 [02:23<03:31,  1.11s/it]\n","Epoch (training) 3:  37%|███▋      | 111/301 [02:24<03:25,  1.08s/it]\n","Epoch (training) 3:  37%|███▋      | 112/301 [02:25<03:03,  1.03it/s]\n","Epoch (training) 3:  38%|███▊      | 113/301 [02:26<03:29,  1.11s/it]\n","Epoch (training) 3:  38%|███▊      | 114/301 [02:27<03:16,  1.05s/it]\n","Epoch (training) 3:  38%|███▊      | 115/301 [02:28<03:05,  1.00it/s]\n","Epoch (training) 3:  39%|███▊      | 116/301 [02:30<03:59,  1.30s/it]\n","Epoch (training) 3:  39%|███▉      | 117/301 [02:32<04:44,  1.55s/it]\n","Epoch (training) 3:  39%|███▉      | 118/301 [02:34<05:00,  1.64s/it]\n","Epoch (training) 3:  40%|███▉      | 119/301 [02:35<04:53,  1.61s/it]\n","Epoch (training) 3:  40%|███▉      | 120/301 [02:37<05:05,  1.69s/it]\n","Epoch (training) 3:  40%|████      | 121/301 [02:38<04:27,  1.48s/it]\n","Epoch (training) 3:  41%|████      | 122/301 [02:39<04:00,  1.34s/it]\n","Epoch (training) 3:  41%|████      | 123/301 [02:40<03:31,  1.19s/it]\n","Epoch (training) 3:  41%|████      | 124/301 [02:41<03:16,  1.11s/it]\n","Epoch (training) 3:  42%|████▏     | 125/301 [02:42<03:15,  1.11s/it]\n","Epoch (training) 3:  42%|████▏     | 126/301 [02:43<02:59,  1.02s/it]\n","Epoch (training) 3:  42%|████▏     | 127/301 [02:45<03:42,  1.28s/it]\n","Epoch (training) 3:  43%|████▎     | 128/301 [02:47<04:48,  1.67s/it]\n","Epoch (training) 3:  43%|████▎     | 129/301 [02:49<04:59,  1.74s/it]\n","Epoch (training) 3:  43%|████▎     | 130/301 [02:50<04:14,  1.49s/it]\n","Epoch (training) 3:  44%|████▎     | 131/301 [02:51<03:47,  1.34s/it]\n","Epoch (training) 3:  44%|████▍     | 132/301 [02:53<03:46,  1.34s/it]\n","Epoch (training) 3:  44%|████▍     | 133/301 [02:53<03:18,  1.18s/it]\n","Epoch (training) 3:  45%|████▍     | 134/301 [02:55<03:30,  1.26s/it]\n","Epoch (training) 3:  45%|████▍     | 135/301 [02:56<03:12,  1.16s/it]\n","Epoch (training) 3:  45%|████▌     | 136/301 [02:58<03:42,  1.35s/it]\n","Epoch (training) 3:  46%|████▌     | 137/301 [03:00<04:22,  1.60s/it]\n","Epoch (training) 3:  46%|████▌     | 138/301 [03:01<04:07,  1.52s/it]\n","Epoch (training) 3:  46%|████▌     | 139/301 [03:03<04:02,  1.50s/it]\n","Epoch (training) 3:  47%|████▋     | 140/301 [03:03<03:30,  1.31s/it]\n","Epoch (training) 3:  47%|████▋     | 141/301 [03:04<03:12,  1.20s/it]\n","Epoch (training) 3:  47%|████▋     | 142/301 [03:05<02:59,  1.13s/it]\n","Epoch (training) 3:  48%|████▊     | 143/301 [03:06<02:51,  1.08s/it]\n","Epoch (training) 3:  48%|████▊     | 144/301 [03:08<02:54,  1.11s/it]\n","Epoch (training) 3:  48%|████▊     | 145/301 [03:09<03:10,  1.22s/it]\n","Epoch (training) 3:  49%|████▊     | 146/301 [03:11<03:42,  1.44s/it]\n","Epoch (training) 3:  49%|████▉     | 147/301 [03:12<03:33,  1.39s/it]\n","Epoch (training) 3:  49%|████▉     | 148/301 [03:13<03:27,  1.36s/it]\n","Epoch (training) 3:  50%|████▉     | 149/301 [03:15<03:21,  1.33s/it]\n","Epoch (training) 3:  50%|████▉     | 150/301 [03:16<03:24,  1.36s/it]\n","Epoch (training) 3:  50%|█████     | 151/301 [03:19<04:09,  1.66s/it]\n","Epoch (training) 3:  50%|█████     | 152/301 [03:20<03:44,  1.51s/it]\n","Epoch (training) 3:  51%|█████     | 153/301 [03:21<03:23,  1.37s/it]\n","Epoch (training) 3:  51%|█████     | 154/301 [03:22<03:23,  1.38s/it]\n","Epoch (training) 3:  51%|█████▏    | 155/301 [03:23<02:49,  1.16s/it]\n","Epoch (training) 3:  52%|█████▏    | 156/301 [03:24<02:41,  1.11s/it]\n","Epoch (training) 3:  52%|█████▏    | 157/301 [03:24<02:20,  1.03it/s]\n","Epoch (training) 3:  52%|█████▏    | 158/301 [03:26<02:22,  1.00it/s]\n","Epoch (training) 3:  53%|█████▎    | 159/301 [03:26<02:14,  1.06it/s]\n","Epoch (training) 3:  53%|█████▎    | 160/301 [03:27<02:16,  1.03it/s]\n","Epoch (training) 3:  53%|█████▎    | 161/301 [03:28<02:13,  1.05it/s]\n","Epoch (training) 3:  54%|█████▍    | 162/301 [03:29<02:15,  1.02it/s]\n","Epoch (training) 3:  54%|█████▍    | 163/301 [03:31<02:46,  1.20s/it]\n","Epoch (training) 3:  54%|█████▍    | 164/301 [03:33<03:08,  1.38s/it]\n","Epoch (training) 3:  55%|█████▍    | 165/301 [03:34<02:55,  1.29s/it]\n","Epoch (training) 3:  55%|█████▌    | 166/301 [03:35<02:59,  1.33s/it]\n","Epoch (training) 3:  55%|█████▌    | 167/301 [03:37<03:04,  1.38s/it]\n","Epoch (training) 3:  56%|█████▌    | 168/301 [03:38<03:08,  1.42s/it]\n","Epoch (training) 3:  56%|█████▌    | 169/301 [03:40<03:18,  1.50s/it]\n","Epoch (training) 3:  56%|█████▋    | 170/301 [03:41<03:14,  1.49s/it]\n","Epoch (training) 3:  57%|█████▋    | 171/301 [03:42<02:53,  1.33s/it]\n","Epoch (training) 3:  57%|█████▋    | 172/301 [03:44<02:58,  1.38s/it]\n","Epoch (training) 3:  57%|█████▋    | 173/301 [03:45<02:58,  1.39s/it]\n","Epoch (training) 3:  58%|█████▊    | 174/301 [03:47<03:17,  1.55s/it]\n","Epoch (training) 3:  58%|█████▊    | 175/301 [03:48<02:49,  1.34s/it]\n","Epoch (training) 3:  58%|█████▊    | 176/301 [03:49<02:29,  1.19s/it]\n","Epoch (training) 3:  59%|█████▉    | 177/301 [03:50<02:07,  1.03s/it]\n","Epoch (training) 3:  59%|█████▉    | 178/301 [03:51<02:05,  1.02s/it]\n","Epoch (training) 3:  59%|█████▉    | 179/301 [03:51<01:56,  1.04it/s]\n","Epoch (training) 3:  60%|█████▉    | 180/301 [03:52<01:54,  1.06it/s]\n","Epoch (training) 3:  60%|██████    | 181/301 [03:53<01:56,  1.03it/s]\n","Epoch (training) 3:  60%|██████    | 182/301 [03:54<01:53,  1.05it/s]\n","Epoch (training) 3:  61%|██████    | 183/301 [03:56<02:07,  1.08s/it]\n","Epoch (training) 3:  61%|██████    | 184/301 [03:57<02:05,  1.07s/it]\n","Epoch (training) 3:  61%|██████▏   | 185/301 [03:58<02:18,  1.19s/it]\n","Epoch (training) 3:  62%|██████▏   | 186/301 [03:59<02:13,  1.16s/it]\n","Epoch (training) 3:  62%|██████▏   | 187/301 [04:01<02:20,  1.23s/it]\n","Epoch (training) 3:  62%|██████▏   | 188/301 [04:02<02:21,  1.25s/it]\n","Epoch (training) 3:  63%|██████▎   | 189/301 [04:04<02:59,  1.60s/it]\n","Epoch (training) 3:  63%|██████▎   | 190/301 [04:05<02:35,  1.40s/it]\n","Epoch (training) 3:  63%|██████▎   | 191/301 [04:07<02:29,  1.36s/it]\n","Epoch (training) 3:  64%|██████▍   | 192/301 [04:08<02:24,  1.33s/it]\n","Epoch (training) 3:  64%|██████▍   | 193/301 [04:09<02:12,  1.23s/it]\n","Epoch (training) 3:  64%|██████▍   | 194/301 [04:10<02:04,  1.16s/it]\n","Epoch (training) 3:  65%|██████▍   | 195/301 [04:11<01:59,  1.13s/it]\n","Epoch (training) 3:  65%|██████▌   | 196/301 [04:13<02:35,  1.48s/it]\n","Epoch (training) 3:  65%|██████▌   | 197/301 [04:16<03:10,  1.83s/it]\n","Epoch (training) 3:  66%|██████▌   | 198/301 [04:17<02:50,  1.66s/it]\n","Epoch (training) 3:  66%|██████▌   | 199/301 [04:18<02:33,  1.51s/it]\n","Epoch (training) 3:  66%|██████▋   | 200/301 [04:19<02:10,  1.29s/it]\n","Epoch (training) 3:  67%|██████▋   | 201/301 [04:20<01:56,  1.16s/it]\n","Epoch (training) 3:  67%|██████▋   | 202/301 [04:22<02:14,  1.36s/it]\n","Epoch (training) 3:  67%|██████▋   | 203/301 [04:23<02:05,  1.28s/it]\n","Epoch (training) 3:  68%|██████▊   | 204/301 [04:24<01:58,  1.22s/it]\n","Epoch (training) 3:  68%|██████▊   | 205/301 [04:25<01:53,  1.19s/it]\n","Epoch (training) 3:  68%|██████▊   | 206/301 [04:26<01:43,  1.09s/it]\n","Epoch (training) 3:  69%|██████▉   | 207/301 [04:27<01:44,  1.11s/it]\n","Epoch (training) 3:  69%|██████▉   | 208/301 [04:28<01:50,  1.18s/it]\n","Epoch (training) 3:  69%|██████▉   | 209/301 [04:31<02:23,  1.56s/it]\n","Epoch (training) 3:  70%|██████▉   | 210/301 [04:32<02:07,  1.40s/it]\n","Epoch (training) 3:  70%|███████   | 211/301 [04:33<02:05,  1.39s/it]\n","Epoch (training) 3:  70%|███████   | 212/301 [04:34<01:46,  1.19s/it]\n","Epoch (training) 3:  71%|███████   | 213/301 [04:35<01:41,  1.15s/it]\n","Epoch (training) 3:  71%|███████   | 214/301 [04:37<01:56,  1.34s/it]\n","Epoch (training) 3:  71%|███████▏  | 215/301 [04:38<01:46,  1.23s/it]\n","Epoch (training) 3:  72%|███████▏  | 216/301 [04:39<01:33,  1.10s/it]\n","Epoch (training) 3:  72%|███████▏  | 217/301 [04:40<01:33,  1.11s/it]\n","Epoch (training) 3:  72%|███████▏  | 218/301 [04:41<01:45,  1.27s/it]\n","Epoch (training) 3:  73%|███████▎  | 219/301 [04:43<01:55,  1.41s/it]\n","Epoch (training) 3:  73%|███████▎  | 220/301 [04:45<02:08,  1.58s/it]\n","Epoch (training) 3:  73%|███████▎  | 221/301 [04:47<02:03,  1.54s/it]\n","Epoch (training) 3:  74%|███████▍  | 222/301 [04:48<01:50,  1.40s/it]\n","Epoch (training) 3:  74%|███████▍  | 223/301 [04:49<01:38,  1.26s/it]\n","Epoch (training) 3:  74%|███████▍  | 224/301 [04:50<01:30,  1.18s/it]\n","Epoch (training) 3:  75%|███████▍  | 225/301 [04:51<01:26,  1.14s/it]\n","Epoch (training) 3:  75%|███████▌  | 226/301 [04:51<01:19,  1.06s/it]\n","Epoch (training) 3:  75%|███████▌  | 227/301 [04:53<01:21,  1.10s/it]\n","Epoch (training) 3:  76%|███████▌  | 228/301 [04:54<01:20,  1.10s/it]\n","Epoch (training) 3:  76%|███████▌  | 229/301 [04:55<01:20,  1.11s/it]\n","Epoch (training) 3:  76%|███████▋  | 230/301 [04:56<01:21,  1.15s/it]\n","Epoch (training) 3:  77%|███████▋  | 231/301 [04:57<01:23,  1.19s/it]\n","Epoch (training) 3:  77%|███████▋  | 232/301 [04:59<01:23,  1.21s/it]\n","Epoch (training) 3:  77%|███████▋  | 233/301 [05:00<01:29,  1.32s/it]\n","Epoch (training) 3:  78%|███████▊  | 234/301 [05:01<01:22,  1.23s/it]\n","Epoch (training) 3:  78%|███████▊  | 235/301 [05:02<01:14,  1.13s/it]\n","Epoch (training) 3:  78%|███████▊  | 236/301 [05:04<01:19,  1.23s/it]\n","Epoch (training) 3:  79%|███████▊  | 237/301 [05:05<01:12,  1.14s/it]\n","Epoch (training) 3:  79%|███████▉  | 238/301 [05:05<01:06,  1.05s/it]\n","Epoch (training) 3:  79%|███████▉  | 239/301 [05:07<01:07,  1.09s/it]\n","Epoch (training) 3:  80%|███████▉  | 240/301 [05:07<01:01,  1.01s/it]\n","Epoch (training) 3:  80%|████████  | 241/301 [05:08<01:01,  1.02s/it]\n","Epoch (training) 3:  80%|████████  | 242/301 [05:10<01:03,  1.08s/it]\n","Epoch (training) 3:  81%|████████  | 243/301 [05:11<01:06,  1.14s/it]\n","Epoch (training) 3:  81%|████████  | 244/301 [05:13<01:15,  1.32s/it]\n","Epoch (training) 3:  81%|████████▏ | 245/301 [05:14<01:20,  1.44s/it]\n","Epoch (training) 3:  82%|████████▏ | 246/301 [05:15<01:13,  1.34s/it]\n","Epoch (training) 3:  82%|████████▏ | 247/301 [05:16<01:03,  1.18s/it]\n","Epoch (training) 3:  82%|████████▏ | 248/301 [05:18<01:08,  1.30s/it]\n","Epoch (training) 3:  83%|████████▎ | 249/301 [05:19<01:01,  1.19s/it]\n","Epoch (training) 3:  83%|████████▎ | 250/301 [05:20<00:59,  1.16s/it]\n","Epoch (training) 3:  83%|████████▎ | 251/301 [05:21<00:53,  1.08s/it]\n","Epoch (training) 3:  84%|████████▎ | 252/301 [05:23<01:05,  1.34s/it]\n","Epoch (training) 3:  84%|████████▍ | 253/301 [05:24<00:57,  1.19s/it]\n","Epoch (training) 3:  84%|████████▍ | 254/301 [05:25<00:53,  1.15s/it]\n","Epoch (training) 3:  85%|████████▍ | 255/301 [05:27<01:06,  1.44s/it]\n","Epoch (training) 3:  85%|████████▌ | 256/301 [05:29<01:17,  1.71s/it]\n","Epoch (training) 3:  85%|████████▌ | 257/301 [05:30<01:09,  1.58s/it]\n","Epoch (training) 3:  86%|████████▌ | 258/301 [05:32<01:05,  1.51s/it]\n","Epoch (training) 3:  86%|████████▌ | 259/301 [05:33<00:55,  1.33s/it]\n","Epoch (training) 3:  86%|████████▋ | 260/301 [05:35<01:02,  1.52s/it]\n","Epoch (training) 3:  87%|████████▋ | 261/301 [05:37<01:10,  1.76s/it]\n","Epoch (training) 3:  87%|████████▋ | 262/301 [05:38<01:00,  1.55s/it]\n","Epoch (training) 3:  87%|████████▋ | 263/301 [05:39<00:50,  1.34s/it]\n","Epoch (training) 3:  88%|████████▊ | 264/301 [05:40<00:44,  1.21s/it]\n","Epoch (training) 3:  88%|████████▊ | 265/301 [05:41<00:44,  1.22s/it]\n","Epoch (training) 3:  88%|████████▊ | 266/301 [05:43<00:46,  1.33s/it]\n","Epoch (training) 3:  89%|████████▊ | 267/301 [05:44<00:50,  1.50s/it]\n","Epoch (training) 3:  89%|████████▉ | 268/301 [05:46<00:46,  1.40s/it]\n","Epoch (training) 3:  89%|████████▉ | 269/301 [05:47<00:44,  1.38s/it]\n","Epoch (training) 3:  90%|████████▉ | 270/301 [05:48<00:36,  1.19s/it]\n","Epoch (training) 3:  90%|█████████ | 271/301 [05:48<00:30,  1.03s/it]\n","Epoch (training) 3:  90%|█████████ | 272/301 [05:50<00:31,  1.09s/it]\n","Epoch (training) 3:  91%|█████████ | 273/301 [05:51<00:35,  1.29s/it]\n","Epoch (training) 3:  91%|█████████ | 274/301 [05:52<00:32,  1.20s/it]\n","Epoch (training) 3:  91%|█████████▏| 275/301 [05:54<00:33,  1.27s/it]\n","Epoch (training) 3:  92%|█████████▏| 276/301 [05:55<00:32,  1.30s/it]\n","Epoch (training) 3:  92%|█████████▏| 277/301 [05:56<00:30,  1.26s/it]\n","Epoch (training) 3:  92%|█████████▏| 278/301 [05:57<00:27,  1.21s/it]\n","Epoch (training) 3:  93%|█████████▎| 279/301 [05:59<00:28,  1.28s/it]\n","Epoch (training) 3:  93%|█████████▎| 280/301 [06:01<00:30,  1.47s/it]\n","Epoch (training) 3:  93%|█████████▎| 281/301 [06:02<00:25,  1.25s/it]\n","Epoch (training) 3:  94%|█████████▎| 282/301 [06:03<00:24,  1.27s/it]\n","Epoch (training) 3:  94%|█████████▍| 283/301 [06:04<00:22,  1.23s/it]\n","Epoch (training) 3:  94%|█████████▍| 284/301 [06:06<00:23,  1.39s/it]\n","Epoch (training) 3:  95%|█████████▍| 285/301 [06:08<00:24,  1.52s/it]\n","Epoch (training) 3:  95%|█████████▌| 286/301 [06:09<00:20,  1.38s/it]\n","Epoch (training) 3:  95%|█████████▌| 287/301 [06:10<00:21,  1.51s/it]\n","Epoch (training) 3:  96%|█████████▌| 288/301 [06:12<00:19,  1.52s/it]\n","Epoch (training) 3:  96%|█████████▌| 289/301 [06:13<00:17,  1.46s/it]\n","Epoch (training) 3:  96%|█████████▋| 290/301 [06:14<00:14,  1.32s/it]\n","Epoch (training) 3:  97%|█████████▋| 291/301 [06:15<00:12,  1.26s/it]\n","Epoch (training) 3:  97%|█████████▋| 292/301 [06:16<00:10,  1.13s/it]\n","Epoch (training) 3:  97%|█████████▋| 293/301 [06:17<00:08,  1.06s/it]\n","Epoch (training) 3:  98%|█████████▊| 294/301 [06:18<00:07,  1.10s/it]\n","Epoch (training) 3:  98%|█████████▊| 295/301 [06:19<00:06,  1.05s/it]\n","Epoch (training) 3:  98%|█████████▊| 296/301 [06:20<00:04,  1.04it/s]\n","Epoch (training) 3:  99%|█████████▊| 297/301 [06:22<00:04,  1.17s/it]\n","Epoch (training) 3:  99%|█████████▉| 298/301 [06:23<00:03,  1.23s/it]\n","Epoch (training) 3:  99%|█████████▉| 299/301 [06:24<00:02,  1.13s/it]\n","Epoch (training) 3: 100%|█████████▉| 300/301 [06:24<00:00,  1.10it/s]\n","Epoch (training) 3: 100%|██████████| 301/301 [06:24<00:00,  1.28s/it]\n","Epoch (test) 3:   0%|          | 0/76 [00:00<?, ?it/s]\n","Epoch (test) 3:   1%|▏         | 1/76 [00:02<02:43,  2.19s/it]\n","Epoch (test) 3:   3%|▎         | 2/76 [00:03<02:05,  1.69s/it]\n","Epoch (test) 3:   4%|▍         | 3/76 [00:04<01:40,  1.38s/it]\n","Epoch (test) 3:   5%|▌         | 4/76 [00:05<01:23,  1.16s/it]\n","Epoch (test) 3:   7%|▋         | 5/76 [00:06<01:18,  1.10s/it]\n","Epoch (test) 3:   8%|▊         | 6/76 [00:06<01:05,  1.07it/s]\n","Epoch (test) 3:   9%|▉         | 7/76 [00:08<01:06,  1.04it/s]\n","Epoch (test) 3:  11%|█         | 8/76 [00:08<00:59,  1.15it/s]\n","Epoch (test) 3:  12%|█▏        | 9/76 [00:09<00:58,  1.14it/s]\n","Epoch (test) 3:  13%|█▎        | 10/76 [00:10<00:58,  1.13it/s]\n","Epoch (test) 3:  14%|█▍        | 11/76 [00:11<00:51,  1.26it/s]\n","Epoch (test) 3:  16%|█▌        | 12/76 [00:11<00:51,  1.25it/s]\n","Epoch (test) 3:  17%|█▋        | 13/76 [00:12<00:53,  1.18it/s]\n","Epoch (test) 3:  18%|█▊        | 14/76 [00:13<00:51,  1.20it/s]\n","Epoch (test) 3:  20%|█▉        | 15/76 [00:14<00:48,  1.26it/s]\n","Epoch (test) 3:  21%|██        | 16/76 [00:15<00:50,  1.19it/s]\n","Epoch (test) 3:  22%|██▏       | 17/76 [00:15<00:45,  1.29it/s]\n","Epoch (test) 3:  24%|██▎       | 18/76 [00:17<00:54,  1.06it/s]\n","Epoch (test) 3:  25%|██▌       | 19/76 [00:17<00:50,  1.13it/s]\n","Epoch (test) 3:  26%|██▋       | 20/76 [00:18<00:48,  1.14it/s]\n","Epoch (test) 3:  28%|██▊       | 21/76 [00:19<00:48,  1.14it/s]\n","Epoch (test) 3:  29%|██▉       | 22/76 [00:20<00:47,  1.14it/s]\n","Epoch (test) 3:  30%|███       | 23/76 [00:21<00:45,  1.16it/s]\n","Epoch (test) 3:  32%|███▏      | 24/76 [00:22<00:42,  1.21it/s]\n","Epoch (test) 3:  33%|███▎      | 25/76 [00:23<00:49,  1.04it/s]\n","Epoch (test) 3:  34%|███▍      | 26/76 [00:24<00:53,  1.08s/it]\n","Epoch (test) 3:  36%|███▌      | 27/76 [00:25<00:48,  1.02it/s]\n","Epoch (test) 3:  37%|███▋      | 28/76 [00:26<00:49,  1.02s/it]\n","Epoch (test) 3:  38%|███▊      | 29/76 [00:27<00:48,  1.04s/it]\n","Epoch (test) 3:  39%|███▉      | 30/76 [00:28<00:44,  1.03it/s]\n","Epoch (test) 3:  41%|████      | 31/76 [00:29<00:45,  1.02s/it]\n","Epoch (test) 3:  42%|████▏     | 32/76 [00:31<00:55,  1.26s/it]\n","Epoch (test) 3:  43%|████▎     | 33/76 [00:32<00:48,  1.14s/it]\n","Epoch (test) 3:  45%|████▍     | 34/76 [00:33<00:43,  1.03s/it]\n","Epoch (test) 3:  46%|████▌     | 35/76 [00:34<00:40,  1.02it/s]\n","Epoch (test) 3:  47%|████▋     | 36/76 [00:34<00:33,  1.20it/s]\n","Epoch (test) 3:  49%|████▊     | 37/76 [00:35<00:30,  1.29it/s]\n","Epoch (test) 3:  50%|█████     | 38/76 [00:35<00:27,  1.40it/s]\n","Epoch (test) 3:  51%|█████▏    | 39/76 [00:36<00:30,  1.21it/s]\n","Epoch (test) 3:  53%|█████▎    | 40/76 [00:37<00:28,  1.27it/s]\n","Epoch (test) 3:  54%|█████▍    | 41/76 [00:38<00:24,  1.41it/s]\n","Epoch (test) 3:  55%|█████▌    | 42/76 [00:38<00:26,  1.28it/s]\n","Epoch (test) 3:  57%|█████▋    | 43/76 [00:40<00:28,  1.14it/s]\n","Epoch (test) 3:  58%|█████▊    | 44/76 [00:41<00:28,  1.12it/s]\n","Epoch (test) 3:  59%|█████▉    | 45/76 [00:41<00:26,  1.16it/s]\n","Epoch (test) 3:  61%|██████    | 46/76 [00:44<00:40,  1.36s/it]\n","Epoch (test) 3:  62%|██████▏   | 47/76 [00:46<00:42,  1.47s/it]\n","Epoch (test) 3:  63%|██████▎   | 48/76 [00:47<00:41,  1.48s/it]\n","Epoch (test) 3:  64%|██████▍   | 49/76 [00:48<00:39,  1.45s/it]\n","Epoch (test) 3:  66%|██████▌   | 50/76 [00:50<00:42,  1.63s/it]\n","Epoch (test) 3:  67%|██████▋   | 51/76 [00:52<00:38,  1.52s/it]\n","Epoch (test) 3:  68%|██████▊   | 52/76 [00:53<00:37,  1.57s/it]\n","Epoch (test) 3:  70%|██████▉   | 53/76 [00:55<00:35,  1.55s/it]\n","Epoch (test) 3:  71%|███████   | 54/76 [00:58<00:44,  2.04s/it]\n","Epoch (test) 3:  72%|███████▏  | 55/76 [01:01<00:48,  2.31s/it]\n","Epoch (test) 3:  74%|███████▎  | 56/76 [01:03<00:43,  2.20s/it]\n","Epoch (test) 3:  75%|███████▌  | 57/76 [01:05<00:39,  2.09s/it]\n","Epoch (test) 3:  76%|███████▋  | 58/76 [01:06<00:32,  1.83s/it]\n","Epoch (test) 3:  78%|███████▊  | 59/76 [01:07<00:26,  1.58s/it]\n","Epoch (test) 3:  79%|███████▉  | 60/76 [01:08<00:24,  1.54s/it]\n","Epoch (test) 3:  80%|████████  | 61/76 [01:10<00:22,  1.49s/it]\n","Epoch (test) 3:  82%|████████▏ | 62/76 [01:11<00:19,  1.40s/it]\n","Epoch (test) 3:  83%|████████▎ | 63/76 [01:13<00:20,  1.54s/it]\n","Epoch (test) 3:  84%|████████▍ | 64/76 [01:17<00:25,  2.16s/it]\n","Epoch (test) 3:  86%|████████▌ | 65/76 [01:18<00:21,  1.93s/it]\n","Epoch (test) 3:  87%|████████▋ | 66/76 [01:19<00:16,  1.65s/it]\n","Epoch (test) 3:  88%|████████▊ | 67/76 [01:20<00:13,  1.50s/it]\n","Epoch (test) 3:  89%|████████▉ | 68/76 [01:21<00:11,  1.38s/it]\n","Epoch (test) 3:  91%|█████████ | 69/76 [01:23<00:10,  1.52s/it]\n","Epoch (test) 3:  92%|█████████▏| 70/76 [01:26<00:10,  1.83s/it]\n","Epoch (test) 3:  93%|█████████▎| 71/76 [01:28<00:10,  2.12s/it]\n","Epoch (test) 3:  95%|█████████▍| 72/76 [01:30<00:08,  2.07s/it]\n","Epoch (test) 3:  96%|█████████▌| 73/76 [01:32<00:06,  2.01s/it]\n","Epoch (test) 3:  97%|█████████▋| 74/76 [01:36<00:05,  2.51s/it]\n","Epoch (test) 3: 100%|██████████| 76/76 [01:36<00:00,  1.27s/it]\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_cv_outer_4/TorchTrainer_b33ac_00000_0_2024-04-14_19-32-16/checkpoint_000002)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training finished iteration 3 at 2024-04-14 21:25:11. Total running time: 1hr 52min 55s\n","+---------------------------------------------+\n","| Training result                             |\n","+---------------------------------------------+\n","| checkpoint_dir_name       checkpoint_000002 |\n","| time_this_iter_s                  485.59284 |\n","| time_total_s                     6765.74428 |\n","| training_iteration                        3 |\n","| accuracy                            0.44833 |\n","| confusion_matrix       ... 7, 9, 7, 7, 10]) |\n","| f1                                  0.44585 |\n","| loss                                 1.5903 |\n","| precision                           0.47974 |\n","| recall                              0.44833 |\n","| summary/epoch/0                         1.0 |\n","| summary/epoch/1                         2.0 |\n","| summary/epoch/2                         3.0 |\n","| summary/train_acc/0     0.28052083333333333 |\n","| summary/train_acc/1     0.40020833333333333 |\n","| summary/train_acc/2      0.4580208333333333 |\n","| summary/train_loss/0     2.0832002725316046 |\n","| summary/train_loss/1      1.756782130545556 |\n","| summary/train_loss/2     1.5777994148754995 |\n","| summary/val_acc/0       0.37833333333333335 |\n","| summary/val_acc/1       0.40291666666666665 |\n","| summary/val_acc/2        0.4483333333333333 |\n","| summary/val_loss/0       1.8843663452487243 |\n","| summary/val_loss/1        1.757122580158083 |\n","| summary/val_loss/2       1.5903012258441824 |\n","+---------------------------------------------+\n","Training saved a checkpoint for iteration 3 at: (local)/root/ray_results/wide_resnet50_cv_outer_4/TorchTrainer_b33ac_00000_0_2024-04-14_19-32-16/checkpoint_000002\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 4:   0%|          | 0/301 [00:00<?, ?it/s]\n","Epoch (training) 4:   0%|          | 1/301 [00:05<28:50,  5.77s/it]\n","Epoch (training) 4:   1%|          | 2/301 [00:08<18:32,  3.72s/it]\n","Epoch (training) 4:   1%|          | 3/301 [00:09<12:12,  2.46s/it]\n","Epoch (training) 4:   1%|▏         | 4/301 [00:09<09:08,  1.85s/it]\n","Epoch (training) 4:   2%|▏         | 5/301 [00:11<08:13,  1.67s/it]\n","Epoch (training) 4:   2%|▏         | 6/301 [00:11<06:33,  1.34s/it]\n","Epoch (training) 4:   2%|▏         | 7/301 [00:13<07:32,  1.54s/it]\n","Epoch (training) 4:   3%|▎         | 8/301 [00:15<07:08,  1.46s/it]\n","Epoch (training) 4:   3%|▎         | 9/301 [00:16<06:12,  1.28s/it]\n","Epoch (training) 4:   3%|▎         | 10/301 [00:17<06:24,  1.32s/it]\n","Epoch (training) 4:   4%|▎         | 11/301 [00:19<07:10,  1.48s/it]\n","Epoch (training) 4:   4%|▍         | 12/301 [00:20<06:25,  1.33s/it]\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m /usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m   warnings.warn(\n","Epoch (training) 4:   4%|▍         | 13/301 [00:21<05:39,  1.18s/it]\n","Epoch (training) 4:   5%|▍         | 14/301 [00:22<05:10,  1.08s/it]\n","Epoch (training) 4:   5%|▍         | 15/301 [00:24<06:55,  1.45s/it]\n","Epoch (training) 4:   5%|▌         | 16/301 [00:25<07:06,  1.50s/it]\n","Epoch (training) 4:   6%|▌         | 17/301 [00:26<05:59,  1.27s/it]\n","Epoch (training) 4:   6%|▌         | 18/301 [00:27<05:23,  1.14s/it]\n","Epoch (training) 4:   6%|▋         | 19/301 [00:28<05:47,  1.23s/it]\n","Epoch (training) 4:   7%|▋         | 20/301 [00:30<05:35,  1.19s/it]\n","Epoch (training) 4:   7%|▋         | 21/301 [00:32<07:42,  1.65s/it]\n","Epoch (training) 4:   7%|▋         | 22/301 [00:34<07:33,  1.62s/it]\n","Epoch (training) 4:   8%|▊         | 23/301 [00:35<07:29,  1.62s/it]\n","Epoch (training) 4:   8%|▊         | 24/301 [00:36<06:27,  1.40s/it]\n","Epoch (training) 4:   8%|▊         | 25/301 [00:38<07:02,  1.53s/it]\n","Epoch (training) 4:   9%|▊         | 26/301 [00:39<06:05,  1.33s/it]\n","Epoch (training) 4:   9%|▉         | 27/301 [00:40<05:14,  1.15s/it]\n","Epoch (training) 4:   9%|▉         | 28/301 [00:41<05:21,  1.18s/it]\n","Epoch (training) 4:  10%|▉         | 29/301 [00:42<05:10,  1.14s/it]\n","Epoch (training) 4:  10%|▉         | 30/301 [00:43<04:34,  1.01s/it]\n","Epoch (training) 4:  10%|█         | 31/301 [00:44<04:55,  1.09s/it]\n","Epoch (training) 4:  11%|█         | 32/301 [00:45<04:35,  1.02s/it]\n","Epoch (training) 4:  11%|█         | 33/301 [00:46<04:59,  1.12s/it]\n","Epoch (training) 4:  11%|█▏        | 34/301 [00:48<05:19,  1.20s/it]\n","Epoch (training) 4:  12%|█▏        | 35/301 [00:49<05:43,  1.29s/it]\n","Epoch (training) 4:  12%|█▏        | 36/301 [00:50<05:08,  1.16s/it]\n","Epoch (training) 4:  12%|█▏        | 37/301 [00:52<05:50,  1.33s/it]\n","Epoch (training) 4:  13%|█▎        | 38/301 [00:54<06:43,  1.53s/it]\n","Epoch (training) 4:  13%|█▎        | 39/301 [00:55<05:54,  1.35s/it]\n","Epoch (training) 4:  13%|█▎        | 40/301 [00:56<05:26,  1.25s/it]\n","Epoch (training) 4:  14%|█▎        | 41/301 [00:57<05:17,  1.22s/it]\n","Epoch (training) 4:  14%|█▍        | 42/301 [00:58<05:11,  1.20s/it]\n","Epoch (training) 4:  14%|█▍        | 43/301 [00:59<04:49,  1.12s/it]\n","Epoch (training) 4:  15%|█▍        | 44/301 [01:00<04:52,  1.14s/it]\n","Epoch (training) 4:  15%|█▍        | 45/301 [01:02<06:05,  1.43s/it]\n","Epoch (training) 4:  15%|█▌        | 46/301 [01:03<05:38,  1.33s/it]\n","Epoch (training) 4:  16%|█▌        | 47/301 [01:05<06:03,  1.43s/it]\n","Epoch (training) 4:  16%|█▌        | 48/301 [01:06<05:35,  1.33s/it]\n","Epoch (training) 4:  16%|█▋        | 49/301 [01:07<05:06,  1.22s/it]\n","Epoch (training) 4:  17%|█▋        | 50/301 [01:08<04:26,  1.06s/it]\n","Epoch (training) 4:  17%|█▋        | 51/301 [01:09<04:42,  1.13s/it]\n","Epoch (training) 4:  17%|█▋        | 52/301 [01:11<05:13,  1.26s/it]\n","Epoch (training) 4:  18%|█▊        | 53/301 [01:11<04:46,  1.15s/it]\n","Epoch (training) 4:  18%|█▊        | 54/301 [01:13<05:01,  1.22s/it]\n","Epoch (training) 4:  18%|█▊        | 55/301 [01:14<04:47,  1.17s/it]\n","Epoch (training) 4:  19%|█▊        | 56/301 [01:15<04:55,  1.21s/it]\n","Epoch (training) 4:  19%|█▉        | 57/301 [01:17<05:11,  1.28s/it]\n","Epoch (training) 4:  19%|█▉        | 58/301 [01:18<05:08,  1.27s/it]\n","Epoch (training) 4:  20%|█▉        | 59/301 [01:19<05:23,  1.34s/it]\n","Epoch (training) 4:  20%|█▉        | 60/301 [01:21<05:23,  1.34s/it]\n","Epoch (training) 4:  20%|██        | 61/301 [01:22<05:21,  1.34s/it]\n","Epoch (training) 4:  21%|██        | 62/301 [01:24<05:30,  1.38s/it]\n","Epoch (training) 4:  21%|██        | 63/301 [01:26<06:19,  1.60s/it]\n","Epoch (training) 4:  21%|██▏       | 64/301 [01:27<06:06,  1.55s/it]\n","Epoch (training) 4:  22%|██▏       | 65/301 [01:28<05:21,  1.36s/it]\n","Epoch (training) 4:  22%|██▏       | 66/301 [01:29<05:10,  1.32s/it]\n","Epoch (training) 4:  22%|██▏       | 67/301 [01:30<04:51,  1.25s/it]\n","Epoch (training) 4:  23%|██▎       | 68/301 [01:32<05:17,  1.36s/it]\n","Epoch (training) 4:  23%|██▎       | 69/301 [01:33<04:58,  1.29s/it]\n","Epoch (training) 4:  23%|██▎       | 70/301 [01:34<04:40,  1.21s/it]\n","Epoch (training) 4:  24%|██▎       | 71/301 [01:35<03:58,  1.04s/it]\n","Epoch (training) 4:  24%|██▍       | 72/301 [01:37<05:01,  1.32s/it]\n","Epoch (training) 4:  24%|██▍       | 73/301 [01:39<05:34,  1.47s/it]\n","Epoch (training) 4:  25%|██▍       | 74/301 [01:40<05:22,  1.42s/it]\n","Epoch (training) 4:  25%|██▍       | 75/301 [01:41<05:19,  1.41s/it]\n","Epoch (training) 4:  25%|██▌       | 76/301 [01:42<04:55,  1.31s/it]\n","Epoch (training) 4:  26%|██▌       | 77/301 [01:45<05:54,  1.58s/it]\n","Epoch (training) 4:  26%|██▌       | 78/301 [01:46<05:49,  1.57s/it]\n","Epoch (training) 4:  26%|██▌       | 79/301 [01:47<05:24,  1.46s/it]\n","Epoch (training) 4:  27%|██▋       | 80/301 [01:49<05:16,  1.43s/it]\n","Epoch (training) 4:  27%|██▋       | 81/301 [01:50<04:57,  1.35s/it]\n","Epoch (training) 4:  27%|██▋       | 82/301 [01:51<04:23,  1.20s/it]\n","Epoch (training) 4:  28%|██▊       | 83/301 [01:52<04:17,  1.18s/it]\n","Epoch (training) 4:  28%|██▊       | 84/301 [01:53<03:53,  1.07s/it]\n","Epoch (training) 4:  28%|██▊       | 85/301 [01:54<04:05,  1.14s/it]\n","Epoch (training) 4:  29%|██▊       | 86/301 [01:55<04:25,  1.23s/it]\n","Epoch (training) 4:  29%|██▉       | 87/301 [01:56<04:03,  1.14s/it]\n","Epoch (training) 4:  29%|██▉       | 88/301 [01:57<03:51,  1.09s/it]\n","Epoch (training) 4:  30%|██▉       | 89/301 [01:59<04:17,  1.21s/it]\n","Epoch (training) 4:  30%|██▉       | 90/301 [02:00<04:28,  1.27s/it]\n","Epoch (training) 4:  30%|███       | 91/301 [02:01<04:10,  1.19s/it]\n","Epoch (training) 4:  31%|███       | 92/301 [02:02<04:11,  1.20s/it]\n","Epoch (training) 4:  31%|███       | 93/301 [02:04<04:31,  1.30s/it]\n","Epoch (training) 4:  31%|███       | 94/301 [02:05<04:08,  1.20s/it]\n","Epoch (training) 4:  32%|███▏      | 95/301 [02:06<03:33,  1.04s/it]\n","Epoch (training) 4:  32%|███▏      | 96/301 [02:07<04:11,  1.23s/it]\n","Epoch (training) 4:  32%|███▏      | 97/301 [02:08<04:08,  1.22s/it]\n","Epoch (training) 4:  33%|███▎      | 98/301 [02:10<04:08,  1.22s/it]\n","Epoch (training) 4:  33%|███▎      | 99/301 [02:12<05:20,  1.59s/it]\n","Epoch (training) 4:  33%|███▎      | 100/301 [02:14<06:02,  1.80s/it]\n","Epoch (training) 4:  34%|███▎      | 101/301 [02:15<04:57,  1.49s/it]\n","Epoch (training) 4:  34%|███▍      | 102/301 [02:17<04:58,  1.50s/it]\n","Epoch (training) 4:  34%|███▍      | 103/301 [02:19<05:20,  1.62s/it]\n","Epoch (training) 4:  35%|███▍      | 104/301 [02:20<04:38,  1.41s/it]\n","Epoch (training) 4:  35%|███▍      | 105/301 [02:21<04:23,  1.34s/it]\n","Epoch (training) 4:  35%|███▌      | 106/301 [02:22<04:04,  1.26s/it]\n","Epoch (training) 4:  36%|███▌      | 107/301 [02:23<03:46,  1.17s/it]\n","Epoch (training) 4:  36%|███▌      | 108/301 [02:24<03:45,  1.17s/it]\n","Epoch (training) 4:  36%|███▌      | 109/301 [02:25<04:00,  1.25s/it]\n","Epoch (training) 4:  37%|███▋      | 110/301 [02:26<03:41,  1.16s/it]\n","Epoch (training) 4:  37%|███▋      | 111/301 [02:28<04:02,  1.28s/it]\n","Epoch (training) 4:  37%|███▋      | 112/301 [02:30<04:25,  1.40s/it]\n","Epoch (training) 4:  38%|███▊      | 113/301 [02:31<04:30,  1.44s/it]\n","Epoch (training) 4:  38%|███▊      | 114/301 [02:32<04:18,  1.38s/it]\n","Epoch (training) 4:  38%|███▊      | 115/301 [02:34<04:08,  1.34s/it]\n","Epoch (training) 4:  39%|███▊      | 116/301 [02:35<03:51,  1.25s/it]\n","Epoch (training) 4:  39%|███▉      | 117/301 [02:35<03:27,  1.13s/it]\n","Epoch (training) 4:  39%|███▉      | 118/301 [02:36<03:02,  1.00it/s]\n","Epoch (training) 4:  40%|███▉      | 119/301 [02:37<03:01,  1.00it/s]\n","Epoch (training) 4:  40%|███▉      | 120/301 [02:38<02:50,  1.06it/s]\n","Epoch (training) 4:  40%|████      | 121/301 [02:39<02:42,  1.11it/s]\n","Epoch (training) 4:  41%|████      | 122/301 [02:40<02:51,  1.05it/s]\n","Epoch (training) 4:  41%|████      | 123/301 [02:41<02:54,  1.02it/s]\n","Epoch (training) 4:  41%|████      | 124/301 [02:42<02:56,  1.00it/s]\n","Epoch (training) 4:  42%|████▏     | 125/301 [02:43<03:07,  1.07s/it]\n","Epoch (training) 4:  42%|████▏     | 126/301 [02:45<03:58,  1.36s/it]\n","Epoch (training) 4:  42%|████▏     | 127/301 [02:47<04:10,  1.44s/it]\n","Epoch (training) 4:  43%|████▎     | 128/301 [02:48<03:49,  1.32s/it]\n","Epoch (training) 4:  43%|████▎     | 129/301 [02:49<03:24,  1.19s/it]\n","Epoch (training) 4:  43%|████▎     | 130/301 [02:50<03:21,  1.18s/it]\n","Epoch (training) 4:  44%|████▎     | 131/301 [02:51<03:01,  1.07s/it]\n","Epoch (training) 4:  44%|████▍     | 132/301 [02:52<02:54,  1.03s/it]\n","Epoch (training) 4:  44%|████▍     | 133/301 [02:53<03:18,  1.18s/it]\n","Epoch (training) 4:  45%|████▍     | 134/301 [02:54<03:04,  1.10s/it]\n","Epoch (training) 4:  45%|████▍     | 135/301 [02:55<02:47,  1.01s/it]\n","Epoch (training) 4:  45%|████▌     | 136/301 [02:56<02:50,  1.03s/it]\n","Epoch (training) 4:  46%|████▌     | 137/301 [02:57<02:53,  1.06s/it]\n","Epoch (training) 4:  46%|████▌     | 138/301 [02:58<03:07,  1.15s/it]\n","Epoch (training) 4:  46%|████▌     | 139/301 [03:00<03:31,  1.31s/it]\n","Epoch (training) 4:  47%|████▋     | 140/301 [03:01<03:15,  1.21s/it]\n","Epoch (training) 4:  47%|████▋     | 141/301 [03:02<03:10,  1.19s/it]\n","Epoch (training) 4:  47%|████▋     | 142/301 [03:03<03:09,  1.19s/it]\n","Epoch (training) 4:  48%|████▊     | 143/301 [03:05<03:03,  1.16s/it]\n","Epoch (training) 4:  48%|████▊     | 144/301 [03:05<02:38,  1.01s/it]\n","Epoch (training) 4:  48%|████▊     | 145/301 [03:06<02:27,  1.06it/s]\n","Epoch (training) 4:  49%|████▊     | 146/301 [03:07<02:22,  1.09it/s]\n","Epoch (training) 4:  49%|████▉     | 147/301 [03:08<02:38,  1.03s/it]\n","Epoch (training) 4:  49%|████▉     | 148/301 [03:10<02:55,  1.14s/it]\n","Epoch (training) 4:  50%|████▉     | 149/301 [03:10<02:43,  1.07s/it]\n","Epoch (training) 4:  50%|████▉     | 150/301 [03:11<02:28,  1.02it/s]\n","Epoch (training) 4:  50%|█████     | 151/301 [03:13<02:42,  1.09s/it]\n","Epoch (training) 4:  50%|█████     | 152/301 [03:14<02:48,  1.13s/it]\n","Epoch (training) 4:  51%|█████     | 153/301 [03:16<03:25,  1.39s/it]\n","Epoch (training) 4:  51%|█████     | 154/301 [03:17<03:04,  1.26s/it]\n","Epoch (training) 4:  51%|█████▏    | 155/301 [03:18<02:51,  1.17s/it]\n","Epoch (training) 4:  52%|█████▏    | 156/301 [03:19<02:38,  1.09s/it]\n","Epoch (training) 4:  52%|█████▏    | 157/301 [03:20<02:37,  1.09s/it]\n","Epoch (training) 4:  52%|█████▏    | 158/301 [03:21<02:45,  1.16s/it]\n","Epoch (training) 4:  53%|█████▎    | 159/301 [03:23<03:16,  1.38s/it]\n","Epoch (training) 4:  53%|█████▎    | 160/301 [03:24<02:55,  1.24s/it]\n","Epoch (training) 4:  53%|█████▎    | 161/301 [03:25<03:11,  1.37s/it]\n","Epoch (training) 4:  54%|█████▍    | 162/301 [03:27<03:00,  1.30s/it]\n","Epoch (training) 4:  54%|█████▍    | 163/301 [03:28<02:57,  1.29s/it]\n","Epoch (training) 4:  54%|█████▍    | 164/301 [03:29<02:46,  1.21s/it]\n","Epoch (training) 4:  55%|█████▍    | 165/301 [03:31<03:03,  1.35s/it]\n","Epoch (training) 4:  55%|█████▌    | 166/301 [03:32<03:01,  1.34s/it]\n","Epoch (training) 4:  55%|█████▌    | 167/301 [03:34<03:11,  1.43s/it]\n","Epoch (training) 4:  56%|█████▌    | 168/301 [03:35<03:23,  1.53s/it]\n","Epoch (training) 4:  56%|█████▌    | 169/301 [03:36<02:51,  1.30s/it]\n","Epoch (training) 4:  56%|█████▋    | 170/301 [03:37<02:33,  1.17s/it]\n","Epoch (training) 4:  57%|█████▋    | 171/301 [03:39<02:55,  1.35s/it]\n","Epoch (training) 4:  57%|█████▋    | 172/301 [03:40<02:34,  1.20s/it]\n","Epoch (training) 4:  57%|█████▋    | 173/301 [03:41<02:26,  1.15s/it]\n","Epoch (training) 4:  58%|█████▊    | 174/301 [03:43<03:04,  1.45s/it]\n","Epoch (training) 4:  58%|█████▊    | 175/301 [03:44<03:09,  1.50s/it]\n","Epoch (training) 4:  58%|█████▊    | 176/301 [03:45<02:54,  1.40s/it]\n","Epoch (training) 4:  59%|█████▉    | 177/301 [03:47<02:49,  1.37s/it]\n","Epoch (training) 4:  59%|█████▉    | 178/301 [03:48<02:42,  1.32s/it]\n","Epoch (training) 4:  59%|█████▉    | 179/301 [03:49<02:39,  1.31s/it]\n","Epoch (training) 4:  60%|█████▉    | 180/301 [03:50<02:34,  1.27s/it]\n","Epoch (training) 4:  60%|██████    | 181/301 [03:51<02:16,  1.14s/it]\n","Epoch (training) 4:  60%|██████    | 182/301 [03:52<02:03,  1.03s/it]\n","Epoch (training) 4:  61%|██████    | 183/301 [03:53<02:08,  1.09s/it]\n","Epoch (training) 4:  61%|██████    | 184/301 [03:54<01:58,  1.02s/it]\n","Epoch (training) 4:  61%|██████▏   | 185/301 [03:56<02:24,  1.25s/it]\n","Epoch (training) 4:  62%|██████▏   | 186/301 [03:58<02:57,  1.54s/it]\n","Epoch (training) 4:  62%|██████▏   | 187/301 [04:00<02:53,  1.52s/it]\n","Epoch (training) 4:  62%|██████▏   | 188/301 [04:01<02:49,  1.50s/it]\n","Epoch (training) 4:  63%|██████▎   | 189/301 [04:02<02:39,  1.42s/it]\n","Epoch (training) 4:  63%|██████▎   | 190/301 [04:04<02:36,  1.41s/it]\n","Epoch (training) 4:  63%|██████▎   | 191/301 [04:05<02:25,  1.32s/it]\n","Epoch (training) 4:  64%|██████▍   | 192/301 [04:06<02:21,  1.30s/it]\n","Epoch (training) 4:  64%|██████▍   | 193/301 [04:07<02:21,  1.31s/it]\n","Epoch (training) 4:  64%|██████▍   | 194/301 [04:08<02:01,  1.13s/it]\n","Epoch (training) 4:  65%|██████▍   | 195/301 [04:09<01:59,  1.13s/it]\n","Epoch (training) 4:  65%|██████▌   | 196/301 [04:10<01:52,  1.07s/it]\n","Epoch (training) 4:  65%|██████▌   | 197/301 [04:12<02:02,  1.18s/it]\n","Epoch (training) 4:  66%|██████▌   | 198/301 [04:13<02:07,  1.24s/it]\n","Epoch (training) 4:  66%|██████▌   | 199/301 [04:15<02:20,  1.38s/it]\n","Epoch (training) 4:  66%|██████▋   | 200/301 [04:17<02:59,  1.77s/it]\n","Epoch (training) 4:  67%|██████▋   | 201/301 [04:18<02:26,  1.47s/it]\n","Epoch (training) 4:  67%|██████▋   | 202/301 [04:19<02:11,  1.33s/it]\n","Epoch (training) 4:  67%|██████▋   | 203/301 [04:21<02:28,  1.52s/it]\n","Epoch (training) 4:  68%|██████▊   | 204/301 [04:23<02:31,  1.57s/it]\n","Epoch (training) 4:  68%|██████▊   | 205/301 [04:25<02:38,  1.65s/it]\n","Epoch (training) 4:  68%|██████▊   | 206/301 [04:26<02:23,  1.51s/it]\n","Epoch (training) 4:  69%|██████▉   | 207/301 [04:27<02:24,  1.54s/it]\n","Epoch (training) 4:  69%|██████▉   | 208/301 [04:29<02:30,  1.62s/it]\n","Epoch (training) 4:  69%|██████▉   | 209/301 [04:31<02:42,  1.76s/it]\n","Epoch (training) 4:  70%|██████▉   | 210/301 [04:32<02:19,  1.54s/it]\n","Epoch (training) 4:  70%|███████   | 211/301 [04:34<02:23,  1.59s/it]\n","Epoch (training) 4:  70%|███████   | 212/301 [04:35<02:06,  1.42s/it]\n","Epoch (training) 4:  71%|███████   | 213/301 [04:36<01:50,  1.25s/it]\n","Epoch (training) 4:  71%|███████   | 214/301 [04:37<01:35,  1.10s/it]\n","Epoch (training) 4:  71%|███████▏  | 215/301 [04:37<01:25,  1.00it/s]\n","Epoch (training) 4:  72%|███████▏  | 216/301 [04:39<01:44,  1.23s/it]\n","Epoch (training) 4:  72%|███████▏  | 217/301 [04:40<01:44,  1.25s/it]\n","Epoch (training) 4:  72%|███████▏  | 218/301 [04:42<01:48,  1.31s/it]\n","Epoch (training) 4:  73%|███████▎  | 219/301 [04:43<01:45,  1.29s/it]\n","Epoch (training) 4:  73%|███████▎  | 220/301 [04:45<01:50,  1.36s/it]\n","Epoch (training) 4:  73%|███████▎  | 221/301 [04:46<01:37,  1.22s/it]\n","Epoch (training) 4:  74%|███████▍  | 222/301 [04:47<01:34,  1.20s/it]\n","Epoch (training) 4:  74%|███████▍  | 223/301 [04:48<01:25,  1.09s/it]\n","Epoch (training) 4:  74%|███████▍  | 224/301 [04:49<01:36,  1.26s/it]\n","Epoch (training) 4:  75%|███████▍  | 225/301 [04:50<01:27,  1.15s/it]\n","Epoch (training) 4:  75%|███████▌  | 226/301 [04:51<01:25,  1.14s/it]\n","Epoch (training) 4:  75%|███████▌  | 227/301 [04:52<01:18,  1.07s/it]\n","Epoch (training) 4:  76%|███████▌  | 228/301 [04:53<01:16,  1.04s/it]\n","Epoch (training) 4:  76%|███████▌  | 229/301 [04:54<01:08,  1.05it/s]\n","Epoch (training) 4:  76%|███████▋  | 230/301 [04:56<01:30,  1.28s/it]\n","Epoch (training) 4:  77%|███████▋  | 231/301 [04:57<01:31,  1.31s/it]\n","Epoch (training) 4:  77%|███████▋  | 232/301 [05:00<02:01,  1.76s/it]\n","Epoch (training) 4:  77%|███████▋  | 233/301 [05:01<01:49,  1.62s/it]\n","Epoch (training) 4:  78%|███████▊  | 234/301 [05:02<01:36,  1.44s/it]\n","Epoch (training) 4:  78%|███████▊  | 235/301 [05:04<01:32,  1.41s/it]\n","Epoch (training) 4:  78%|███████▊  | 236/301 [05:05<01:28,  1.36s/it]\n","Epoch (training) 4:  79%|███████▊  | 237/301 [05:06<01:18,  1.23s/it]\n","Epoch (training) 4:  79%|███████▉  | 238/301 [05:07<01:12,  1.15s/it]\n","Epoch (training) 4:  79%|███████▉  | 239/301 [05:08<01:11,  1.16s/it]\n","Epoch (training) 4:  80%|███████▉  | 240/301 [05:09<01:04,  1.05s/it]\n","Epoch (training) 4:  80%|████████  | 241/301 [05:12<01:33,  1.55s/it]\n","Epoch (training) 4:  80%|████████  | 242/301 [05:13<01:25,  1.45s/it]\n","Epoch (training) 4:  81%|████████  | 243/301 [05:14<01:25,  1.48s/it]\n","Epoch (training) 4:  81%|████████  | 244/301 [05:16<01:19,  1.39s/it]\n","Epoch (training) 4:  81%|████████▏ | 245/301 [05:17<01:12,  1.30s/it]\n","Epoch (training) 4:  82%|████████▏ | 246/301 [05:18<01:05,  1.20s/it]\n","Epoch (training) 4:  82%|████████▏ | 247/301 [05:18<00:58,  1.09s/it]\n","Epoch (training) 4:  82%|████████▏ | 248/301 [05:20<01:10,  1.32s/it]\n","Epoch (training) 4:  83%|████████▎ | 249/301 [05:21<01:03,  1.21s/it]\n","Epoch (training) 4:  83%|████████▎ | 250/301 [05:22<00:56,  1.10s/it]\n","Epoch (training) 4:  83%|████████▎ | 251/301 [05:23<00:58,  1.18s/it]\n","Epoch (training) 4:  84%|████████▎ | 252/301 [05:26<01:12,  1.47s/it]\n","Epoch (training) 4:  84%|████████▍ | 253/301 [05:27<01:06,  1.39s/it]\n","Epoch (training) 4:  84%|████████▍ | 254/301 [05:28<01:03,  1.34s/it]\n","Epoch (training) 4:  85%|████████▍ | 255/301 [05:29<00:54,  1.18s/it]\n","Epoch (training) 4:  85%|████████▌ | 256/301 [05:30<00:57,  1.27s/it]\n","Epoch (training) 4:  85%|████████▌ | 257/301 [05:32<00:57,  1.31s/it]\n","Epoch (training) 4:  86%|████████▌ | 258/301 [05:33<01:00,  1.41s/it]\n","Epoch (training) 4:  86%|████████▌ | 259/301 [05:35<00:57,  1.37s/it]\n","Epoch (training) 4:  86%|████████▋ | 260/301 [05:35<00:49,  1.20s/it]\n","Epoch (training) 4:  87%|████████▋ | 261/301 [05:37<00:51,  1.29s/it]\n","Epoch (training) 4:  87%|████████▋ | 262/301 [05:39<00:58,  1.51s/it]\n","Epoch (training) 4:  87%|████████▋ | 263/301 [05:41<01:05,  1.72s/it]\n","Epoch (training) 4:  88%|████████▊ | 264/301 [05:43<01:03,  1.72s/it]\n","Epoch (training) 4:  88%|████████▊ | 265/301 [05:44<00:57,  1.60s/it]\n","Epoch (training) 4:  88%|████████▊ | 266/301 [05:45<00:50,  1.43s/it]\n","Epoch (training) 4:  89%|████████▊ | 267/301 [05:46<00:41,  1.23s/it]\n","Epoch (training) 4:  89%|████████▉ | 268/301 [05:47<00:40,  1.24s/it]\n","Epoch (training) 4:  89%|████████▉ | 269/301 [05:48<00:39,  1.24s/it]\n","Epoch (training) 4:  90%|████████▉ | 270/301 [05:50<00:38,  1.25s/it]\n","Epoch (training) 4:  90%|█████████ | 271/301 [05:52<00:42,  1.41s/it]\n","Epoch (training) 4:  90%|█████████ | 272/301 [05:54<00:46,  1.62s/it]\n","Epoch (training) 4:  91%|█████████ | 273/301 [05:56<00:54,  1.96s/it]\n","Epoch (training) 4:  91%|█████████ | 274/301 [05:58<00:51,  1.90s/it]\n","Epoch (training) 4:  91%|█████████▏| 275/301 [05:59<00:43,  1.67s/it]\n","Epoch (training) 4:  92%|█████████▏| 276/301 [06:01<00:39,  1.59s/it]\n","Epoch (training) 4:  92%|█████████▏| 277/301 [06:02<00:33,  1.39s/it]\n","Epoch (training) 4:  92%|█████████▏| 278/301 [06:03<00:29,  1.27s/it]\n","Epoch (training) 4:  93%|█████████▎| 279/301 [06:03<00:25,  1.14s/it]\n","Epoch (training) 4:  93%|█████████▎| 280/301 [06:05<00:24,  1.16s/it]\n","Epoch (training) 4:  93%|█████████▎| 281/301 [06:06<00:24,  1.22s/it]\n","Epoch (training) 4:  94%|█████████▎| 282/301 [06:07<00:23,  1.25s/it]\n","Epoch (training) 4:  94%|█████████▍| 283/301 [06:09<00:25,  1.44s/it]\n","Epoch (training) 4:  94%|█████████▍| 284/301 [06:10<00:23,  1.38s/it]\n","Epoch (training) 4:  95%|█████████▍| 285/301 [06:12<00:25,  1.56s/it]\n","Epoch (training) 4:  95%|█████████▌| 286/301 [06:13<00:20,  1.38s/it]\n","Epoch (training) 4:  95%|█████████▌| 287/301 [06:15<00:19,  1.36s/it]\n","Epoch (training) 4:  96%|█████████▌| 288/301 [06:16<00:16,  1.28s/it]\n","Epoch (training) 4:  96%|█████████▌| 289/301 [06:17<00:14,  1.22s/it]\n","Epoch (training) 4:  96%|█████████▋| 290/301 [06:18<00:12,  1.18s/it]\n","Epoch (training) 4:  97%|█████████▋| 291/301 [06:19<00:10,  1.07s/it]\n","Epoch (training) 4:  97%|█████████▋| 292/301 [06:20<00:08,  1.04it/s]\n","Epoch (training) 4:  97%|█████████▋| 293/301 [06:20<00:07,  1.12it/s]\n","Epoch (training) 4:  98%|█████████▊| 294/301 [06:21<00:06,  1.08it/s]\n","Epoch (training) 4:  98%|█████████▊| 295/301 [06:22<00:05,  1.07it/s]\n","Epoch (training) 4:  98%|█████████▊| 296/301 [06:23<00:04,  1.08it/s]\n","Epoch (training) 4:  99%|█████████▊| 297/301 [06:25<00:04,  1.15s/it]\n","Epoch (training) 4:  99%|█████████▉| 298/301 [06:26<00:03,  1.25s/it]\n","Epoch (training) 4:  99%|█████████▉| 299/301 [06:28<00:02,  1.25s/it]\n","Epoch (training) 4: 100%|█████████▉| 300/301 [06:28<00:01,  1.01s/it]\n","Epoch (training) 4: 100%|██████████| 301/301 [06:28<00:00,  1.29s/it]\n","Epoch (test) 4:   0%|          | 0/76 [00:00<?, ?it/s]\n","Epoch (test) 4:   1%|▏         | 1/76 [00:01<01:58,  1.58s/it]\n","Epoch (test) 4:   3%|▎         | 2/76 [00:02<01:30,  1.23s/it]\n","Epoch (test) 4:   4%|▍         | 3/76 [00:03<01:21,  1.12s/it]\n","Epoch (test) 4:   5%|▌         | 4/76 [00:04<01:12,  1.01s/it]\n","Epoch (test) 4:   7%|▋         | 5/76 [00:05<01:11,  1.01s/it]\n","Epoch (test) 4:   8%|▊         | 6/76 [00:05<01:00,  1.16it/s]\n","Epoch (test) 4:   9%|▉         | 7/76 [00:07<01:04,  1.07it/s]\n","Epoch (test) 4:  11%|█         | 8/76 [00:07<00:57,  1.18it/s]\n","Epoch (test) 4:  12%|█▏        | 9/76 [00:08<00:58,  1.15it/s]\n","Epoch (test) 4:  13%|█▎        | 10/76 [00:09<01:02,  1.06it/s]\n","Epoch (test) 4:  14%|█▍        | 11/76 [00:10<01:00,  1.08it/s]\n","Epoch (test) 4:  16%|█▌        | 12/76 [00:11<01:03,  1.01it/s]\n","Epoch (test) 4:  17%|█▋        | 13/76 [00:13<01:09,  1.11s/it]\n","Epoch (test) 4:  18%|█▊        | 14/76 [00:13<01:03,  1.03s/it]\n","Epoch (test) 4:  20%|█▉        | 15/76 [00:14<00:53,  1.14it/s]\n","Epoch (test) 4:  21%|██        | 16/76 [00:15<00:48,  1.24it/s]\n","Epoch (test) 4:  22%|██▏       | 17/76 [00:15<00:41,  1.41it/s]\n","Epoch (test) 4:  24%|██▎       | 18/76 [00:16<00:44,  1.30it/s]\n","Epoch (test) 4:  25%|██▌       | 19/76 [00:17<00:39,  1.44it/s]\n","Epoch (test) 4:  26%|██▋       | 20/76 [00:17<00:41,  1.34it/s]\n","Epoch (test) 4:  28%|██▊       | 21/76 [00:18<00:43,  1.26it/s]\n","Epoch (test) 4:  29%|██▉       | 22/76 [00:19<00:44,  1.21it/s]\n","Epoch (test) 4:  30%|███       | 23/76 [00:20<00:44,  1.19it/s]\n","Epoch (test) 4:  32%|███▏      | 24/76 [00:21<00:43,  1.20it/s]\n","Epoch (test) 4:  33%|███▎      | 25/76 [00:22<00:49,  1.03it/s]\n","Epoch (test) 4:  34%|███▍      | 26/76 [00:24<00:55,  1.10s/it]\n","Epoch (test) 4:  36%|███▌      | 27/76 [00:25<00:52,  1.08s/it]\n","Epoch (test) 4:  37%|███▋      | 28/76 [00:26<01:00,  1.25s/it]\n","Epoch (test) 4:  38%|███▊      | 29/76 [00:28<01:02,  1.33s/it]\n","Epoch (test) 4:  39%|███▉      | 30/76 [00:29<00:52,  1.14s/it]\n","Epoch (test) 4:  41%|████      | 31/76 [00:29<00:46,  1.04s/it]\n","Epoch (test) 4:  42%|████▏     | 32/76 [00:31<00:49,  1.12s/it]\n","Epoch (test) 4:  43%|████▎     | 33/76 [00:31<00:41,  1.04it/s]\n","Epoch (test) 4:  45%|████▍     | 34/76 [00:32<00:37,  1.13it/s]\n","Epoch (test) 4:  46%|████▌     | 35/76 [00:33<00:35,  1.15it/s]\n","Epoch (test) 4:  47%|████▋     | 36/76 [00:33<00:30,  1.30it/s]\n","Epoch (test) 4:  49%|████▊     | 37/76 [00:34<00:28,  1.37it/s]\n","Epoch (test) 4:  50%|█████     | 38/76 [00:35<00:26,  1.45it/s]\n","Epoch (test) 4:  51%|█████▏    | 39/76 [00:36<00:29,  1.23it/s]\n","Epoch (test) 4:  53%|█████▎    | 40/76 [00:36<00:28,  1.27it/s]\n","Epoch (test) 4:  54%|█████▍    | 41/76 [00:37<00:24,  1.40it/s]\n","Epoch (test) 4:  55%|█████▌    | 42/76 [00:38<00:26,  1.27it/s]\n","Epoch (test) 4:  57%|█████▋    | 43/76 [00:39<00:33,  1.01s/it]\n","Epoch (test) 4:  58%|█████▊    | 44/76 [00:41<00:35,  1.11s/it]\n","Epoch (test) 4:  59%|█████▉    | 45/76 [00:42<00:34,  1.13s/it]\n","Epoch (test) 4:  61%|██████    | 46/76 [00:44<00:44,  1.47s/it]\n","Epoch (test) 4:  62%|██████▏   | 47/76 [00:45<00:40,  1.40s/it]\n","Epoch (test) 4:  63%|██████▎   | 48/76 [00:47<00:36,  1.32s/it]\n","Epoch (test) 4:  64%|██████▍   | 49/76 [00:48<00:35,  1.33s/it]\n","Epoch (test) 4:  66%|██████▌   | 50/76 [00:50<00:40,  1.58s/it]\n","Epoch (test) 4:  67%|██████▋   | 51/76 [00:51<00:37,  1.48s/it]\n","Epoch (test) 4:  68%|██████▊   | 52/76 [00:53<00:39,  1.64s/it]\n","Epoch (test) 4:  70%|██████▉   | 53/76 [00:55<00:40,  1.77s/it]\n","Epoch (test) 4:  71%|███████   | 54/76 [00:59<00:49,  2.25s/it]\n","Epoch (test) 4:  72%|███████▏  | 55/76 [01:01<00:45,  2.18s/it]\n","Epoch (test) 4:  74%|███████▎  | 56/76 [01:03<00:41,  2.06s/it]\n","Epoch (test) 4:  75%|███████▌  | 57/76 [01:04<00:37,  1.99s/it]\n","Epoch (test) 4:  76%|███████▋  | 58/76 [01:06<00:31,  1.77s/it]\n","Epoch (test) 4:  78%|███████▊  | 59/76 [01:07<00:26,  1.56s/it]\n","Epoch (test) 4:  79%|███████▉  | 60/76 [01:09<00:26,  1.63s/it]\n","Epoch (test) 4:  80%|████████  | 61/76 [01:10<00:26,  1.74s/it]\n","Epoch (test) 4:  82%|████████▏ | 62/76 [01:12<00:24,  1.74s/it]\n","Epoch (test) 4:  83%|████████▎ | 63/76 [01:14<00:21,  1.67s/it]\n","Epoch (test) 4:  84%|████████▍ | 64/76 [01:16<00:23,  1.93s/it]\n","Epoch (test) 4:  86%|████████▌ | 65/76 [01:18<00:19,  1.78s/it]\n","Epoch (test) 4:  87%|████████▋ | 66/76 [01:19<00:15,  1.55s/it]\n","Epoch (test) 4:  88%|████████▊ | 67/76 [01:20<00:13,  1.45s/it]\n","Epoch (test) 4:  89%|████████▉ | 68/76 [01:21<00:10,  1.36s/it]\n","Epoch (test) 4:  91%|█████████ | 69/76 [01:23<00:11,  1.62s/it]\n","Epoch (test) 4:  92%|█████████▏| 70/76 [01:27<00:13,  2.24s/it]\n","Epoch (test) 4:  93%|█████████▎| 71/76 [01:29<00:11,  2.23s/it]\n","Epoch (test) 4:  95%|█████████▍| 72/76 [01:31<00:07,  1.98s/it]\n","Epoch (test) 4:  96%|█████████▌| 73/76 [01:32<00:05,  1.88s/it]\n","Epoch (test) 4:  97%|█████████▋| 74/76 [01:36<00:04,  2.43s/it]\n","Epoch (test) 4: 100%|██████████| 76/76 [01:36<00:00,  1.27s/it]\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_cv_outer_4/TorchTrainer_b33ac_00000_0_2024-04-14_19-32-16/checkpoint_000003)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training finished iteration 4 at 2024-04-14 21:33:20. Total running time: 2hr 1min 4s\n","+---------------------------------------------+\n","| Training result                             |\n","+---------------------------------------------+\n","| checkpoint_dir_name       checkpoint_000003 |\n","| time_this_iter_s                  488.99802 |\n","| time_total_s                      7254.7423 |\n","| training_iteration                        4 |\n","| accuracy                            0.45458 |\n","| confusion_matrix       ...11, 8, 7, 7, 11]) |\n","| f1                                  0.43183 |\n","| loss                                1.60006 |\n","| precision                           0.51559 |\n","| recall                              0.45458 |\n","| summary/epoch/0                         1.0 |\n","| summary/epoch/1                         2.0 |\n","| summary/epoch/2                         3.0 |\n","| summary/epoch/3                         4.0 |\n","| summary/train_acc/0     0.28052083333333333 |\n","| summary/train_acc/1     0.40020833333333333 |\n","| summary/train_acc/2      0.4580208333333333 |\n","| summary/train_acc/3      0.5085416666666667 |\n","| summary/train_loss/0     2.0832002725316046 |\n","| summary/train_loss/1      1.756782130545556 |\n","| summary/train_loss/2     1.5777994148754995 |\n","| summary/train_loss/3      1.447633372588807 |\n","| summary/val_acc/0       0.37833333333333335 |\n","| summary/val_acc/1       0.40291666666666665 |\n","| summary/val_acc/2        0.4483333333333333 |\n","| summary/val_acc/3       0.45458333333333334 |\n","| summary/val_loss/0       1.8843663452487243 |\n","| summary/val_loss/1        1.757122580158083 |\n","| summary/val_loss/2       1.5903012258441824 |\n","| summary/val_loss/3        1.600063558863966 |\n","+---------------------------------------------+\n","Training saved a checkpoint for iteration 4 at: (local)/root/ray_results/wide_resnet50_cv_outer_4/TorchTrainer_b33ac_00000_0_2024-04-14_19-32-16/checkpoint_000003\n"]},{"output_type":"stream","name":"stderr","text":["Epoch (training) 5:   0%|          | 0/301 [00:00<?, ?it/s]\n","Epoch (training) 5:   0%|          | 1/301 [00:03<16:39,  3.33s/it]\n","Epoch (training) 5:   1%|          | 2/301 [00:04<09:24,  1.89s/it]\n","Epoch (training) 5:   1%|          | 3/301 [00:05<06:56,  1.40s/it]\n","Epoch (training) 5:   1%|▏         | 4/301 [00:06<06:32,  1.32s/it]\n","Epoch (training) 5:   2%|▏         | 5/301 [00:07<05:45,  1.17s/it]\n","Epoch (training) 5:   2%|▏         | 6/301 [00:08<05:16,  1.07s/it]\n","Epoch (training) 5:   2%|▏         | 7/301 [00:08<04:38,  1.06it/s]\n","Epoch (training) 5:   3%|▎         | 8/301 [00:09<04:15,  1.15it/s]\n","Epoch (training) 5:   3%|▎         | 9/301 [00:10<04:04,  1.19it/s]\n","Epoch (training) 5:   3%|▎         | 10/301 [00:11<04:48,  1.01it/s]\n","Epoch (training) 5:   4%|▎         | 11/301 [00:12<04:23,  1.10it/s]\n","Epoch (training) 5:   4%|▍         | 12/301 [00:13<04:55,  1.02s/it]\n","Epoch (training) 5:   4%|▍         | 13/301 [00:15<06:18,  1.32s/it]\n","Epoch (training) 5:   5%|▍         | 14/301 [00:16<05:42,  1.19s/it]\n","Epoch (training) 5:   5%|▍         | 15/301 [00:17<05:27,  1.14s/it]\n","Epoch (training) 5:   5%|▌         | 16/301 [00:18<04:55,  1.04s/it]\n","Epoch (training) 5:   6%|▌         | 17/301 [00:19<04:50,  1.02s/it]\n","Epoch (training) 5:   6%|▌         | 18/301 [00:20<05:02,  1.07s/it]\n","Epoch (training) 5:   6%|▋         | 19/301 [00:21<04:54,  1.05s/it]\n","Epoch (training) 5:   7%|▋         | 20/301 [00:22<05:16,  1.12s/it]\n","Epoch (training) 5:   7%|▋         | 21/301 [00:23<04:46,  1.02s/it]\n","Epoch (training) 5:   7%|▋         | 22/301 [00:24<05:12,  1.12s/it]\n","Epoch (training) 5:   8%|▊         | 23/301 [00:25<04:55,  1.06s/it]\n","Epoch (training) 5:   8%|▊         | 24/301 [00:26<04:45,  1.03s/it]\n","Epoch (training) 5:   8%|▊         | 25/301 [00:28<05:58,  1.30s/it]\n","Epoch (training) 5:   9%|▊         | 26/301 [00:29<05:48,  1.27s/it]\n","Epoch (training) 5:   9%|▉         | 27/301 [00:31<06:31,  1.43s/it]\n","Epoch (training) 5:   9%|▉         | 28/301 [00:32<05:49,  1.28s/it]\n","Epoch (training) 5:  10%|▉         | 29/301 [00:33<05:10,  1.14s/it]\n","Epoch (training) 5:  10%|▉         | 30/301 [00:34<05:01,  1.11s/it]\n","Epoch (training) 5:  10%|█         | 31/301 [00:35<05:16,  1.17s/it]\n","Epoch (training) 5:  11%|█         | 32/301 [00:36<04:38,  1.04s/it]\n","Epoch (training) 5:  11%|█         | 33/301 [00:37<04:15,  1.05it/s]\n","Epoch (training) 5:  11%|█▏        | 34/301 [00:38<04:27,  1.00s/it]\n","Epoch (training) 5:  12%|█▏        | 35/301 [00:39<04:11,  1.06it/s]\n","Epoch (training) 5:  12%|█▏        | 36/301 [00:40<04:10,  1.06it/s]\n","Epoch (training) 5:  12%|█▏        | 37/301 [00:41<04:26,  1.01s/it]\n","Epoch (training) 5:  13%|█▎        | 38/301 [00:43<06:02,  1.38s/it]\n","Epoch (training) 5:  13%|█▎        | 39/301 [00:45<06:16,  1.44s/it]\n","Epoch (training) 5:  13%|█▎        | 40/301 [00:46<06:34,  1.51s/it]\n","Epoch (training) 5:  14%|█▎        | 41/301 [00:47<05:34,  1.29s/it]\n","Epoch (training) 5:  14%|█▍        | 42/301 [00:49<06:09,  1.43s/it]\n","Epoch (training) 5:  14%|█▍        | 43/301 [00:51<07:07,  1.66s/it]\n","Epoch (training) 5:  15%|█▍        | 44/301 [00:52<06:34,  1.53s/it]\n","Epoch (training) 5:  15%|█▍        | 45/301 [00:53<06:00,  1.41s/it]\n","Epoch (training) 5:  15%|█▌        | 46/301 [00:54<05:18,  1.25s/it]\n","Epoch (training) 5:  16%|█▌        | 47/301 [00:56<05:52,  1.39s/it]\n","Epoch (training) 5:  16%|█▌        | 48/301 [00:59<07:42,  1.83s/it]\n","Epoch (training) 5:  16%|█▋        | 49/301 [01:00<07:28,  1.78s/it]\n","Epoch (training) 5:  17%|█▋        | 50/301 [01:01<06:09,  1.47s/it]\n","Epoch (training) 5:  17%|█▋        | 51/301 [01:02<05:21,  1.29s/it]\n","Epoch (training) 5:  17%|█▋        | 52/301 [01:03<04:48,  1.16s/it]\n","Epoch (training) 5:  18%|█▊        | 53/301 [01:04<04:28,  1.08s/it]\n","Epoch (training) 5:  18%|█▊        | 54/301 [01:05<04:24,  1.07s/it]\n","Epoch (training) 5:  18%|█▊        | 55/301 [01:06<04:03,  1.01it/s]\n","Epoch (training) 5:  19%|█▊        | 56/301 [01:07<04:50,  1.19s/it]\n","Epoch (training) 5:  19%|█▉        | 57/301 [01:08<04:27,  1.10s/it]\n","Epoch (training) 5:  19%|█▉        | 58/301 [01:09<04:05,  1.01s/it]\n","Epoch (training) 5:  20%|█▉        | 59/301 [01:10<04:14,  1.05s/it]\n","Epoch (training) 5:  20%|█▉        | 60/301 [01:12<05:35,  1.39s/it]\n","Epoch (training) 5:  20%|██        | 61/301 [01:14<06:24,  1.60s/it]\n","Epoch (training) 5:  21%|██        | 62/301 [01:16<06:32,  1.64s/it]\n","Epoch (training) 5:  21%|██        | 63/301 [01:17<05:27,  1.38s/it]\n","Epoch (training) 5:  21%|██▏       | 64/301 [01:18<05:27,  1.38s/it]\n","Epoch (training) 5:  22%|██▏       | 65/301 [01:19<04:52,  1.24s/it]\n","Epoch (training) 5:  22%|██▏       | 66/301 [01:20<04:21,  1.11s/it]\n","Epoch (training) 5:  22%|██▏       | 67/301 [01:21<04:05,  1.05s/it]\n","Epoch (training) 5:  23%|██▎       | 68/301 [01:22<04:02,  1.04s/it]\n","Epoch (training) 5:  23%|██▎       | 69/301 [01:23<03:51,  1.00it/s]\n","Epoch (training) 5:  23%|██▎       | 70/301 [01:24<03:35,  1.07it/s]\n","Epoch (training) 5:  24%|██▎       | 71/301 [01:25<03:49,  1.00it/s]\n","Epoch (training) 5:  24%|██▍       | 72/301 [01:26<04:01,  1.05s/it]\n","Epoch (training) 5:  24%|██▍       | 73/301 [01:27<04:22,  1.15s/it]\n","Epoch (training) 5:  25%|██▍       | 74/301 [01:29<05:01,  1.33s/it]\n","Epoch (training) 5:  25%|██▍       | 75/301 [01:31<05:16,  1.40s/it]\n","Epoch (training) 5:  25%|██▌       | 76/301 [01:32<05:00,  1.33s/it]\n","Epoch (training) 5:  26%|██▌       | 77/301 [01:33<04:38,  1.24s/it]\n","Epoch (training) 5:  26%|██▌       | 78/301 [01:34<04:33,  1.23s/it]\n","Epoch (training) 5:  26%|██▌       | 79/301 [01:35<04:10,  1.13s/it]\n","Epoch (training) 5:  27%|██▋       | 80/301 [01:36<03:43,  1.01s/it]\n","Epoch (training) 5:  27%|██▋       | 81/301 [01:38<05:11,  1.42s/it]\n","Epoch (training) 5:  27%|██▋       | 82/301 [01:39<04:43,  1.30s/it]\n","Epoch (training) 5:  28%|██▊       | 83/301 [01:40<04:25,  1.22s/it]\n","Epoch (training) 5:  28%|██▊       | 84/301 [01:43<06:04,  1.68s/it]\n","Epoch (training) 5:  28%|██▊       | 85/301 [01:45<06:36,  1.84s/it]\n","Epoch (training) 5:  29%|██▊       | 86/301 [01:46<06:04,  1.70s/it]\n","Epoch (training) 5:  29%|██▉       | 87/301 [01:47<05:14,  1.47s/it]\n","Epoch (training) 5:  29%|██▉       | 88/301 [01:49<04:51,  1.37s/it]\n","Epoch (training) 5:  30%|██▉       | 89/301 [01:49<04:24,  1.25s/it]\n","Epoch (training) 5:  30%|██▉       | 90/301 [01:51<04:29,  1.28s/it]\n","Epoch (training) 5:  30%|███       | 91/301 [01:52<04:42,  1.35s/it]\n","Epoch (training) 5:  31%|███       | 92/301 [01:53<04:22,  1.26s/it]\n","Epoch (training) 5:  31%|███       | 93/301 [01:55<05:04,  1.47s/it]\n","Epoch (training) 5:  31%|███       | 94/301 [01:57<05:28,  1.59s/it]\n","Epoch (training) 5:  32%|███▏      | 95/301 [01:59<05:14,  1.53s/it]\n","Epoch (training) 5:  32%|███▏      | 96/301 [02:00<04:44,  1.39s/it]\n","Epoch (training) 5:  32%|███▏      | 97/301 [02:01<04:11,  1.23s/it]\n","Epoch (training) 5:  33%|███▎      | 98/301 [02:01<03:42,  1.09s/it]\n","Epoch (training) 5:  33%|███▎      | 99/301 [02:02<03:44,  1.11s/it]\n","Epoch (training) 5:  33%|███▎      | 100/301 [02:04<03:39,  1.09s/it]\n","Epoch (training) 5:  34%|███▎      | 101/301 [02:04<03:26,  1.03s/it]\n","Epoch (training) 5:  34%|███▍      | 102/301 [02:06<03:32,  1.07s/it]\n","Epoch (training) 5:  34%|███▍      | 103/301 [02:06<03:23,  1.03s/it]\n","Epoch (training) 5:  35%|███▍      | 104/301 [02:08<03:38,  1.11s/it]\n","Epoch (training) 5:  35%|███▍      | 105/301 [02:09<03:16,  1.00s/it]\n","Epoch (training) 5:  35%|███▌      | 106/301 [02:09<03:11,  1.02it/s]\n","Epoch (training) 5:  36%|███▌      | 107/301 [02:11<03:26,  1.07s/it]\n","Epoch (training) 5:  36%|███▌      | 108/301 [02:12<03:29,  1.09s/it]\n","Epoch (training) 5:  36%|███▌      | 109/301 [02:13<03:27,  1.08s/it]\n","Epoch (training) 5:  37%|███▋      | 110/301 [02:14<03:44,  1.17s/it]\n","Epoch (training) 5:  37%|███▋      | 111/301 [02:15<03:25,  1.08s/it]\n","Epoch (training) 5:  37%|███▋      | 112/301 [02:17<04:11,  1.33s/it]\n","Epoch (training) 5:  38%|███▊      | 113/301 [02:18<03:41,  1.18s/it]\n","Epoch (training) 5:  38%|███▊      | 114/301 [02:19<03:15,  1.05s/it]\n","Epoch (training) 5:  38%|███▊      | 115/301 [02:19<02:57,  1.05it/s]\n","Epoch (training) 5:  39%|███▊      | 116/301 [02:21<03:43,  1.21s/it]\n","Epoch (training) 5:  39%|███▉      | 117/301 [02:22<03:27,  1.13s/it]\n","Epoch (training) 5:  39%|███▉      | 118/301 [02:23<03:27,  1.13s/it]\n","Epoch (training) 5:  40%|███▉      | 119/301 [02:25<03:31,  1.16s/it]\n","Epoch (training) 5:  40%|███▉      | 120/301 [02:26<03:45,  1.25s/it]\n","Epoch (training) 5:  40%|████      | 121/301 [02:27<03:47,  1.26s/it]\n","Epoch (training) 5:  41%|████      | 122/301 [02:29<03:48,  1.28s/it]\n","Epoch (training) 5:  41%|████      | 123/301 [02:30<03:40,  1.24s/it]\n","Epoch (training) 5:  41%|████      | 124/301 [02:31<03:24,  1.16s/it]\n","Epoch (training) 5:  42%|████▏     | 125/301 [02:32<03:26,  1.17s/it]\n","Epoch (training) 5:  42%|████▏     | 126/301 [02:33<03:41,  1.27s/it]\n","Epoch (training) 5:  42%|████▏     | 127/301 [02:35<03:50,  1.33s/it]\n","Epoch (training) 5:  43%|████▎     | 128/301 [02:36<04:04,  1.42s/it]\n","Epoch (training) 5:  43%|████▎     | 129/301 [02:38<03:48,  1.33s/it]\n","Epoch (training) 5:  43%|████▎     | 130/301 [02:39<03:55,  1.38s/it]\n","Epoch (training) 5:  44%|████▎     | 131/301 [02:40<03:47,  1.34s/it]\n","Epoch (training) 5:  44%|████▍     | 132/301 [02:43<04:53,  1.73s/it]\n","Epoch (training) 5:  44%|████▍     | 133/301 [02:44<04:19,  1.54s/it]\n","Epoch (training) 5:  45%|████▍     | 134/301 [02:45<03:46,  1.36s/it]\n","Epoch (training) 5:  45%|████▍     | 135/301 [02:46<03:15,  1.18s/it]\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m /usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m   warnings.warn(\n","Epoch (training) 5:  45%|████▌     | 136/301 [02:47<03:02,  1.11s/it]\n","Epoch (training) 5:  46%|████▌     | 137/301 [02:47<02:38,  1.04it/s]\n","Epoch (training) 5:  46%|████▌     | 138/301 [02:48<02:35,  1.05it/s]\n","Epoch (training) 5:  46%|████▌     | 139/301 [02:49<02:32,  1.07it/s]\n","Epoch (training) 5:  47%|████▋     | 140/301 [02:50<02:26,  1.10it/s]\n","Epoch (training) 5:  47%|████▋     | 141/301 [02:51<02:47,  1.05s/it]\n","Epoch (training) 5:  47%|████▋     | 142/301 [02:52<02:30,  1.06it/s]\n","Epoch (training) 5:  48%|████▊     | 143/301 [02:53<02:32,  1.03it/s]\n","Epoch (training) 5:  48%|████▊     | 144/301 [02:55<03:32,  1.35s/it]\n","Epoch (training) 5:  48%|████▊     | 145/301 [02:58<04:26,  1.71s/it]\n","Epoch (training) 5:  49%|████▊     | 146/301 [02:59<03:40,  1.42s/it]\n","Epoch (training) 5:  49%|████▉     | 147/301 [03:00<03:39,  1.43s/it]\n","Epoch (training) 5:  49%|████▉     | 148/301 [03:02<03:42,  1.45s/it]\n","Epoch (training) 5:  50%|████▉     | 149/301 [03:02<03:08,  1.24s/it]\n","Epoch (training) 5:  50%|████▉     | 150/301 [03:04<03:04,  1.22s/it]\n","Epoch (training) 5:  50%|█████     | 151/301 [03:05<03:07,  1.25s/it]\n","Epoch (training) 5:  50%|█████     | 152/301 [03:06<02:58,  1.20s/it]\n","Epoch (training) 5:  51%|█████     | 153/301 [03:07<03:06,  1.26s/it]\n","Epoch (training) 5:  51%|█████     | 154/301 [03:09<03:18,  1.35s/it]\n","Epoch (training) 5:  51%|█████▏    | 155/301 [03:11<03:32,  1.46s/it]\n","Epoch (training) 5:  52%|█████▏    | 156/301 [03:13<04:17,  1.78s/it]\n","Epoch (training) 5:  52%|█████▏    | 157/301 [03:14<03:35,  1.50s/it]\n","Epoch (training) 5:  52%|█████▏    | 158/301 [03:15<03:24,  1.43s/it]\n","Epoch (training) 5:  53%|█████▎    | 159/301 [03:16<03:01,  1.28s/it]\n","Epoch (training) 5:  53%|█████▎    | 160/301 [03:17<02:48,  1.20s/it]\n","Epoch (training) 5:  53%|█████▎    | 161/301 [03:19<03:31,  1.51s/it]\n","Epoch (training) 5:  54%|█████▍    | 162/301 [03:21<03:29,  1.51s/it]\n","Epoch (training) 5:  54%|█████▍    | 163/301 [03:22<03:06,  1.35s/it]\n","Epoch (training) 5:  54%|█████▍    | 164/301 [03:23<03:01,  1.32s/it]\n","Epoch (training) 5:  55%|█████▍    | 165/301 [03:25<03:12,  1.41s/it]\n","Epoch (training) 5:  55%|█████▌    | 166/301 [03:27<03:31,  1.57s/it]\n","Epoch (training) 5:  55%|█████▌    | 167/301 [03:28<03:26,  1.54s/it]\n","Epoch (training) 5:  56%|█████▌    | 168/301 [03:29<03:14,  1.46s/it]\n","Epoch (training) 5:  56%|█████▌    | 169/301 [03:30<02:50,  1.29s/it]\n","Epoch (training) 5:  56%|█████▋    | 170/301 [03:31<02:28,  1.13s/it]\n","Epoch (training) 5:  57%|█████▋    | 171/301 [03:33<02:44,  1.26s/it]\n","Epoch (training) 5:  57%|█████▋    | 172/301 [03:34<02:45,  1.29s/it]\n","Epoch (training) 5:  57%|█████▋    | 173/301 [03:35<02:39,  1.25s/it]\n","Epoch (training) 5:  58%|█████▊    | 174/301 [03:36<02:34,  1.22s/it]\n","Epoch (training) 5:  58%|█████▊    | 175/301 [03:37<02:15,  1.07s/it]\n","Epoch (training) 5:  58%|█████▊    | 176/301 [03:38<02:11,  1.05s/it]\n","Epoch (training) 5:  59%|█████▉    | 177/301 [03:40<02:25,  1.17s/it]\n","Epoch (training) 5:  59%|█████▉    | 178/301 [03:41<02:19,  1.13s/it]\n","Epoch (training) 5:  59%|█████▉    | 179/301 [03:42<02:42,  1.33s/it]\n","Epoch (training) 5:  60%|█████▉    | 180/301 [03:43<02:21,  1.17s/it]\n","Epoch (training) 5:  60%|██████    | 181/301 [03:44<02:12,  1.11s/it]\n","Epoch (training) 5:  60%|██████    | 182/301 [03:45<02:05,  1.06s/it]\n","Epoch (training) 5:  61%|██████    | 183/301 [03:48<03:16,  1.66s/it]\n","Epoch (training) 5:  61%|██████    | 184/301 [03:49<02:46,  1.43s/it]\n","Epoch (training) 5:  61%|██████▏   | 185/301 [03:50<02:30,  1.29s/it]\n","Epoch (training) 5:  62%|██████▏   | 186/301 [03:51<02:11,  1.15s/it]\n","Epoch (training) 5:  62%|██████▏   | 187/301 [03:53<03:03,  1.61s/it]\n","Epoch (training) 5:  62%|██████▏   | 188/301 [03:55<02:47,  1.49s/it]\n","Epoch (training) 5:  63%|██████▎   | 189/301 [03:56<02:41,  1.44s/it]\n","Epoch (training) 5:  63%|██████▎   | 190/301 [03:58<02:56,  1.59s/it]\n","Epoch (training) 5:  63%|██████▎   | 191/301 [03:59<02:26,  1.33s/it]\n","Epoch (training) 5:  64%|██████▍   | 192/301 [04:00<02:19,  1.28s/it]\n","Epoch (training) 5:  64%|██████▍   | 193/301 [04:02<02:30,  1.39s/it]\n","Epoch (training) 5:  64%|██████▍   | 194/301 [04:02<02:14,  1.26s/it]\n","Epoch (training) 5:  65%|██████▍   | 195/301 [04:03<02:03,  1.17s/it]\n","Epoch (training) 5:  65%|██████▌   | 196/301 [04:05<02:14,  1.28s/it]\n","Epoch (training) 5:  65%|██████▌   | 197/301 [04:06<02:19,  1.34s/it]\n","Epoch (training) 5:  66%|██████▌   | 198/301 [04:08<02:11,  1.28s/it]\n","Epoch (training) 5:  66%|██████▌   | 199/301 [04:11<03:04,  1.81s/it]\n","Epoch (training) 5:  66%|██████▋   | 200/301 [04:12<02:41,  1.60s/it]\n","Epoch (training) 5:  67%|██████▋   | 201/301 [04:13<02:25,  1.45s/it]\n","Epoch (training) 5:  67%|██████▋   | 202/301 [04:15<02:50,  1.72s/it]\n","Epoch (training) 5:  67%|██████▋   | 203/301 [04:17<02:39,  1.63s/it]\n","Epoch (training) 5:  68%|██████▊   | 204/301 [04:18<02:28,  1.53s/it]\n","Epoch (training) 5:  68%|██████▊   | 205/301 [04:19<02:17,  1.43s/it]\n","Epoch (training) 5:  68%|██████▊   | 206/301 [04:20<02:01,  1.28s/it]\n","Epoch (training) 5:  69%|██████▉   | 207/301 [04:21<01:56,  1.24s/it]\n","Epoch (training) 5:  69%|██████▉   | 208/301 [04:23<02:06,  1.36s/it]\n","Epoch (training) 5:  69%|██████▉   | 209/301 [04:24<02:02,  1.33s/it]\n","Epoch (training) 5:  70%|██████▉   | 210/301 [04:26<02:07,  1.40s/it]\n","Epoch (training) 5:  70%|███████   | 211/301 [04:27<02:08,  1.43s/it]\n","Epoch (training) 5:  70%|███████   | 212/301 [04:28<01:53,  1.27s/it]\n","Epoch (training) 5:  71%|███████   | 213/301 [04:29<01:39,  1.13s/it]\n","Epoch (training) 5:  71%|███████   | 214/301 [04:30<01:32,  1.07s/it]\n","Epoch (training) 5:  71%|███████▏  | 215/301 [04:31<01:36,  1.13s/it]\n","Epoch (training) 5:  72%|███████▏  | 216/301 [04:32<01:40,  1.18s/it]\n","Epoch (training) 5:  72%|███████▏  | 217/301 [04:34<01:52,  1.34s/it]\n","Epoch (training) 5:  72%|███████▏  | 218/301 [04:35<01:45,  1.28s/it]\n","Epoch (training) 5:  73%|███████▎  | 219/301 [04:36<01:42,  1.25s/it]\n","Epoch (training) 5:  73%|███████▎  | 220/301 [04:38<01:48,  1.34s/it]\n","Epoch (training) 5:  73%|███████▎  | 221/301 [04:39<01:37,  1.22s/it]\n","Epoch (training) 5:  74%|███████▍  | 222/301 [04:41<01:59,  1.51s/it]\n","Epoch (training) 5:  74%|███████▍  | 223/301 [04:42<01:48,  1.40s/it]\n","Epoch (training) 5:  74%|███████▍  | 224/301 [04:43<01:43,  1.34s/it]\n","Epoch (training) 5:  75%|███████▍  | 225/301 [04:44<01:34,  1.25s/it]\n","Epoch (training) 5:  75%|███████▌  | 226/301 [04:46<01:40,  1.35s/it]\n","Epoch (training) 5:  75%|███████▌  | 227/301 [04:48<01:46,  1.44s/it]\n","Epoch (training) 5:  76%|███████▌  | 228/301 [04:48<01:31,  1.25s/it]\n","Epoch (training) 5:  76%|███████▌  | 229/301 [04:50<01:28,  1.23s/it]\n","Epoch (training) 5:  76%|███████▋  | 230/301 [04:51<01:22,  1.16s/it]\n","Epoch (training) 5:  77%|███████▋  | 231/301 [04:53<01:38,  1.41s/it]\n","Epoch (training) 5:  77%|███████▋  | 232/301 [04:54<01:38,  1.42s/it]\n","Epoch (training) 5:  77%|███████▋  | 233/301 [04:56<01:45,  1.55s/it]\n","Epoch (training) 5:  78%|███████▊  | 234/301 [04:57<01:30,  1.35s/it]\n","Epoch (training) 5:  78%|███████▊  | 235/301 [04:58<01:30,  1.38s/it]\n","Epoch (training) 5:  78%|███████▊  | 236/301 [05:00<01:43,  1.59s/it]\n","Epoch (training) 5:  79%|███████▊  | 237/301 [05:02<01:52,  1.76s/it]\n","Epoch (training) 5:  79%|███████▉  | 238/301 [05:04<01:49,  1.73s/it]\n","Epoch (training) 5:  79%|███████▉  | 239/301 [05:06<01:50,  1.79s/it]\n","Epoch (training) 5:  80%|███████▉  | 240/301 [05:07<01:38,  1.61s/it]\n","Epoch (training) 5:  80%|████████  | 241/301 [05:10<02:02,  2.04s/it]\n","Epoch (training) 5:  80%|████████  | 242/301 [05:12<01:53,  1.92s/it]\n","Epoch (training) 5:  81%|████████  | 243/301 [05:13<01:37,  1.68s/it]\n","Epoch (training) 5:  81%|████████  | 244/301 [05:14<01:18,  1.37s/it]\n","Epoch (training) 5:  81%|████████▏ | 245/301 [05:15<01:08,  1.22s/it]\n","Epoch (training) 5:  82%|████████▏ | 246/301 [05:17<01:20,  1.46s/it]\n","Epoch (training) 5:  82%|████████▏ | 247/301 [05:18<01:17,  1.43s/it]\n","Epoch (training) 5:  82%|████████▏ | 248/301 [05:19<01:07,  1.28s/it]\n","Epoch (training) 5:  83%|████████▎ | 249/301 [05:20<01:00,  1.16s/it]\n","Epoch (training) 5:  83%|████████▎ | 250/301 [05:21<00:58,  1.14s/it]\n","Epoch (training) 5:  83%|████████▎ | 251/301 [05:22<00:58,  1.17s/it]\n","Epoch (training) 5:  84%|████████▎ | 252/301 [05:25<01:19,  1.61s/it]\n","Epoch (training) 5:  84%|████████▍ | 253/301 [05:27<01:20,  1.67s/it]\n","Epoch (training) 5:  84%|████████▍ | 254/301 [05:28<01:20,  1.71s/it]\n","Epoch (training) 5:  85%|████████▍ | 255/301 [05:29<01:06,  1.44s/it]\n","Epoch (training) 5:  85%|████████▌ | 256/301 [05:30<00:58,  1.30s/it]\n","Epoch (training) 5:  85%|████████▌ | 257/301 [05:32<01:04,  1.46s/it]\n","Epoch (training) 5:  86%|████████▌ | 258/301 [05:33<00:54,  1.26s/it]\n","Epoch (training) 5:  86%|████████▌ | 259/301 [05:34<00:50,  1.20s/it]\n","Epoch (training) 5:  86%|████████▋ | 260/301 [05:35<00:46,  1.13s/it]\n","Epoch (training) 5:  87%|████████▋ | 261/301 [05:38<01:05,  1.63s/it]\n","Epoch (training) 5:  87%|████████▋ | 262/301 [05:39<00:59,  1.52s/it]\n","Epoch (training) 5:  87%|████████▋ | 263/301 [05:41<01:01,  1.62s/it]\n","Epoch (training) 5:  88%|████████▊ | 264/301 [05:43<01:05,  1.76s/it]\n","Epoch (training) 5:  88%|████████▊ | 265/301 [05:45<01:10,  1.96s/it]\n","Epoch (training) 5:  88%|████████▊ | 266/301 [05:46<00:56,  1.62s/it]\n","Epoch (training) 5:  89%|████████▊ | 267/301 [05:47<00:47,  1.39s/it]\n","Epoch (training) 5:  89%|████████▉ | 268/301 [05:48<00:40,  1.22s/it]\n","Epoch (training) 5:  89%|████████▉ | 269/301 [05:49<00:36,  1.14s/it]\n","Epoch (training) 5:  90%|████████▉ | 270/301 [05:51<00:42,  1.37s/it]\n","Epoch (training) 5:  90%|█████████ | 271/301 [05:52<00:40,  1.34s/it]\n","Epoch (training) 5:  90%|█████████ | 272/301 [05:53<00:38,  1.34s/it]\n","Epoch (training) 5:  91%|█████████ | 273/301 [05:54<00:35,  1.26s/it]\n","Epoch (training) 5:  91%|█████████ | 274/301 [05:55<00:33,  1.25s/it]\n","Epoch (training) 5:  91%|█████████▏| 275/301 [05:57<00:32,  1.26s/it]\n","Epoch (training) 5:  92%|█████████▏| 276/301 [05:58<00:30,  1.21s/it]\n","Epoch (training) 5:  92%|█████████▏| 277/301 [05:59<00:28,  1.21s/it]\n","Epoch (training) 5:  92%|█████████▏| 278/301 [06:01<00:31,  1.36s/it]\n","Epoch (training) 5:  93%|█████████▎| 279/301 [06:02<00:26,  1.21s/it]\n","Epoch (training) 5:  93%|█████████▎| 280/301 [06:03<00:25,  1.23s/it]\n","Epoch (training) 5:  93%|█████████▎| 281/301 [06:04<00:23,  1.17s/it]\n","Epoch (training) 5:  94%|█████████▎| 282/301 [06:05<00:24,  1.27s/it]\n","Epoch (training) 5:  94%|█████████▍| 283/301 [06:08<00:28,  1.57s/it]\n","Epoch (training) 5:  94%|█████████▍| 284/301 [06:09<00:25,  1.50s/it]\n","Epoch (training) 5:  95%|█████████▍| 285/301 [06:10<00:20,  1.31s/it]\n","Epoch (training) 5:  95%|█████████▌| 286/301 [06:11<00:18,  1.26s/it]\n","Epoch (training) 5:  95%|█████████▌| 287/301 [06:12<00:15,  1.10s/it]\n","Epoch (training) 5:  96%|█████████▌| 288/301 [06:13<00:13,  1.02s/it]\n","Epoch (training) 5:  96%|█████████▌| 289/301 [06:14<00:12,  1.03s/it]\n","Epoch (training) 5:  96%|█████████▋| 290/301 [06:15<00:12,  1.13s/it]\n","Epoch (training) 5:  97%|█████████▋| 291/301 [06:16<00:11,  1.16s/it]\n","Epoch (training) 5:  97%|█████████▋| 292/301 [06:17<00:09,  1.09s/it]\n","Epoch (training) 5:  97%|█████████▋| 293/301 [06:18<00:08,  1.01s/it]\n","Epoch (training) 5:  98%|█████████▊| 294/301 [06:19<00:07,  1.08s/it]\n","Epoch (training) 5:  98%|█████████▊| 295/301 [06:21<00:06,  1.13s/it]\n","Epoch (training) 5:  98%|█████████▊| 296/301 [06:23<00:07,  1.40s/it]\n","Epoch (training) 5:  99%|█████████▊| 297/301 [06:24<00:05,  1.38s/it]\n","Epoch (training) 5:  99%|█████████▉| 298/301 [06:25<00:03,  1.25s/it]\n","Epoch (training) 5:  99%|█████████▉| 299/301 [06:26<00:02,  1.32s/it]\n","Epoch (training) 5: 100%|█████████▉| 300/301 [06:27<00:00,  1.02it/s]\n","Epoch (training) 5: 100%|██████████| 301/301 [06:27<00:00,  1.29s/it]\n","Epoch (test) 5:   0%|          | 0/76 [00:00<?, ?it/s]\n","Epoch (test) 5:   1%|▏         | 1/76 [00:01<01:58,  1.58s/it]\n","Epoch (test) 5:   3%|▎         | 2/76 [00:02<01:32,  1.25s/it]\n","Epoch (test) 5:   4%|▍         | 3/76 [00:03<01:21,  1.12s/it]\n","Epoch (test) 5:   5%|▌         | 4/76 [00:04<01:12,  1.01s/it]\n","Epoch (test) 5:   7%|▋         | 5/76 [00:05<01:11,  1.01s/it]\n","Epoch (test) 5:   8%|▊         | 6/76 [00:06<01:00,  1.15it/s]\n","Epoch (test) 5:   9%|▉         | 7/76 [00:07<01:07,  1.02it/s]\n","Epoch (test) 5:  11%|█         | 8/76 [00:08<01:06,  1.03it/s]\n","Epoch (test) 5:  12%|█▏        | 9/76 [00:09<01:12,  1.08s/it]\n","Epoch (test) 5:  13%|█▎        | 10/76 [00:10<01:15,  1.15s/it]\n","Epoch (test) 5:  14%|█▍        | 11/76 [00:11<01:07,  1.03s/it]\n","Epoch (test) 5:  16%|█▌        | 12/76 [00:12<01:01,  1.04it/s]\n","Epoch (test) 5:  17%|█▋        | 13/76 [00:13<01:00,  1.04it/s]\n","Epoch (test) 5:  18%|█▊        | 14/76 [00:14<00:56,  1.10it/s]\n","Epoch (test) 5:  20%|█▉        | 15/76 [00:14<00:48,  1.26it/s]\n","Epoch (test) 5:  21%|██        | 16/76 [00:15<00:45,  1.31it/s]\n","Epoch (test) 5:  22%|██▏       | 17/76 [00:15<00:40,  1.45it/s]\n","Epoch (test) 5:  24%|██▎       | 18/76 [00:16<00:44,  1.31it/s]\n","Epoch (test) 5:  25%|██▌       | 19/76 [00:17<00:39,  1.43it/s]\n","Epoch (test) 5:  26%|██▋       | 20/76 [00:18<00:41,  1.36it/s]\n","Epoch (test) 5:  28%|██▊       | 21/76 [00:19<00:43,  1.26it/s]\n","Epoch (test) 5:  29%|██▉       | 22/76 [00:19<00:44,  1.22it/s]\n","Epoch (test) 5:  30%|███       | 23/76 [00:20<00:43,  1.21it/s]\n","Epoch (test) 5:  32%|███▏      | 24/76 [00:21<00:43,  1.20it/s]\n","Epoch (test) 5:  33%|███▎      | 25/76 [00:23<00:58,  1.14s/it]\n","Epoch (test) 5:  34%|███▍      | 26/76 [00:25<01:07,  1.35s/it]\n","Epoch (test) 5:  36%|███▌      | 27/76 [00:26<01:00,  1.23s/it]\n","Epoch (test) 5:  37%|███▋      | 28/76 [00:27<00:57,  1.20s/it]\n","Epoch (test) 5:  38%|███▊      | 29/76 [00:28<00:54,  1.17s/it]\n","Epoch (test) 5:  39%|███▉      | 30/76 [00:29<00:47,  1.02s/it]\n","Epoch (test) 5:  41%|████      | 31/76 [00:30<00:43,  1.03it/s]\n","Epoch (test) 5:  42%|████▏     | 32/76 [00:31<00:47,  1.07s/it]\n","Epoch (test) 5:  43%|████▎     | 33/76 [00:31<00:40,  1.06it/s]\n","Epoch (test) 5:  45%|████▍     | 34/76 [00:32<00:36,  1.14it/s]\n","Epoch (test) 5:  46%|████▌     | 35/76 [00:33<00:35,  1.16it/s]\n","Epoch (test) 5:  47%|████▋     | 36/76 [00:34<00:30,  1.33it/s]\n","Epoch (test) 5:  49%|████▊     | 37/76 [00:34<00:28,  1.39it/s]\n","Epoch (test) 5:  50%|█████     | 38/76 [00:35<00:26,  1.46it/s]\n","Epoch (test) 5:  51%|█████▏    | 39/76 [00:36<00:30,  1.20it/s]\n","Epoch (test) 5:  53%|█████▎    | 40/76 [00:37<00:31,  1.13it/s]\n","Epoch (test) 5:  54%|█████▍    | 41/76 [00:38<00:28,  1.22it/s]\n","Epoch (test) 5:  55%|█████▌    | 42/76 [00:39<00:33,  1.01it/s]\n","Epoch (test) 5:  57%|█████▋    | 43/76 [00:40<00:37,  1.12s/it]\n","Epoch (test) 5:  58%|█████▊    | 44/76 [00:41<00:34,  1.08s/it]\n","Epoch (test) 5:  59%|█████▉    | 45/76 [00:42<00:30,  1.01it/s]\n","Epoch (test) 5:  61%|██████    | 46/76 [00:44<00:39,  1.31s/it]\n","Epoch (test) 5:  62%|██████▏   | 47/76 [00:46<00:37,  1.29s/it]\n","Epoch (test) 5:  63%|██████▎   | 48/76 [00:47<00:34,  1.25s/it]\n","Epoch (test) 5:  64%|██████▍   | 49/76 [00:48<00:34,  1.27s/it]\n","Epoch (test) 5:  66%|██████▌   | 50/76 [00:50<00:39,  1.53s/it]\n","Epoch (test) 5:  67%|██████▋   | 51/76 [00:52<00:39,  1.58s/it]\n","Epoch (test) 5:  68%|██████▊   | 52/76 [00:54<00:43,  1.82s/it]\n","Epoch (test) 5:  70%|██████▉   | 53/76 [00:56<00:40,  1.76s/it]\n","Epoch (test) 5:  71%|███████   | 54/76 [00:59<00:45,  2.06s/it]\n","Epoch (test) 5:  72%|███████▏  | 55/76 [01:01<00:43,  2.05s/it]\n","Epoch (test) 5:  74%|███████▎  | 56/76 [01:02<00:39,  1.98s/it]\n","Epoch (test) 5:  75%|███████▌  | 57/76 [01:04<00:36,  1.94s/it]\n","Epoch (test) 5:  76%|███████▋  | 58/76 [01:06<00:32,  1.78s/it]\n","Epoch (test) 5:  78%|███████▊  | 59/76 [01:07<00:28,  1.65s/it]\n","Epoch (test) 5:  79%|███████▉  | 60/76 [01:09<00:27,  1.74s/it]\n","Epoch (test) 5:  80%|████████  | 61/76 [01:11<00:25,  1.70s/it]\n","Epoch (test) 5:  82%|████████▏ | 62/76 [01:12<00:21,  1.54s/it]\n","Epoch (test) 5:  83%|████████▎ | 63/76 [01:13<00:19,  1.53s/it]\n","Epoch (test) 5:  84%|████████▍ | 64/76 [01:16<00:22,  1.84s/it]\n","Epoch (test) 5:  86%|████████▌ | 65/76 [01:17<00:18,  1.70s/it]\n","Epoch (test) 5:  87%|████████▋ | 66/76 [01:18<00:14,  1.50s/it]\n","Epoch (test) 5:  88%|████████▊ | 67/76 [01:19<00:12,  1.40s/it]\n","Epoch (test) 5:  89%|████████▉ | 68/76 [01:21<00:11,  1.44s/it]\n","Epoch (test) 5:  91%|█████████ | 69/76 [01:24<00:12,  1.80s/it]\n","Epoch (test) 5:  92%|█████████▏| 70/76 [01:26<00:12,  2.09s/it]\n","Epoch (test) 5:  93%|█████████▎| 71/76 [01:28<00:10,  2.11s/it]\n","Epoch (test) 5:  95%|█████████▍| 72/76 [01:30<00:07,  1.90s/it]\n","Epoch (test) 5:  96%|█████████▌| 73/76 [01:31<00:05,  1.81s/it]\n","Epoch (test) 5:  97%|█████████▋| 74/76 [01:36<00:04,  2.50s/it]\n","Epoch (test) 5: 100%|██████████| 76/76 [01:36<00:00,  1.27s/it]\n","\u001b[36m(RayTrainWorker pid=5624)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/wide_resnet50_cv_outer_4/TorchTrainer_b33ac_00000_0_2024-04-14_19-32-16/checkpoint_000004)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training finished iteration 5 at 2024-04-14 21:41:30. Total running time: 2hr 9min 13s\n","+---------------------------------------------+\n","| Training result                             |\n","+---------------------------------------------+\n","| checkpoint_dir_name       checkpoint_000004 |\n","| time_this_iter_s                  489.09886 |\n","| time_total_s                     7743.84116 |\n","| training_iteration                        5 |\n","| accuracy                            0.51208 |\n","| confusion_matrix       ...0, 8, 11, 8, 10]) |\n","| f1                                  0.50517 |\n","| loss                                1.45386 |\n","| precision                           0.55147 |\n","| recall                              0.51208 |\n","| summary/epoch/0                         1.0 |\n","| summary/epoch/1                         2.0 |\n","| summary/epoch/2                         3.0 |\n","| summary/epoch/3                         4.0 |\n","| summary/epoch/4                         5.0 |\n","| summary/train_acc/0     0.28052083333333333 |\n","| summary/train_acc/1     0.40020833333333333 |\n","| summary/train_acc/2      0.4580208333333333 |\n","| summary/train_acc/3      0.5085416666666667 |\n","| summary/train_acc/4      0.5579166666666666 |\n","| summary/train_loss/0     2.0832002725316046 |\n","| summary/train_loss/1      1.756782130545556 |\n","| summary/train_loss/2     1.5777994148754995 |\n","| summary/train_loss/3      1.447633372588807 |\n","| summary/train_loss/4     1.3009527222658708 |\n","| summary/val_acc/0       0.37833333333333335 |\n","| summary/val_acc/1       0.40291666666666665 |\n","| summary/val_acc/2        0.4483333333333333 |\n","| summary/val_acc/3       0.45458333333333334 |\n","| summary/val_acc/4        0.5120833333333333 |\n","| summary/val_loss/0       1.8843663452487243 |\n","| summary/val_loss/1        1.757122580158083 |\n","| summary/val_loss/2       1.5903012258441824 |\n","| summary/val_loss/3        1.600063558863966 |\n","| summary/val_loss/4       1.4538564948659194 |\n","+---------------------------------------------+\n","Training saved a checkpoint for iteration 5 at: (local)/root/ray_results/wide_resnet50_cv_outer_4/TorchTrainer_b33ac_00000_0_2024-04-14_19-32-16/checkpoint_000004\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-14 21:41:31,685\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n","You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n","You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n","2024-04-14 21:41:31,699\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/wide_resnet50_cv_outer_4' in 0.0488s.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training completed after 5 iterations at 2024-04-14 21:41:31. Total running time: 2hr 9min 15s\n","\n"]}]},{"cell_type":"markdown","source":["# Transfer learning"],"metadata":{"id":"UNkbu381p4uo"}},{"cell_type":"code","source":["ciri_trainer = CIRI_trainer(model=selected_model,\n","                            data_folders=data_folders,\n","                            data_prop=0.8)"],"metadata":{"id":"NLd2W-IYqPwy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_folder = ... # Redefine here project folder if necessary\n","persistence_path = os.path.join(project_folder, 'checkpoints', f'TransferLearning_{selected_model}')\n","os.makedirs(persistence_path, exist_ok=True)"],"metadata":{"id":"t0IVxWD8t1h4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tl_results = ciri_trainer.train(\n","    run_name=f'{selected_model}_transfer_learning',\n","    config={\n","        **best_params,\n","        'additional_metrics': ['precision', 'recall', 'f1', 'confusion_matrix'],\n","        'weights': 'IMAGENET1K_V2',\n","    },\n","    persist_dir=persistence_path\n",")"],"metadata":{"id":"KLx8ha5UuGND"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[],"authorship_tag":"ABX9TyNtyyD99EAucoZCKtr3Pjlr"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}